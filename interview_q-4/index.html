<!DOCTYPE html>
<html lang="tr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka ve RabbitMQ Mülakat Soruları</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        .code-block {
            border-radius: 0.5rem;
            padding: 1rem;
            overflow-x: auto;
            font-family: monospace;
            font-size: 0.875rem;
        }

        .code-block.bash {
            background-color: #1e293b;
            color: #e2e8f0;
        }

        .code-block.json {
            background-color: #1e3a5f;
            color: #e2e8f0;
        }

        .code-block.yaml {
            background-color: #1e3a1e;
            color: #e2e8f0;
        }

        .code-block.java {
            background-color: #3a1e3a;
            color: #e2e8f0;
        }

        .code-block.xml {
            background-color: #3a1e1e;
            color: #e2e8f0;
        }

        .code-block.properties {
            background-color: #1e293b;
            color: #e2e8f0;
        }

        .category-card {
            transition: transform 0.3s ease;
        }

        .category-card:hover {
            transform: translateY(-5px);
        }

        .question-card {
            transition: all 0.3s ease;
        }

        .question-card:hover {
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }

        .kafka-color {
            background-color: #2a3f5f;
        }

        .rabbit-color {
            background-color: #ff6600;
        }
    </style>
</head>

<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <header class="text-center mb-12">
            <h1 class="text-4xl font-bold text-gray-800 mb-2">Kafka ve RabbitMQ Mülakat Soruları</h1>
            <p class="text-gray-600">100 adet ileri seviye soru ve cevapla hazırlanmış kapsamlı arşiv</p>
        </header>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-12">
            <div class="category-card bg-white rounded-lg shadow-md p-6">
                <div class="flex items-center mb-4">
                    <div class="bg-blue-100 p-3 rounded-full mr-4">
                        <i class="fas fa-stream text-blue-600 text-xl"></i>
                    </div>
                    <h2 class="text-xl font-bold text-gray-800">Apache Kafka</h2>
                </div>
                <p class="text-gray-600 mb-4">70 adet ileri seviye Kafka mülakat sorusu ve cevabı</p>
                <button onclick="scrollToCategory('kafka')"
                    class="text-blue-600 font-medium hover:text-blue-800">Soruları Görüntüle <i
                        class="fas fa-arrow-right ml-1"></i></button>
            </div>

            <div class="category-card bg-white rounded-lg shadow-md p-6">
                <div class="flex items-center mb-4">
                    <div class="bg-orange-100 p-3 rounded-full mr-4">
                        <i class="fas fa-envelope text-orange-600 text-xl"></i>
                    </div>
                    <h2 class="text-xl font-bold text-gray-800">RabbitMQ</h2>
                </div>
                <p class="text-gray-600 mb-4">30 adet ileri seviye RabbitMQ mülakat sorusu ve cevabı</p>
                <button onclick="scrollToCategory('rabbitmq')"
                    class="text-orange-600 font-medium hover:text-orange-800">Soruları Görüntüle <i
                        class="fas fa-arrow-right ml-1"></i></button>
            </div>
        </div>

        <!-- Kafka Soruları -->
        <section id="kafka" class="mb-16">
            <div class="bg-white rounded-lg shadow-md p-6 mb-8">
                <div class="flex items-center mb-6">
                    <div class="kafka-color p-3 rounded-full mr-4">
                        <i class="fas fa-stream text-white text-xl"></i>
                    </div>
                    <h2 class="text-2xl font-bold text-gray-800">Apache Kafka Mülakat Soruları</h2>
                </div>
                <p class="text-gray-600 mb-6">Bu dokümanda Apache Kafka mülakatlarında en çok sorulan konular soru-cevap mantığıyla açıklanmış ve örnek kodlar eklenmiştir.</p>

                <div class="space-y-6">
                    <!-- Temel Kafka Kavramları -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Temel Kafka Kavramları</h3>

                        <!-- Soru 1 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 1: Apache Kafka nedir? Ne işe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Apache Kafka, açık kaynaklı bir dağıtık olay akışı platformudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Yüksek verimli, gerçek zamanlı veri akışları için kullanılır.</li>
                                    <li>Pub-sub modeli temelinde çalışır.</li>
                                    <li>Veri kalıcılığı sağlar (persistent messaging).</li>
                                    <li>Büyük ölçekli veri işleme sistemlerinde kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Sunucusunu Başlatma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-server-start.sh config/server.properties</pre>
                            </div>
                        </div>

                        <!-- Soru 2 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 2: Kafka'da Topic nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Topic, Kafka'da mesajların kategorize edildiği mantıksal birimdir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Mesajlar topic'ler aracılığıyla yayınlanır ve tüketilir.</li>
                                    <li>Her topic birden fazla partition içerebilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Topic Oluşturma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3 --topic my-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 3 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 3: Partition nedir? Neden
                                önemlidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Partition, bir topic'in bölümleridir ve paralel işlemeye olanak tanır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her partition, bir broker üzerinde fiziksel olarak depolanır.</li>
                                    <li>Partition sayısı arttıkça okuma ve yazma işlemi paralel olarak yapılabilir.</li>
                                    <li>Veri dağıtımı ve yük dengeleme için önemlidir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 4 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 4: Producer ve Consumer
                                arasındaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Producer:</strong> Kafka'ya mesaj gönderen uygulamadır.</li>
                                    <li><strong>Consumer:</strong> Kafka'dan mesaj alan uygulamadır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Java Producer Örneği:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
producer.send(new ProducerRecord<>("my-topic", "key", "value"));
producer.close();</pre>
                            </div>
                        </div>

                        <!-- Soru 5 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 5: Consumer Group nedir? Ne işe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer Group, aynı topic'i tüketen consumer'ların koleksiyonudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Bir topic'teki partition'lar consumer group içindeki consumer'lara dağıtılır.</li>
                                    <li>Her partition sadece bir consumer tarafından tüketilebilir.</li>
                                    <li>Load balancing ve fault tolerance sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Group ile Consumer Başlatma:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "test-group");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Collections.singletonList("my-topic"));</pre>
                            </div>
                        </div>

                        <!-- Soru 6 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 6: Broker nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Broker, Kafka kümesindeki bir sunucudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her broker, cluster içinde benzersiz bir ID'ye sahiptir.</li>
                                    <li>Partition'ları barındırır ve client isteklerini yönetir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 7 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 7: Zookeeper Kafka'da ne işe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Zookeeper, Kafka kümesi için koordinasyon hizmeti sağlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Broker'ların, topic'lerin ve partition'ların metadata'sını saklar.</li>
                                    <li>Leader seçimi ve cluster yönetimi için kullanılır.</li>
                                    <li>Kafka 3.0 ve sonrası için KIP-500 ile Zookeepersiz mod de desteklenmektedir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 8 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 8: Offset nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Offset, bir partition içindeki her mesajın benzersiz konumunu belirten bir sayıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her partition kendi offset'lerini yönetir.</li>
                                    <li>Consumer'lar hangi mesaja kadar okuduklarını offset'ler aracılığıyla takip ederler.</li>
                                    <li>Offset'ler __consumer_offsets topic'inde saklanır.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 9 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 9: Replication nedir? Neden
                                önemlidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Replication, veri kopyalarının farklı broker'lar üzerinde saklanmasıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Veri güvenliği ve dayanıklılık sağlar.</li>
                                    <li>Bir broker çöktüğünde, veri kaybı önlenmiş olur.</li>
                                    <li>Replication faktörü, her partition için kaç kopya olacağını belirtir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Replication Faktörü Ayarları:</p>
                                <pre class="code-block bash mt-2"># Topic oluştururken replication faktörü belirtme
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 3 --topic replicated-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 10 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 10: Leader ve Follower
                                partition'lar arasındaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Leader Partition:</strong> Bir partition için tüm okuma ve yazma işlemlerinden sorumlu olan partition'dır.</li>
                                    <li><strong>Follower Partition:</strong> Leader partition'dan veriyi çoğaltan (replicate eden) partition'lardır.</li>
                                </ul>
                                <p>Leader partition çöktüğünde, follower'lardan biri yeni leader olarak seçilir.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka İleri Düzey Konular -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka İleri Düzey Konular</h3>

                        <!-- Soru 11 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 11: Kafka'nın mesajlaşma
                                garantileri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka üç farklı mesajlaşma garantisi sunar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>At most once:</strong> Mesajların en fazla bir kez teslim edildiği, kaybolabileceği garanti.</li>
                                    <li><strong>At least once:</strong> Mesajların en az bir kez teslim edildiği, tekrarlanabileceği garanti.</li>
                                    <li><strong>Exactly once:</strong> Mesajların tam olarak bir kez teslim edildiği garanti (Kafka Streams ve Transactions ile).</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer için Acks Ayarları:</p>
                                <pre class="code-block java mt-2">// At most once
props.put("acks", "0");

// At least once (default)
props.put("acks", "1");

// Exactly once / En güvenli
props.put("acks", "all");</pre>
                            </div>
                        </div>

                        <!-- Soru 12 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 12: Kafka Connector'lar
                                nelerdir? Ne işe yararlar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka Connector'lar, Kafka'yı diğer sistemlerle entegre etmek için kullanılan bileşenlerdir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Source Connector:</strong> Diğer sistemlerden Kafka'ya veri aktarır.</li>
                                    <li><strong>Sink Connector:</strong> Kafka'dan diğer sistemlere veri aktarır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Örnek Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "jdbc-source-connector",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url": "jdbc:postgresql://localhost:5432/mydb",
    "connection.user": "user",
    "connection.password": "password",
    "mode": "bulk",
    "topic.prefix": "jdbc-",
    "tasks.max": "1"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 13 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 13: Kafka Streams nedir? Ne
                                işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka Streams, Kafka üzerinde gerçek zamanlı veri işleme uygulamaları geliştirmek için kullanılan bir kütüphanedir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Stream Processing (akış işleme) için kullanılır.</li>
                                    <li>Scala veya Java ile yazılabilir.</li>
                                    <li>Stateful ve stateless işlemleri destekler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Basit Kafka Stream Örneği:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount-app");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

KStream<String, String> source = builder.stream("text-input");
KTable<String, Long> counts = source
    .flatMapValues(value -> Arrays.asList(value.toLowerCase().split("\\W+")))
    .groupBy((key, value) -> value)
    .count();
counts.toStream().to("word-count-output", Produced.with(Serdes.String(), Serdes.Long()));</pre>
                            </div>
                        </div>

                        <!-- Soru 14 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 14: Kafka'da Compaction nedir?
                                Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Compaction, bir topic'te aynı anahtara sahip mesajların sadece en sonuncusunu tutma işlemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Log compaction olarak da bilinir.</li>
                                    <li>Değişen veriler için kullanışlıdır (örneğin, kullanıcı profilleri).</li>
                                    <li>Topic'in son durumunu korurken depolama alanından tasarruf sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Compaction Özellikli Topic Oluşturma:</p>
                                <pre class="code-block bash mt-2">bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic compacted-topic --config cleanup.policy=compact</pre>
                            </div>
                        </div>

                        <!-- Soru 15 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 15: Kafka'da Retention Period
                                nedir? Nasıl ayarlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Retention Period, mesajların Kafka'da ne kadar süre kalacağını belirten süredir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Zamana dayalı (örneğin, 7 gün) veya boyuta dayalı (örneğin, 1GB) olabilir.</li>
                                    <li>Süre dolduğunda mesajlar otomatik olarak silinir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Retention Ayarları:</p>
                                <pre class="code-block bash mt-2"># Topic oluştururken retention ayarlama
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic retention-topic --config retention.ms=604800000

# Mevcut topic'in retention süresini değiştirme
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name retention-topic --alter --add-config retention.ms=259200000</pre>
                            </div>
                        </div>

                        <!-- Soru 16 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 16: Kafka'da Schema Registry
                                nedir? Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Schema Registry, Kafka'da kullanılan veri şemalarını (Avro, JSON, Protobuf) yönetmek için kullanılan bir servistir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Veri şemalarının merkezi olarak saklanmasını sağlar.</li>
                                    <li>Producer ve Consumer arasındaki uyumluluğu kontrol eder.</li>
                                    <li>Şema evrimini (evolution) yönetir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Schema Registry Kullanımı:</p>
                                <pre class="code-block bash mt-2"># Schema yükleme
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  --data '{"schema": "{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"age\",\"type\":\"int\"}]}"}' \
  http://localhost:8081/subjects/users-value/versions</pre>
                            </div>
                        </div>

                        <!-- Soru 17 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 17: Kafka'da ISR (In-Sync
                                Replicas) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> ISR, leader partition ile senkronize olan replikaların kümesidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>ISR'deki replikalar, leader partition'daki tüm mesajları kopyalamışlardır.</li>
                                    <li>Bir replica, belirli bir süre içinde leader ile senkronize olamazsa ISR'den çıkarılır.</li>
                                    <li>Leader seçimi ISR içindeki replikalar arasından yapılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">ISR İle İlgili Ayarlar:</p>
                                <pre class="code-block properties mt-2"># Minimum ISR boyutu
min.insync.replicas=2

# Replica senkronizasyon zaman aşımı
replica.lag.time.max.ms=30000</pre>
                            </div>
                        </div>

                        <!-- Soru 18 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 18: Kafka'da Consumer Rebalance
                                nedir? Ne zaman gerçekleşir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer Rebalance, bir consumer grubundaki partition'ların consumer'lar arasında yeniden dağıtılması işlemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Yeni bir consumer gruba katıldığında.</li>
                                    <li>Bir consumer gruptan ayrıldığında veya çöktüğünde.</li>
                                    <li>Bir topic'in partition sayısı değiştiğinde.</li>
                                </ul>
                                <p>Rebalance sırasında, consumer'lar geçici olarak veri işlemezler. Bu nedenle, uzun sürebilecek işlemler için dikkatli olunmalıdır.</p>
                            </div>
                        </div>

                        <!-- Soru 19 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 19: Kafka'da Static ve Dynamic
                                Membership arasındaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Static Membership:</strong> Consumer'ların sabit bir kimlik (group.instance.id) ile gruba katıldığı bir moddur. Bu modda, bir consumer geçici olarak ayrılıp geri döndüğünde, aynı partition'ları alır.</li>
                                    <li><strong>Dynamic Membership:</strong> Consumer'ların geçici kimliklerle gruba katıldığı varsayılan moddur. Bir consumer ayrılıp geri döndüğünde, farklı partition'lar alabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Static Membership Ayarı:</p>
                                <pre class="code-block java mt-2">props.put("group.instance.id", "consumer-1-instance");</pre>
                            </div>
                        </div>

                        <!-- Soru 20 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 20: Kafka'da Exactly-Once
                                Semantics nasıl sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da exactly-once semantik, iki mekanizma ile sağlanır:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> Aynı mesajın birden fazla kez gönderilmesini önler.</li>
                                    <li><strong>Transactions:</strong> Birden fazla partition'a atomik yazma işlemleri sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Producer Ayarı:</p>
                                <pre class="code-block java mt-2">props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Transactional Producer Örneği:</p>
                                <pre class="code-block java mt-2">props.put("transactional.id", "my-transactional-id");
Producer<String, String> producer = new KafkaProducer<>(props);

producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic1", "key", "value"));
    producer.send(new ProducerRecord<>("topic2", "key", "value"));
    producer.commitTransaction();
} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
    producer.close();
} catch (KafkaException e) {
    producer.abortTransaction();
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Performans ve Ölçeklendirme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka Performans ve Ölçeklendirme</h3>

                        <!-- Soru 21 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 21: Kafka kümesini ölçeklendirmek
                                için nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kümesini ölçeklendirirken dikkat edilmesi gereken önemli noktalar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker Ekleme:</strong> Yeni broker'lar küme eklendikten sonra partition'lar yeniden dağıtılmalıdır.</li>
                                    <li><strong>Partition Sayısı:</strong> Daha fazla paralel işlem için partition sayısı artırılabilir, ancak bu sayı azaltılamaz.</li>
                                    <li><strong>Replication Faktörü:</strong> Artan broker sayısıyla birlikte replication faktörü artırılabilir.</li>
                                    <li><strong>Network ve Disk I/O:</strong> Yeni broker'ların ağ ve disk kapasitesi mevcut broker'larla uyumlu olmalıdır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Partition Yeniden Dağıtma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file reassign.json --execute</pre>
                            </div>
                        </div>

                        <!-- Soru 22 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 22: Kafka'da batch processing
                                nedir? Performansı nasıl etkiler?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Batch processing, Kafka'da birden fazla mesajın tek bir network isteğiyle gönderilmesidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Network trafiğini azaltır ve verimliliği artırır.</li>
                                    <li>Gecikme (latency) ile verimlilik (throughput) arasında bir denge kurar.</li>
                                    <li>Batch boyutu arttıkça verimlilik artar, ancak gecikme de artar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Batch Ayarları:</p>
                                <pre class="code-block java mt-2">// Batch boyutu (bayt cinsinden)
props.put("batch.size", 16384);

// Bir mesajın ne kadar bekleneceği (milisaniye)
props.put("linger.ms", 5);</pre>
                            </div>
                        </div>

                        <!-- Soru 23 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 23: Kafka'da partition sayısını
                                belirlerken nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Partition sayısını belirlerken dikkat edilmesi gereken faktörler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Tüketim Hızı:</strong> Partition sayısı, paralel tüketim için maksimum consumer sayısını belirler.</li>
                                    <li><strong>Üretim Hızı:</strong> Daha fazla partition, daha yüksek paralel yazma imkanı sağlar.</li>
                                    <li><strong>Depolama ve Bellek:</strong> Her partition, broker'larda ek depolama ve bellek gerektirir.</li>
                                    <li><strong>Gelecek Büyüme:</strong> Partition sayısı azaltılamayacağı için gelecekteki ihtiyaçlar dikkate alınmalıdır.</li>
                                </ul>
                                <p>Genel bir kural olarak, partition sayısı, beklenen maksimum paralel consumer sayısından biraz fazla olmalıdır.</p>
                            </div>
                        </div>

                        <!-- Soru 24 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 24: Kafka'da compression nasıl
                                çalışır? Hangi compression algoritmaları desteklenir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka, mesajları göndermeden önce sıkıştırabilir, bu da network trafiğini azaltır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Compression, producer tarafında yapılır ve consumer tarafında otomatik olarak açılır.</li>
                                    <li>Desteklenen algoritmalar: gzip, snappy, lz4, zstd.</li>
                                </ul>
                                <p class="mt-2 font-medium">Compression Ayarları:</p>
                                <pre class="code-block java mt-2">// Compression türü
props.put("compression.type", "lz4");

// Sıkıştırma seviyesi (sadece gzip ve zstd için)
props.put("compression.level", "5");</pre>
                            </div>
                        </div>

                        <!-- Soru 25 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 25: Kafka'da consumer
                                performansını artırmak için neler yapılabilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer performansını artırmak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>fetch.min.bytes ve fetch.max.wait.ms:</strong> Consumer'ın ne kadar veri bekleyeceğini kontrol eder.</li>
                                    <li><strong>max.partition.fetch.bytes:</strong> Bir partition'dan çekilebilecek maksimum veri boyutu.</li>
                                    <li><strong>max.poll.records:</strong> Bir poll() çağrısında döndürülen maksimum kayıt sayısı.</li>
                                    <li><strong>Concurrent Processing:</strong> Veriyi paralel işlemek için thread'ler kullanılabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Performans Ayarları:</p>
                                <pre class="code-block java mt-2">// Minimum byte bekleme
props.put("fetch.min.bytes", 1024);

// Maksimum bekleme süresi
props.put("fetch.max.wait.ms", 500);

// Bir partition'dan çekilecek maksimum veri
props.put("max.partition.fetch.bytes", 1048576);

// Bir poll'da döndürülecek maksimum kayıt
props.put("max.poll.records", 500);</pre>
                            </div>
                        </div>

                        <!-- Soru 26 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 26: Kafka'da producer
                                performansını artırmak için neler yapılabilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Producer performansını artırmak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>batch.size ve linger.ms:</strong> Daha büyük batch'ler ve daha uzun bekleme süreleri verimliliği artırır.</li>
                                    <li><strong>compression.type:</strong> Veri sıkıştırma network trafiğini azaltır.</li>
                                    <li><strong>buffer.memory:</strong> Toplam buffer belleğini artırmak.</li>
                                    <li><strong>acks:</strong> Daha düşük acks seviyeleri (0 veya 1) gecikmeyi azaltır.</li>
                                    <li><strong>retries ve retry.backoff.ms:</strong> Geçici hatalarda yeniden deneme mekanizması.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Performans Ayarları:</p>
                                <pre class="code-block java mt-2">// Toplam buffer belleği
props.put("buffer.memory", 67108864);

// Yeniden deneme sayısı
props.put("retries", 3);

// Yeniden deneme aralığı
props.put("retry.backoff.ms", 100);</pre>
                            </div>
                        </div>

                        <!-- Soru 27 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 27: Kafka'da disk I/O
                                performansını optimize etmek için nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Disk I/O performansını optimize etmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>log.dirs:</strong> Farklı disklerde birden fazla log dizini kullanmak.</li>
                                    <li><strong>log.segment.bytes:</strong> Segment boyutunu artırmak.</li>
                                    <li><strong>log.flush.interval.messages ve log.flush.interval.ms:</strong> Disk flush sıklığını ayarlamak.</li>
                                    <li><strong>num.io.threads:</strong> I/O işlemleri için thread sayısını artırmak.</li>
                                    <li><strong>SSD Diskler:</strong> Mekanik disklere göre daha iyi I/O performansı sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Disk I/O Ayarları:</p>
                                <pre class="code-block properties mt-2"># Farklı disklerde log dizinleri
log.dirs=/disk1/kafka-logs,/disk2/kafka-logs

# Segment boyutu (varsayılan: 1GB)
log.segment.bytes=1073741824

# I/O thread sayısı
num.io.threads=8

# Flush aralığı (mesaj sayısı)
log.flush.interval.messages=10000

# Flush aralığı (milisaniye)
log.flush.interval.ms=1000</pre>
                            </div>
                        </div>

                        <!-- Soru 28 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 28: Kafka'da network
                                performansını optimize etmek için nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Network performansını optimize etmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>socket.send.buffer.bytes ve socket.receive.buffer.bytes:</strong> Socket buffer boyutlarını artırmak.</li>
                                    <li><strong>socket.request.max.bytes:</strong> Maksimum istek boyutunu artırmak.</li>
                                    <li><strong>num.network.threads:</strong> Network işlemleri için thread sayısını artırmak.</li>
                                    <li><strong>compression.type:</strong> Veri sıkıştırma kullanarak network trafiğini azaltmak.</li>
                                    <li><strong>batch.size:</strong> Daha büyük batch'ler ile daha az network isteği.</li>
                                </ul>
                                <p class="mt-2 font-medium">Network Ayarları:</p>
                                <pre class="code-block properties mt-2"># Socket buffer boyutları
socket.send.buffer.bytes=1024000
socket.receive.buffer.bytes=1024000

# Maksimum istek boyutu
socket.request.max.bytes=104857600

# Network thread sayısı
num.network.threads=4</pre>
                            </div>
                        </div>

                        <!-- Soru 29 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 29: Kafka'da JVM ayarlarını
                                optimize etmek için nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> JVM ayarlarını optimize etmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Heap Boyutu:</strong> Yeterli heap boyutu ayarlamak (genellikle 6GB ve üzeri).</li>
                                    <li><strong>Garbage Collector:</strong> G1GC kullanmak, büyük heap boyutları için daha uygundur.</li>
                                    <li><strong>JMX Port:</strong> Monitoring için JMX portunu açmak.</li>
                                    <li><strong>GC Logging:</strong> GC performansını izlemek için GC loglarını etkinleştirmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">JVM Ayarları:</p>
                                <pre class="code-block bash mt-2"># Kafka başlatma komutunda JVM ayarları
export KAFKA_HEAP_OPTS="-Xmx6G -Xms6G"
export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true"</pre>
                            </div>
                        </div>

                        <!-- Soru 30 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 30: Kafka'da monitoring için
                                hangi metrikler izlenmelidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka monitoring için önemli metrikler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>UnderReplicatedPartitions:</strong> Yeterli replikası olmayan partition sayısı.</li>
                                    <li><strong>UnderMinIsrPartitionCount:</strong> Minimum ISR sayısının altındaki partition sayısı.</li>
                                    <li><strong>IsrShrinksPerSec ve IsrExpandsPerSec:</strong> ISR'deki değişim oranı.</li>
                                    <li><strong>ActiveControllerCount:</strong> Aktif controller sayısı (1 olmalı).</li>
                                    <li><strong>OfflinePartitionsCount:</strong> Çevrimdışı partition sayısı (0 olmalı).</li>
                                    <li><strong>RequestHandlerAvgIdlePercent:</strong> Network thread'lerin boşta kalma oranı.</li>
                                    <li><strong>BytesInPerSec ve BytesOutPerSec:</strong> Network trafiği.</li>
                                    <li><strong>MessagesInPerSec:</strong> Mesaj giriş hızı.</li>
                                </ul>
                                <p>Bu metrikler, Kafka kümesinin sağlığı ve performansı hakkında önemli bilgiler sağlar.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Güvenlik ve İzleme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka Güvenlik ve İzleme</h3>

                        <!-- Soru 31 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 31: Kafka'da güvenlik nasıl
                                sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da güvenlik sağlamak için kullanılan yöntemler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>SSL/TLS:</strong> Broker'lar arası ve client-broker arası iletişim için şifreleme.</li>
                                    <li><strong>SASL:</strong> Kimlik doğrulama mekanizmaları (PLAIN, SCRAM, GSSAPI/Kerberos).</li>
                                    <li><strong>ACL (Access Control Lists):</strong> Kullanıcı ve yetkilendirme yönetimi.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL Ayarları:</p>
                                <pre class="code-block properties mt-2"># Broker SSL ayarları
listeners=SSL://:9093
ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
ssl.truststore.password=test1234</pre>
                                <p class="mt-2 font-medium">SASL Ayarları:</p>
                                <pre class="code-block properties mt-2"># Broker SASL ayarları
listeners=SASL_SSL://:9093
sasl.mechanism.inter.broker.protocol=GSSAPI
sasl.enabled.mechanisms=GSSAPI
security.inter.broker.protocol=SASL_SSL</pre>
                            </div>
                        </div>

                        <!-- Soru 32 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 32: Kafka'da ACL (Access Control
                                List) nasıl yapılandırılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> ACL, Kafka'da kaynaklara (topic, cluster, group vb.) erişimi kontrol etmek için kullanılır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Principal (kullanıcı veya servis), kaynak ve işlem (READ, WRITE, CREATE, DESCRIBE vb.) bazında erişim kontrolü sağlar.</li>
                                    <li>ACL'ler kafka-acls.sh komutu ile yönetilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">ACL Örnekleri:</p>
                                <pre class="code-block bash mt-2"># User1'in test-topic üzerinde WRITE izni
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --operation Write --topic test-topic

# User1'in test-consumer-group üzerinde READ izni
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --operation Read --group test-consumer-group

# User2'nin tüm topic'leri DESCRIBE etmesine izin verme
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user2 --operation Describe --topic *</pre>
                            </div>
                        </div>

                        <!-- Soru 33 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 33: Kafka'da SASL/SCRAM
                                kimlik doğrulama nasıl yapılandırılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> SASL/SCRAM, kullanıcı adı ve şifre ile kimlik doğrulama sağlayan bir mekanizmadır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Kullanıcı bilgileri Zookeeper'da saklanır.</li>
                                    <li>SCRAM mekanizması, şifrelerin düz metin olarak saklanmasını önler.</li>
                                </ul>
                                <p class="mt-2 font-medium">SCRAM Yapılandırması:</p>
                                <pre class="code-block properties mt-2"># Broker ayarları
listeners=SASL_SSL://:9093
sasl.enabled.mechanisms=SCRAM-SHA-256,SCRAM-SHA-512
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256
security.inter.broker.protocol=SASL_SSL

# JAAS konfigürasyonu
listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="admin" \
  password="admin-secret";</pre>
                                <p class="mt-2 font-medium">Kullanıcı Oluşturma:</p>
                                <pre class="code-block bash mt-2"># Kullanıcı ekleme
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-256=[password=alice-secret],SCRAM-SHA-512=[password=alice-secret]' --entity-type users --entity-name alice</pre>
                            </div>
                        </div>

                        <!-- Soru 34 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 34: Kafka'da SSL/TLS nasıl
                                yapılandırılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> SSL/TLS, Kafka'da iletişimi şifrelemek için kullanılır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Broker'lar arası iletişimi şifrelemek için.</li>
                                    <li>Client-broker arası iletişimi şifrelemek için.</li>
                                    <li>İki yönlü kimlik doğrulama (mutual TLS) için.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL Sertifikası Oluşturma:</p>
                                <pre class="code-block bash mt-2"># CA sertifikası oluşturma
openssl req -new -newkey rsa:2048 -days 365 -x509 -keyout ca-key -out ca-cert -subj "/C=TR/ST=Istanbul/L=Istanbul/O=MyOrg/CN=CA"

# Broker sertifikası oluşturma
keytool -genkey -keystore kafka.server.keystore.jks -alias localhost -keyalg RSA -validity 365 -storepass test1234 -keypass test1234 -dname "CN=localhost"

# CA ile sertifikayı imzalama
keytool -keystore kafka.server.keystore.jks -alias localhost -certreq -file cert-file
openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days 365 -CAcreateserial
keytool -keystore kafka.server.keystore.jks -alias CARoot -import -file ca-cert
keytool -keystore kafka.server.keystore.jks -alias localhost -import -file cert-signed

# Truststore oluşturma
keytool -keystore kafka.server.truststore.jks -alias CARoot -import -file ca-cert -storepass test1234</pre>
                                <p class="mt-2 font-medium">Broker SSL Ayarları:</p>
                                <pre class="code-block properties mt-2">listeners=SSL://:9093
ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
ssl.truststore.password=test1234</pre>
                            </div>
                        </div>

                        <!-- Soru 35 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 35: Kafka'da veri şifreleme
                                (encryption) nasıl sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da veri şifreleme için iki yaklaşım vardır:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Transport Level Encryption (SSL/TLS):</strong> Verinin network üzerinde şifrelenmesi.</li>
                                    <li><strong>Application Level Encryption:</strong> Verinin uygulama katmanında şifrelenmesi.</li>
                                </ul>
                                <p class="mt-2 font-medium">Uygulama Katmanında Şifreleme Örneği:</p>
                                <pre class="code-block java mt-2">import javax.crypto.Cipher;
import javax.crypto.KeyGenerator;
import javax.crypto.SecretKey;
import javax.crypto.spec.SecretKeySpec;
import java.util.Base64;

public class EncryptionUtil {
    private static final String ALGORITHM = "AES";
    
    public static String encrypt(String data, String key) throws Exception {
        SecretKeySpec secretKey = new SecretKeySpec(key.getBytes(), ALGORITHM);
        Cipher cipher = Cipher.getInstance(ALGORITHM);
        cipher.init(Cipher.ENCRYPT_MODE, secretKey);
        byte[] encryptedBytes = cipher.doFinal(data.getBytes());
        return Base64.getEncoder().encodeToString(encryptedBytes);
    }
    
    public static String decrypt(String encryptedData, String key) throws Exception {
        SecretKeySpec secretKey = new SecretKeySpec(key.getBytes(), ALGORITHM);
        Cipher cipher = Cipher.getInstance(ALGORITHM);
        cipher.init(Cipher.DECRYPT_MODE, secretKey);
        byte[] decryptedBytes = cipher.doFinal(Base64.getDecoder().decode(encryptedData));
        return new String(decryptedBytes);
    }
}

// Producer kullanımı
String encryptedData = EncryptionUtil.encrypt("sensitive data", "my-secret-key");
producer.send(new ProducerRecord<>("encrypted-topic", encryptedData));</pre>
                            </div>
                        </div>

                        <!-- Soru 36 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 36: Kafka'da izleme
                                (monitoring) için hangi araçlar kullanılabilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka monitoring için kullanılan araçlar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka内置指标:</strong> Kafka'nın JMX aracılığıyla sağladığı metrikler.</li>
                                    <li><strong>Prometheus + Grafana:</strong> Metrikleri toplamak ve görselleştirmek için.</li>
                                    <li><strong>Confluent Control Center:</strong> Confluent Platform'un sağladığı komerciyel monitoring aracı.</li>
                                    <li><strong>Kafka Manager (CMAK):</strong> Açık kaynaklı Kafka küme yönetim aracı.</li>
                                    <li><strong>Elasticsearch + Kibana:</strong> Logları toplamak ve analiz etmek için.</li>
                                    <li><strong>Jaeger/Zipkin:</strong> Dağıtık izleme (distributed tracing) için.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prometheus JMX Exporter Yapılandırması:</p>
                                <pre class="code-block yaml mt-2"># prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:7071'] # JMX Exporter portu</pre>
                            </div>
                        </div>

                        <!-- Soru 37 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 37: Kafka'da log yönetimi nasıl
                                yapılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da log yönetimi için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>log4j veya logback:</strong> Loglama için kullanılan kütüphaneler.</li>
                                    <li><strong>Log Aggregation:</strong> Logları merkezi bir sistemde toplamak (ELK, Splunk vb.).</li>
                                    <li><strong>Log Rotation:</strong> Log dosyalarının döndürülmesi.</li>
                                    <li><strong>Structured Logging:</strong> JSON formatında loglama.</li>
                                </ul>
                                <p class="mt-2 font-medium">log4j Yapılandırması:</p>
                                <pre class="code-block xml mt-2">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;Configuration status="WARN"&gt;
  &lt;Appenders&gt;
    &lt;Console name="Console" target="SYSTEM_OUT"&gt;
      &lt;PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n"/&gt;
    &lt;/Console&gt;
    &lt;RollingFile name="RollingFile" fileName="logs/kafka.log" filePattern="logs/kafka-%d{yyyy-MM-dd}-%i.log"&gt;
      &lt;PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n"/&gt;
      &lt;Policies&gt;
        &lt;TimeBasedTriggeringPolicy interval="1" modulate="true"/&gt;
        &lt;SizeBasedTriggeringPolicy size="100 MB"/&gt;
      &lt;/Policies&gt;
      &lt;DefaultRolloverStrategy max="10"/&gt;
    &lt;/RollingFile&gt;
  &lt;/Appenders&gt;
  &lt;Loggers&gt;
    &lt;Root level="INFO"&gt;
      &lt;AppenderRef ref="Console"/&gt;
      &lt;AppenderRef ref="RollingFile"/&gt;
    &lt;/Root&gt;
  &lt;/Loggers&gt;
&lt;/Configuration&gt;</pre>
                            </div>
                        </div>

                        <!-- Soru 38 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 38: Kafka'da uyarı (alerting)
                                sistemi nasıl kurulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da uyarı sistemi kurmak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Prometheus Alertmanager:</strong> Prometheus metriklerine dayalı uyarılar oluşturmak.</li>
                                    <li><strong>Grafana Alerting:</strong> Grafana üzerinden uyarı oluşturmak.</li>
                                    <li><strong>Burrow:</strong> Consumer lag izleme ve uyarı için özel araç.</li>
                                    <li><strong>Custom Scripts:</strong> Kafka metriklerini kontrol eden özel betikler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prometheus Alertmanager Yapılandırması:</p>
                                <pre class="code-block yaml mt-2"># alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alertmanager@example.com'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  email_configs:
  - to: 'admin@example.com'

# Prometheus alert rules
groups:
- name: kafka.rules
  rules:
  - alert: KafkaUnderReplicatedPartitions
    expr: kafka_server_replicamanager_underreplicatedpartitions > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Kafka under-replicated partitions (instance {{ $labels.instance }})"
      description: "Kafka has {{ $value }} under-replicated partitions for more than 5 minutes."</pre>
                            </div>
                        </div>

                        <!-- Soru 39 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 39: Kafka'da JMX metrikleri nasıl
                                izlenir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da JMX metriklerini izlemek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>JMX Portu Açma:</strong> Kafka broker'ları için JMX portunu açmak.</li>
                                    <li><strong>JMX Konsolu:</strong> JConsole veya JVisualVM kullanarak metrikleri görüntülemek.</li>
                                    <li><strong>JMX Exporter:</strong> JMX metriklerini Prometheus formatına dönüştürmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">JMX Portu Açma:</p>
                                <pre class="code-block bash mt-2"># Kafka başlatma komutunda JMX ayarları
export KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"</pre>
                                <p class="mt-2 font-medium">JMX Exporter Yapılandırması:</p>
                                <pre class="code-block yaml mt-2"># jmx-exporter-config.yml
rules:
- pattern: "kafka.server&lt;type=ReplicaManager, name=UnderReplicatedPartitions&gt;&lt;&gt;Value"
  name: "kafka_server_replicamanager_underreplicatedpartitions"
  type: GAUGE
  value: "{{ $value }}"</pre>
                            </div>
                        </div>

                        <!-- Soru 40 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 40: Kafka'da audit log nasıl
                                oluşturulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da audit log oluşturmak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Authorizer:</strong> Kimlik doğrulama ve yetkilendirme olaylarını loglamak.</li>
                                    <li><strong>Custom Interceptor:</strong> Producer ve Consumer interceptor'ları ile özel loglama.</li>
                                    <li><strong>Audit Topic:</strong> Audit olaylarını özel bir topic'e göndermek.</li>
                                </ul>
                                <p class="mt-2 font-medium">Audit Log Yapılandırması:</p>
                                <pre class="code-block properties mt-2"># Broker ayarları
authorizer.class.name=kafka.security.authorizer.AclAuthorizer

# Audit log ayarları
kafka.authorizer.logger.listeners=kafka.security.authorizer.AclAuthorizer$AuditLogListener
kafka.authorizer.logger.listeners.log.dir=/var/log/kafka/audit</pre>
                                <p class="mt-2 font-medium">Custom Interceptor Örneği:</p>
                                <pre class="code-block java mt-2">public class AuditProducerInterceptor implements ProducerInterceptor<String, String> {
    private static final Logger LOG = LoggerFactory.getLogger(AuditProducerInterceptor.class);
    
    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
        LOG.info("Sending message to topic: {}, key: {}, value: {}", 
                record.topic(), record.key(), record.value());
        return record;
    }
    
    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            LOG.error("Error sending message", exception);
        } else {
            LOG.info("Message sent successfully to topic: {}, partition: {}, offset: {}", 
                    metadata.topic(), metadata.partition(), metadata.offset());
        }
    }
    
    @Override
    public void close() {}
    
    @Override
    public void configure(Map<String, ?> configs) {}
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Senaryo ve Problem Çözme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka Senaryo ve Problem Çözme</h3>

                        <!-- Soru 41 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 41: Consumer sürekli
                                rebalance oluyor, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer sürekli rebalance oluyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>max.poll.interval.ms:</strong> Bu süreden daha uzun süren işlemler için değeri artırın.</li>
                                    <li><strong>heartbeat.interval.ms:</strong> Heartbeat aralığını kısaltın.</li>
                                    <li><strong>session.timeout.ms:</strong> Oturum zaman aşımını artırın.</li>
                                    <li><strong>İşlem Süresi:</strong> Veri işleme süresini optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Ayarları:</p>
                                <pre class="code-block java mt-2">// Poll aralığı (varsayılan: 300000 ms)
props.put("max.poll.interval.ms", 600000);

// Heartbeat aralığı (varsayılan: 3000 ms)
props.put("heartbeat.interval.ms", 1000);

// Oturum zaman aşımı (varsayılan: 10000 ms)
props.put("session.timeout.ms", 30000);</pre>
                            </div>
                        </div>

                        <!-- Soru 42 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 42: Kafka'da mesaj kaybı
                                yaşıyorum, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesaj kaybını önlemek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>acks=all:</strong> Producer için tüm replikaların onayını bekle.</li>
                                    <li><strong>min.insync.replicas:</strong> Minimum ISR sayısını artır.</li>
                                    <li><strong>retries:</strong> Producer için yeniden deneme sayısını artır.</li>
                                    <li><strong>enable.idempotence:</strong> Idempotent producer'ı etkinleştir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Ayarları:</p>
                                <pre class="code-block java mt-2">// Tüm replikaların onayını bekle
props.put("acks", "all");

// Yeniden deneme sayısı
props.put("retries", 3);

// Idempotent producer
props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Broker Ayarları:</p>
                                <pre class="code-block properties mt-2"># Minimum ISR sayısı
min.insync.replicas=2</pre>
                            </div>
                        </div>

                        <!-- Soru 43 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 43: Kafka'da consumer lag
                                (geride kalma) sorunu yaşıyorum, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer lag sorununu çözmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer Sayısını Artırma:</strong> Daha fazla consumer ekleyin.</li>
                                    <li><strong>Partition Sayısını Artırma:</strong> Topic için daha fazla partition oluşturun.</li>
                                    <li><strong>İşlem Süresini Optimize Etme:</strong> Veri işleme süresini azaltın.</li>
                                    <li><strong>Batch İşleme:</strong> Veriyi toplu olarak işleyin.</li>
                                    <li><strong>Consumer Ayarları:</strong> fetch.min.bytes, max.poll.records gibi ayarları optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Lag Kontrolü:</p>
                                <pre class="code-block bash mt-2"># Consumer lag kontrolü
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-consumer-group</pre>
                                <p class="mt-2 font-medium">Partition Sayısını Artırma:</p>
                                <pre class="code-block bash mt-2"># Partition sayısını artırma
bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic --partitions 10</pre>
                            </div>
                        </div>

                        <!-- Soru 44 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 44: Kafka broker'ı disk alanı
                                doldu, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Broker disk alanı dolduğunda:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Retention Süresini Azaltma:</strong> Mesajların daha hızlı silinmesi için retention süresini azaltın.</li>
                                    <li><strong>Log Segment Boyutunu Azaltma:</strong> Segment boyutunu küçültün.</li>
                                    <li><strong>Disk Temizleme:</strong> Eski log dosyalarını manuel olarak silin.</li>
                                    <li><strong>Yeni Disk Ekleme:</strong> Broker'a yeni disk ekleyin.</li>
                                    <li><strong>Topic'leri Taşıma:</strong> Bazı topic'leri başka broker'lara taşıyın.</li>
                                </ul>
                                <p class="mt-2 font-medium">Retention Süresini Azaltma:</p>
                                <pre class="code-block bash mt-2"># Topic için retention süresini azaltma
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config retention.ms=86400000</pre>
                                <p class="mt-2 font-medium">Log Segment Boyutunu Ayarlama:</p>
                                <pre class="code-block bash mt-2"># Topic için log segment boyutunu ayarlama
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config log.segment.bytes=536870912</pre>
                            </div>
                        </div>

                        <!-- Soru 45 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 45: Kafka kümesinde broker
                                çöktü, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kümesinde broker çöktüğünde:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker'ı Yeniden Başlatma:</strong> Broker'ı yeniden başlatın.</li>
                                    <li><strong>Logları İnceleme:</strong> Neden çöktüğünü anlamak için logları inceleyin.</li>
                                    <li><strong>Replication Faktörünü Kontrol Etme:</strong> Partition'ların replikaları var mı kontrol edin.</li>
                                    <li><strong>Leader Seçimini İzleme:</strong> Yeni leader'ların seçilip seçilmediğini izleyin.</li>
                                    <li><strong>Under-Replicated Partition'ları İzleme:</strong> Yeterli replikası olmayan partition'ları izleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Broker Durumunu Kontrol Etme:</p>
                                <pre class="code-block bash mt-2"># Broker durumunu kontrol etme
bin/kafka-broker-api-versions --bootstrap-server localhost:9092

# Topic durumunu kontrol etme
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 46 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 46: Kafka'da duplicate mesajlar
                                alıyorum, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Duplicate mesajları önlemek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> Producer'ı idempotent hale getirin.</li>
                                    <li><strong>Exactly-Once Semantics:</strong> Transaction kullanarak tam olarak bir kez teslimat sağlayın.</li>
                                    <li><strong>Consumer Tarafında Tekilleştirme:</strong> Aynı mesajın tekrar işlenmesini önleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Producer Ayarı:</p>
                                <pre class="code-block java mt-2">props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Transactional Producer Örneği:</p>
                                <pre class="code-block java mt-2">props.put("transactional.id", "my-transactional-id");
Producer<String, String> producer = new KafkaProducer<>(props);

producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic1", "key", "value"));
    producer.commitTransaction();
} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
    producer.close();
} catch (KafkaException e) {
    producer.abortTransaction();
}</pre>
                                <p class="mt-2 font-medium">Consumer Tarafında Tekilleştirme:</p>
                                <pre class="code-block java mt-2">public class DeduplicatingConsumer {
    private Set<String> processedIds = new HashSet<>();
    
    public void process(ConsumerRecord<String, String> record) {
        String messageId = record.key() + "-" + record.offset();
        if (processedIds.contains(messageId)) {
            return; // Zaten işlenmiş
        }
        
        // Mesajı işle
        processMessage(record.value());
        
        // İşlenmiş olarak işaretle
        processedIds.add(messageId);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 47 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 47: Kafka'da mesajların sırası
                                bozuluyor, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesaj sırasını korumak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Partition Sayısı:</strong> Sıralı mesajlar için tek partition kullanın.</li>
                                    <li><strong>Key Kullanma:</strong> Aynı key'e sahip mesajlar aynı partition'a gider.</li>
                                    <li><strong>Max In Flight Requests:</strong> Producer'da max.in.flight.requests.per.connection=1 ayarlayın.</li>
                                    <li><strong>İşlem Sırası:</strong> Consumer'da mesajları sıralı olarak işleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Ayarları:</p>
                                <pre class="code-block java mt-2">// Sıralı gönderim için
props.put("max.in.flight.requests.per.connection", "1");
props.put("retries", Integer.MAX_VALUE);
props.put("enable.idempotence", "true");

// Aynı key'e sahip mesajlar aynı partition'a gider
producer.send(new ProducerRecord<>("my-topic", "same-key", "value1"));
producer.send(new ProducerRecord<>("my-topic", "same-key", "value2"));</pre>
                                <p class="mt-2 font-medium">Consumer Tarafında Sıralı İşleme:</p>
                                <pre class="code-block java mt-2">public class OrderedConsumer {
    public void consume() {
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                // Sıralı olarak işle
                processInOrder(record);
            }
        }
    }
    
    private void processInOrder(ConsumerRecord<String, String> record) {
        // Mesajı sıralı olarak işle
        System.out.println("Processing: " + record.value());
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 48 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 48: Kafka'da mesajlar tüketiciye
                                ulaşıyor ama işlenmiyor, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesajlar tüketiciye ulaşıyor ama işlenmiyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer Loglarını İnceleme:</strong> Hata veya exception olup olmadığını kontrol edin.</li>
                                    <li><strong>Deserializasyon Hataları:</strong> Mesaj formatının doğru olup olmadığını kontrol edin.</li>
                                    <li><strong>İşlem Hatası:</strong> Mesaj işlenirken hata oluşuyor mu kontrol edin.</li>
                                    <li><strong>Offset Commit:</strong> Offset'lerin commit edilip edilmediğini kontrol edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Hata Ayıklama:</p>
                                <pre class="code-block java mt-2">try {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        try {
            // Mesajı işle
            processMessage(record);
        } catch (Exception e) {
            // Hata durumunda log yaz
            logger.error("Error processing message: " + record.value(), e);
            
            // Hatalı mesajı özel bir topic'e gönder
            sendToDlq(record);
        }
    }
    
    // Başarılı mesajları commit et
    consumer.commitSync();
} catch (Exception e) {
    logger.error("Error in consumer", e);
}</pre>
                            </div>
                        </div>

                        <!-- Soru 49 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 49: Kafka'da producer mesaj
                                gönderemiyor, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Producer mesaj gönderemiyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker Bağlantısı:</strong> Broker'a bağlanıp bağlanamadığını kontrol edin.</li>
                                    <li><strong>Topic Varlığı:</strong> Topic'in var olup olmadığını kontrol edin.</li>
                                    <li><strong>Yetkilendirme:</strong> Producer'ın topic'e yazma yetkisinin olup olmadığını kontrol edin.</li>
                                    <li><strong>Producer Ayarları:</strong> Bootstrap servers, serializer gibi ayarların doğru olup olmadığını kontrol edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Bağlantı Testi:</p>
                                <pre class="code-block bash mt-2"># Broker'a bağlantı testi
telnet localhost 9092

# Topic listesini kontrol etme
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list</pre>
                                <p class="mt-2 font-medium">Producer Hata Ayıklama:</p>
                                <pre class="code-block java mt-2">try {
    ProducerRecord<String, String> record = new ProducerRecord<>("my-topic", "key", "value");
    
    // Senkron gönderim ve hata kontrolü
    RecordMetadata metadata = producer.send(record).get();
    
    System.out.println("Message sent to partition " + metadata.partition() + 
                      " with offset " + metadata.offset());
} catch (InterruptedException | ExecutionException e) {
    // Hata durumunda detaylı bilgi
    if (e.getCause() instanceof TimeoutException) {
        System.err.println("Timeout while sending message");
    } else if (e.getCause() instanceof NotLeaderForPartitionException) {
        System.err.println("Not leader for partition");
    } else {
        System.err.println("Error sending message: " + e.getCause().getMessage());
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 50 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 50: Kafka kümesi yüksek
                                gecikme (latency) yaşıyor, ne yapmalıyım?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kümesinde yüksek gecikme yaşıyorsanız:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Network Gecikmesi:</strong> Broker'lar arası ve client-broker arası network gecikmesini ölçün.</li>
                                    <li><strong>Disk I/O:</strong> Disk I/O performansını kontrol edin.</li>
                                    <li><strong>GC Pauses:</strong> JVM garbage collection sürelerini izleyin.</li>
                                    <li><strong>Broker Kaynakları:</strong> CPU, bellek ve disk kullanımını kontrol edin.</li>
                                    <li><strong>Producer ve Consumer Ayarları:</strong> Batch boyutu, buffer boyutu gibi ayarları optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Gecikme Ölçümü:</p>
                                <pre class="code-block bash mt-2"># Producer gecikmesi ölçümü
bin/kafka-run-class.sh kafka.tools.EndToEndLatency \
  broker-list localhost:9092 \
  topic test-topic \
  num-records 1000 \
  record-size 1000 \
  producer-props acks=all,linger.ms=0 \
  consumer-props group.id=test-group

# Network gecikmesi testi
ping -c 10 kafka-broker-host</pre>
                                <p class="mt-2 font-medium">Producer ve Consumer Ayarları:</p>
                                <pre class="code-block java mt-2">// Producer için düşük gecikme ayarları
props.put("linger.ms", 0); // Bekleme süresini sıfırla
props.put("batch.size", 0); // Batch'leri devre dışı bırak
props.put("compression.type", "none"); // Sıkıştırmayı devre dışı bırak

// Consumer için düşük gecikme ayarları
props.put("fetch.min.bytes", 1); // Minimum bekleme boyutu
props.put("fetch.max.wait.ms", 100); // Maksimum bekleme süresi</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Entegrasyon ve Kullanım Senaryoları -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka Entegrasyon ve Kullanım Senaryoları</h3>

                        <!-- Soru 51 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 51: Kafka ve Spark Streaming nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Spark Streaming entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Spark Kafka Connector:</strong> Spark'ın Kafka ile iletişim kurmasını sağlar.</li>
                                    <li><strong>Structured Streaming:</strong> Spark'ın yapısal akış işleme API'si.</li>
                                </ul>
                                <p class="mt-2 font-medium">Spark Streaming Kafka Entegrasyonu:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

val spark = SparkSession.builder()
  .appName("KafkaSparkIntegration")
  .master("local[*]")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()

// Mesaj değerlerini string olarak dönüştürme
val values = df.selectExpr("CAST(value AS STRING)")

// Veriyi işleme
val processed = values.withColumn("processed", upper(col("value")))

// Kafka'ya yazma
val query = processed.writeStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("topic", "output-topic")
  .option("checkpointLocation", "/tmp/checkpoint")
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 52 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 52: Kafka ve Flink nasıl entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Flink entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Flink Kafka Connector:</strong> Flink'in Kafka ile iletişim kurmasını sağlar.</li>
                                    <li><strong>FlinkKafkaConsumer ve FlinkKafkaProducer:</strong> Kafka'dan veri okuma ve yazma sınıfları.</li>
                                </ul>
                                <p class="mt-2 font-medium">Flink Kafka Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import java.util.Properties;

public class KafkaFlinkIntegration {
    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        Properties properties = new Properties();
        properties.setProperty("bootstrap.servers", "localhost:9092");
        properties.setProperty("group.id", "flink-consumer");
        
        // Kafka'dan veri okuma
        FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
            "input-topic",
            new SimpleStringSchema(),
            properties
        );
        
        DataStream<String> stream = env.addSource(consumer);
        
        // Veriyi işleme
        DataStream<String> processed = stream.map(String::toUpperCase);
        
        // Kafka'ya yazma
        FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<>(
            "localhost:9092",
            "output-topic",
            new SimpleStringSchema()
        );
        
        processed.addSink(producer);
        
        env.execute("Kafka Flink Integration");
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 53 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 53: Kafka ve Storm nasıl entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Storm entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>KafkaSpout:</strong> Kafka'dan veri okumak için kullanılır.</li>
                                    <li><strong>KafkaBolt:</strong> Kafka'ya veri yazmak için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Storm Kafka Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.storm.kafka.BrokerHosts;
import org.apache.storm.kafka.SpoutConfig;
import org.apache.storm.kafka.StringScheme;
import org.apache.storm.kafka.ZkHosts;
import org.apache.storm.kafka.bolt.KafkaBolt;
import org.apache.storm.kafka.bolt.StringKeyValueScheme;
import org.apache.storm.topology.TopologyBuilder;

public class KafkaStormIntegration {
    public static void main(String[] args) throws Exception {
        BrokerHosts hosts = new ZkHosts("localhost:2181");
        
        // Kafka Spout yapılandırması
        SpoutConfig spoutConfig = new SpoutConfig(hosts, "input-topic", "/zookeeper", "storm-consumer");
        spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
        
        // Kafka Bolt yapılandırması
        KafkaBolt<String, String> kafkaBolt = new KafkaBolt<String, String>()
            .withProducerProperties(new Properties() {{
                put("bootstrap.servers", "localhost:9092");
                put("acks", "1");
                put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
                put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
            }})
            .withTopicSelector("output-topic")
            .withTupleToKafkaMapper(new FieldNameTupleToKafkaMapper<String, String>("key", "value"));
        
        // Topoloji oluşturma
        TopologyBuilder builder = new TopologyBuilder();
        builder.setSpout("kafka-spout", new KafkaSpout(spoutConfig), 1);
        builder.setBolt("upper-bolt", new UpperCaseBolt(), 1).shuffleGrouping("kafka-spout");
        builder.setBolt("kafka-bolt", kafkaBolt, 1).shuffleGrouping("upper-bolt");
        
        // Topolojiyi çalıştırma
        Config config = new Config();
        config.setDebug(true);
        
        LocalCluster cluster = new LocalCluster();
        cluster.submitTopology("kafka-storm-integration", config, builder.createTopology());
        
        Thread.sleep(10000);
        cluster.shutdown();
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 54 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 54: Kafka ve Elasticsearch nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Elasticsearch entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Elasticsearch Connector:</strong> Kafka'dan Elasticsearch'e veri aktarmak için kullanılır.</li>
                                    <li><strong>Logstash:</strong> Kafka'dan veri okuyup Elasticsearch'e yazmak için kullanılabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Elasticsearch Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "elasticsearch-sink",
  "config": {
    "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "http://localhost:9200",
    "type.name": "_doc",
    "key.ignore": "true",
    "schema.ignore": "true",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Logstash Konfigürasyonu:</p>
                                <pre class="code-block ruby mt-2"># logstash.conf
input {
  kafka {
    bootstrap_servers => "localhost:9092"
    topics => ["input-topic"]
  }
}

filter {
  # Gerekli dönüşümleri burada yapın
  mutate {
    rename => { "message" => "event_message" }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "kafka-events"
    document_type => "_doc"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 55 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 55: Kafka ve Cassandra nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Cassandra entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Cassandra Connector:</strong> Kafka'dan Cassandra'ya veri aktarmak için kullanılır.</li>
                                    <li><strong>Spark Cassandra Connector:</strong> Spark ile Kafka'dan okunan veriyi Cassandra'ya yazmak için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Cassandra Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "cassandra-sink",
  "config": {
    "connector.class": "com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connect.cassandra.contact.points": "localhost",
    "connect.cassandra.port": "9042",
    "connect.cassandra.key.space": "test_keyspace",
    "connect.cassandra.consistency.level": "ONE",
    "connect.cassandra.error.policy": "NOOP",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark Cassandra Connector Örneği:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import com.datastax.spark.connector.cql.CassandraConnector
import com.datastax.spark.connector._

val spark = SparkSession.builder()
  .appName("KafkaCassandraIntegration")
  .master("local[*]")
  .config("spark.cassandra.connection.host", "localhost")
  .config("spark.cassandra.connection.port", "9042")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING) as json")
  .select(from_json("json", "name STRING, age INT").as("data"))
  .select("data.*")

// Cassandra'ya yazma
val query = df.writeStream
  .foreachBatch { (batchDF: org.apache.spark.sql.DataFrame, batchId: Long) =>
    batchDF.write
      .format("org.apache.spark.sql.cassandra")
      .options(Map("table" -> "users", "keyspace" -> "test_keyspace"))
      .mode("append")
      .save()
  }
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 56 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 56: Kafka ve Hadoop HDFS nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Hadoop HDFS entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect HDFS Connector:</strong> Kafka'dan HDFS'e veri aktarmak için kullanılır.</li>
                                    <li><strong>Spark HDFS Connector:</strong> Spark ile Kafka'dan okunan veriyi HDFS'e yazmak için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect HDFS Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "hdfs-sink",
  "config": {
    "connector.class": "io.confluent.connect.hdfs.HdfsSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "hdfs.url": "hdfs://localhost:9000",
    "hadoop.conf.dir": "/etc/hadoop/conf",
    "flush.size": "3",
    "rotate.interval.ms": "1000",
    "logs.dir": "/kafka-data",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark HDFS Örneği:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("KafkaHdfsIntegration")
  .master("local[*]")
  .config("spark.hadoop.fs.defaultFS", "hdfs://localhost:9000")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING)")

// HDFS'e yazma
val query = df.writeStream
  .format("parquet")
  .option("path", "hdfs://localhost:9000/kafka-data")
  .option("checkpointLocation", "/tmp/checkpoint")
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 57 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 57: Kafka ve MongoDB nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve MongoDB entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect MongoDB Connector:</strong> Kafka'dan MongoDB'ye veri aktarmak için kullanılır.</li>
                                    <li><strong>Spark MongoDB Connector:</strong> Spark ile Kafka'dan okunan veriyi MongoDB'ye yazmak için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect MongoDB Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "mongodb-sink",
  "config": {
    "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.uri": "mongodb://localhost:27017/kafka_db",
    "database": "kafka_db",
    "collection": "events",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark MongoDB Örneği:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import com.mongodb.spark.config._

val spark = SparkSession.builder()
  .appName("KafkaMongoDBIntegration")
  .master("local[*]")
  .config("spark.mongodb.input.uri", "mongodb://localhost:27017/kafka_db.events")
  .config("spark.mongodb.output.uri", "mongodb://localhost:27017/kafka_db.events")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING) as json")
  .select(from_json("json", "name STRING, age INT").as("data"))
  .select("data.*")

// MongoDB'ye yazma
val query = df.writeStream
  .foreachBatch { (batchDF: org.apache.spark.sql.DataFrame, batchId: Long) =>
    batchDF.write
      .format("com.mongodb.spark.sql.DefaultSource")
      .mode("append")
      .save()
  }
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 58 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 58: Kafka ve Redis nasıl entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Redis entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Redis Connector:</strong> Kafka'dan Redis'e veri aktarmak için kullanılır.</li>
                                    <li><strong>Redis Stream:</strong> Redis'in stream veri yapısı ile Kafka arasında veri aktarımı.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Redis Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "redis-sink",
  "config": {
    "connector.class": "com.github.jcustenborder.kafka.connect.redis.RedisSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "redis.host": "localhost",
    "redis.port": "6379",
    "redis.command": "SET",
    "redis.key": "kafka-message",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Java Redis Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;
import redis.clients.jedis.Jedis;
import java.util.Collections;
import java.util.Properties;

public class KafkaRedisIntegration {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "redis-consumer");
        props.put("key.deserializer", StringDeserializer.class.getName());
        props.put("value.deserializer", StringDeserializer.class.getName());
        
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("input-topic"));
        
        Jedis jedis = new Jedis("localhost", 6379);
        
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                // Redis'e yaz
                jedis.set("kafka:" + record.offset(), record.value());
                System.out.println("Written to Redis: " + record.value());
            }
        }
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 59 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 59: Kafka ve PostgreSQL nasıl
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve PostgreSQL entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect JDBC Connector:</strong> Kafka'dan PostgreSQL'e veri aktarmak için kullanılır.</li>
                                    <li><strong>Debezium:</strong> PostgreSQL'den değişiklikleri yakalayıp Kafka'ya göndermek için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect JDBC Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "postgres-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "jdbc:postgresql://localhost:5432/kafka_db",
    "connection.user": "postgres",
    "connection.password": "password",
    "auto.create": "true",
    "auto.evolve": "true",
    "insert.mode": "insert",
    "pk.mode": "none",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Debezium PostgreSQL Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "postgres-source",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.password": "password",
    "database.dbname": "postgres",
    "database.server.name": "postgres-server",
    "plugin.name": "pgoutput"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 60 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 60: Kafka ve MySQL nasıl entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve MySQL entegrasyonu için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect JDBC Connector:</strong> Kafka'dan MySQL'e veri aktarmak için kullanılır.</li>
                                    <li><strong>Debezium:</strong> MySQL'den değişiklikleri yakalayıp Kafka'ya göndermek için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect JDBC Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "mysql-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "jdbc:mysql://localhost:3306/kafka_db",
    "connection.user": "root",
    "connection.password": "password",
    "auto.create": "true",
    "auto.evolve": "true",
    "insert.mode": "insert",
    "pk.mode": "none",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Debezium MySQL Connector Yapılandırması:</p>
                                <pre class="code-block json mt-2">{
  "name": "mysql-source",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "root",
    "database.password": "password",
    "database.server.id": "184054",
    "database.server.name": "mysql-server",
    "database.include.list": "kafka_db",
    "database.history.kafka.bootstrap.servers": "localhost:9092",
    "database.history.kafka.topic": "schema-changes.kafka_db"
  }
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka İleri Düzey Senaryolar -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Kafka İleri Düzey Senaryolar</h3>

                        <!-- Soru 61 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 61: Kafka'da CQRS (Command Query
                                Responsibility Segregation) pattern nasıl uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> CQRS pattern, yazma (command) ve okuma (query) işlemlerini ayıran bir mimari pattern'idir. Kafka ile CQRS uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Command Side:</strong> Kullanıcı eylemleri (create, update, delete) için bir topic.</li>
                                    <li><strong>Event Store:</strong> Komutları olaylara dönüştüren ve olayları bir topic'e yazan bir servis.</li>
                                    <li><strong>Query Side:</strong> Olayları dinleyen ve okuma modelini güncelleyen bir servis.</li>
                                </ul>
                                <p class="mt-2 font-medium">CQRS Mimarisi Örneği:</p>
                                <pre class="code-block java mt-2">// Command Service
public class CommandService {
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    public void createUser(CreateUserCommand command) {
        // Komutu doğrula
        // ...
        
        // Olay oluştur
        UserCreatedEvent event = new UserCreatedEvent(
            command.getUserId(),
            command.getUsername(),
            command.getEmail()
        );
        
        // Olayı Kafka'ya gönder
        kafkaTemplate.send("user-commands", event);
    }
}

// Event Processor
public class EventProcessor {
    @KafkaListener(topics = "user-commands")
    public void processUserCreatedEvent(UserCreatedEvent event) {
        // Olayı işle ve veritabanına yaz
        User user = new User(
            event.getUserId(),
            event.getUsername(),
            event.getEmail()
        );
        
        userRepository.save(user);
        
        // Okuma modelini güncelle
        UserView userView = new UserView(
            event.getUserId(),
            event.getUsername(),
            event.getEmail()
        );
        
        userViewRepository.save(userView);
    }
}

// Query Service
public class QueryService {
    public UserView getUser(String userId) {
        return userViewRepository.findById(userId);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 62 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 62: Kafka'da Event Sourcing pattern
                                nasıl uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Event Sourcing, uygulama durumunu olayların bir dizisi olarak saklayan bir pattern'idir. Kafka ile Event Sourcing uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Event Store:</strong> Olayları saklamak için bir Kafka topic'i.</li>
                                    <li><strong>Aggregate:</strong> Olayları uygulayarak mevcut durumu yeniden oluşturan bir sınıf.</li>
                                    <li><strong>Snapshot:</strong> Performansı artırmak için belirli aralıklarla durumun anlık görüntüsünü alma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Event Sourcing Örneği:</p>
                                <pre class="code-block java mt-2">// Event Interface
public interface Event {
    String getAggregateId();
    Instant getTimestamp();
}

// Aggregate Class
public class UserAggregate {
    private String userId;
    private String username;
    private String email;
    private List<Event> events = new ArrayList<>();
    
    public static UserAggregate create(String userId, String username, String email) {
        UserAggregate aggregate = new UserAggregate();
        aggregate.apply(new UserCreatedEvent(userId, username, email));
        return aggregate;
    }
    
    public void updateEmail(String email) {
        apply(new UserEmailUpdatedEvent(userId, email));
    }
    
    private void apply(Event event) {
        // Olayı uygula
        if (event instanceof UserCreatedEvent) {
            UserCreatedEvent e = (UserCreatedEvent) event;
            this.userId = e.getUserId();
            this.username = e.getUsername();
            this.email = e.getEmail();
        } else if (event instanceof UserEmailUpdatedEvent) {
            UserEmailUpdatedEvent e = (UserEmailUpdatedEvent) event;
            this.email = e.getEmail();
        }
        
        // Olayı listeye ekle
        events.add(event);
    }
    
    public List<Event> getUncommittedEvents() {
        return new ArrayList<>(events);
    }
    
    public void markEventsAsCommitted() {
        events.clear();
    }
}

// Event Store
public class EventStore {
    private final KafkaTemplate<String, Event> kafkaTemplate;
    
    public void saveEvents(String aggregateId, List<Event> events) {
        events.forEach(event -> {
            kafkaTemplate.send("user-events", aggregateId, event);
        });
    }
    
    public List<Event> getEvents(String aggregateId) {
        // Kafka'dan olayları oku
        // ...
        return events;
    }
}

// Aggregate Repository
public class AggregateRepository {
    private final EventStore eventStore;
    
    public void save(UserAggregate aggregate) {
        eventStore.saveEvents(aggregate.getUserId(), aggregate.getUncommittedEvents());
        aggregate.markEventsAsCommitted();
    }
    
    public UserAggregate findById(String userId) {
        List<Event> events = eventStore.getEvents(userId);
        UserAggregate aggregate = new UserAggregate();
        
        // Olayları sırayla uygula
        events.forEach(aggregate::apply);
        
        return aggregate;
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 63 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 63: Kafka'da Saga pattern nasıl
                                uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Saga pattern, dağıtık sistemlerde transaction yönetimi için kullanılan bir pattern'idir. Kafka ile Saga uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Orchestrator-Based Saga:</strong> Merkezi bir orchestrator tüm adımları yönetir.</li>
                                    <li><strong>Choreography-Based Saga:</strong> Her servis kendi adımını tamamlar ve bir sonraki adımı tetikler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Choreography-Based Saga Örneği:</p>
                                <pre class="code-block java mt-2">// Order Service
@Service
public class OrderService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Transactional
    public Order createOrder(OrderRequest orderRequest) {
        // Siparişi oluştur
        Order order = new Order(orderRequest);
        orderRepository.save(order);
        
        // OrderCreatedEvent gönder
        OrderCreatedEvent event = new OrderCreatedEvent(
            order.getId(),
            order.getCustomerId(),
            order.getAmount()
        );
        
        kafkaTemplate.send("orders", event);
        
        return order;
    }
    
    @KafkaListener(topics = "payment-completed")
    public void handlePaymentCompleted(PaymentCompletedEvent event) {
        // Ödeme tamamlandı, siparişi güncelle
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.PAID);
        orderRepository.save(order);
        
        // OrderCompletedEvent gönder
        OrderCompletedEvent orderEvent = new OrderCompletedEvent(order.getId());
        kafkaTemplate.send("orders", orderEvent);
    }
    
    @KafkaListener(topics = "payment-failed")
    public void handlePaymentFailed(PaymentFailedEvent event) {
        // Ödeme başarısız, siparişi iptal et
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.CANCELLED);
        orderRepository.save(order);
        
        // OrderCancelledEvent gönder
        OrderCancelledEvent orderEvent = new OrderCancelledEvent(order.getId());
        kafkaTemplate.send("orders", orderEvent);
    }
}

// Payment Service
@Service
public class PaymentService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @KafkaListener(topics = "orders")
    public void handleOrderCreated(OrderCreatedEvent event) {
        try {
            // Ödeme işlemini yap
            Payment payment = paymentService.processPayment(
                event.getOrderId(),
                event.getAmount()
            );
            
            // PaymentCompletedEvent gönder
            PaymentCompletedEvent paymentEvent = new PaymentCompletedEvent(
                payment.getOrderId(),
                payment.getId()
            );
            
            kafkaTemplate.send("payments", paymentEvent);
        } catch (PaymentException e) {
            // PaymentFailedEvent gönder
            PaymentFailedEvent paymentEvent = new PaymentFailedEvent(
                event.getOrderId(),
                e.getMessage()
            );
            
            kafkaTemplate.send("payments", paymentEvent);
        }
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 64 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 64: Kafka'da Dead Letter Queue (DLQ)
                                nasıl uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Dead Letter Queue, işlenemeyen mesajları saklamak için kullanılan bir pattern'idir. Kafka ile DLQ uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Hata Yakalama:</strong> Mesaj işlenirken oluşan hataları yakala.</li>
                                    <li><strong>DLQ Topic:</strong> İşlenemeyen mesajları göndermek için özel bir topic.</li>
                                    <li><strong>Retry Mekanizması:</strong> Mesajları yeniden denemek için bir mekanizma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Dead Letter Queue Örneği:</p>
                                <pre class="code-block java mt-2">@Service
public class MessageProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Value("${kafka.topic.dlq}")
    private String dlqTopic;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        try {
            // Mesajı işle
            process(record.value());
            
            // Başarılı ise offset'i commit et
            // ...
        } catch (Exception e) {
            // Hata durumunda log yaz
            logger.error("Error processing message: " + record.value(), e);
            
            // Mesajı DLQ'ya gönder
            sendToDlq(record, e);
        }
    }
    
    private void sendToDlq(ConsumerRecord<String, String> record, Exception e) {
        // Orijinal mesaj bilgilerini ve hatayı içeren bir DLQ mesajı oluştur
        DlqMessage dlqMessage = new DlqMessage(
            record.value(),
            record.topic(),
            record.partition(),
            record.offset(),
            e.getMessage(),
            Instant.now()
        );
        
        // DLQ topic'ine gönder
        kafkaTemplate.send(dlqTopic, dlqMessage);
    }
}

// Retry Mekanizması
@Service
public class RetryableMessageProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Value("${kafka.topic.retry}")
    private String retryTopic;
    
    @Value("${kafka.topic.dlq}")
    private String dlqTopic;
    
    @KafkaListener(topics = "input-topic")
    public void processWithRetry(ConsumerRecord<String, String> record) {
        int maxRetries = 3;
        int retryCount = 0;
        boolean success = false;
        
        while (retryCount < maxRetries && !success) {
            try {
                // Mesajı işle
                process(record.value());
                success = true;
            } catch (Exception e) {
                retryCount++;
                
                if (retryCount >= maxRetries) {
                    // Maksimum deneme sayısına ulaşıldı, DLQ'ya gönder
                    sendToDlq(record, e);
                } else {
                    // Retry topic'ine gönder
                    sendToRetryTopic(record, retryCount, e);
                    
                    // Bir sonraki deneme için bekle
                    try {
                        Thread.sleep(1000 * retryCount);
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                    }
                }
            }
        }
    }
    
    private void sendToRetryTopic(ConsumerRecord<String, String> record, int retryCount, Exception e) {
        RetryMessage retryMessage = new RetryMessage(
            record.value(),
            record.topic(),
            record.partition(),
            record.offset(),
            retryCount,
            e.getMessage(),
            Instant.now()
        );
        
        kafkaTemplate.send(retryTopic, retryMessage);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 65 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 65: Kafka'da idempotent consumer nasıl
                                uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Idempotent consumer, aynı mesajın birden fazla kez işlenmesini önleyen bir pattern'idir. Kafka ile idempotent consumer uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Mesaj ID'si:</strong> Her mesaj için benzersiz bir ID.</li>
                                    <li><strong>İşlenmiş ID'ler:</strong> Zaten işlenmiş mesaj ID'lerini saklayan bir mekanizma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Consumer Örneği:</p>
                                <pre class="code-block java mt-2">@Service
public class IdempotentConsumer {
    @Autowired
    private ProcessedMessageRepository processedMessageRepository;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Mesaj ID'sini oluştur
        String messageId = record.key() + "-" + record.offset();
        
        // Mesajın daha önce işlenip işlenmediğini kontrol et
        if (processedMessageRepository.existsById(messageId)) {
            logger.info("Message already processed: " + messageId);
            return;
        }
        
        try {
            // Mesajı işle
            process(record.value());
            
            // Mesajı işlenmiş olarak işaretle
            ProcessedMessage processedMessage = new ProcessedMessage(
                messageId,
                record.topic(),
                record.partition(),
                record.offset(),
                Instant.now()
            );
            
            processedMessageRepository.save(processedMessage);
        } catch (Exception e) {
            // Hata durumunda log yaz ve işlemi geri al
            logger.error("Error processing message: " + messageId, e);
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // Mesajı işle
        // ...
    }
}

// Redis ile Idempotent Consumer
@Service
public class RedisIdempotentConsumer {
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Mesaj ID'sini oluştur
        String messageId = record.key() + "-" + record.offset();
        
        // Redis'te mesaj ID'sini kontrol et
        Boolean isProcessed = redisTemplate.hasKey(messageId);
        
        if (Boolean.TRUE.equals(isProcessed)) {
            logger.info("Message already processed: " + messageId);
            return;
        }
        
        try {
            // Mesajı işle
            process(record.value());
            
            // Mesajı Redis'te işlenmiş olarak işaretle
            redisTemplate.opsForValue().set(messageId, "PROCESSED");
            
            // Mesajın ne kadar süre kalacağını ayarla (örneğin 7 gün)
            redisTemplate.expire(messageId, 7, TimeUnit.DAYS);
        } catch (Exception e) {
            // Hata durumunda log yaz ve işlemi geri al
            logger.error("Error processing message: " + messageId, e);
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // Mesajı işle
        // ...
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 66 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 66: Kafka'da backpressure nasıl
                                yönetilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Backpressure, veri üreticisinin hızını tüketicinin işleyebileceği hızla sınırlayan bir mekanizmadır. Kafka'da backpressure yönetmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer Lag İzleme:</strong> Consumer'ın geride kalmasını izleme.</li>
                                    <li><strong>Dynamic Throttling:</strong> Producer hızını dinamik olarak ayarlama.</li>
                                    <li><strong>Buffer Boyutunu Ayarlama:</strong> Producer ve consumer buffer boyutlarını ayarlama.</li>
                                </ul>
                                <p class="mt-2 font-medium">Backpressure Yönetimi Örneği:</p>
                                <pre class="code-block java mt-2">@Service
public class BackpressureManager {
    @Autowired
    private KafkaAdmin kafkaAdmin;
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    private final double maxLagThreshold = 1000.0; // Maksimum lag eşiği
    private final double minLagThreshold = 100.0;  // Minimum lag eşiği
    
    @Scheduled(fixedRate = 5000) // Her 5 saniyede bir kontrol et
    public void manageBackpressure() {
        // Tüm consumer grupları için lag değerlerini al
        Map<String, Map<TopicPartition, OffsetAndMetadata>> consumerGroups = getConsumerGroupOffsets();
        
        for (Map.Entry<String, Map<TopicPartition, OffsetAndMetadata>> entry : consumerGroups.entrySet()) {
            String groupId = entry.getKey();
            Map<TopicPartition, OffsetAndMetadata> offsets = entry.getValue();
            
            // Her topic için lag hesapla
            Map<String, Long> topicLags = calculateTopicLags(offsets);
            
            for (Map.Entry<String, Long> topicEntry : topicLags.entrySet()) {
                String topic = topicEntry.getKey();
                Long lag = topicEntry.getValue();
                
                // Lag eşiğine göre throttling uygula
                if (lag > maxLagThreshold) {
                    // Producer hızını düşür
                    throttleProducer(topic, 0.5); // %50 hızında
                    logger.info("Throttling producer for topic: " + topic + " due to high lag: " + lag);
                } else if (lag < minLagThreshold) {
                    // Producer hızını artır
                    throttleProducer(topic, 1.0); // Tam hız
                    logger.info("Resuming producer for topic: " + topic + " as lag is normal: " + lag);
                }
            }
        }
    }
    
    private Map<String, Long> calculateTopicLags(Map<TopicPartition, OffsetAndMetadata> offsets) {
        Map<String, Long> topicLags = new HashMap<>();
        
        // Her topic için lag hesapla
        for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {
            TopicPartition partition = entry.getKey();
            OffsetAndMetadata offsetMetadata = entry.getValue();
            
            // Topic son offset'ini al
            long endOffset = getEndOffset(partition);
            
            // Lag hesapla
            long lag = endOffset - offsetMetadata.offset();
            
            // Topic lag'ini güncelle
            topicLags.merge(partition.topic(), lag, Long::sum);
        }
        
        return topicLags;
    }
    
    private void throttleProducer(String topic, double throttleFactor) {
        // Producer'ı kısıtla
        // Bu, producer'ın linger.ms ve batch.size ayarlarını değiştirerek yapılabilir
        // veya özel bir throttling mekanizması uygulanabilir
        
        // Örnek: linger.ms değerini artır
        updateProducerConfig(topic, "linger.ms", (int) (10 / throttleFactor));
        
        // Örnek: batch.size değerini artır
        updateProducerConfig(topic, "batch.size", (int) (16384 / throttleFactor));
    }
    
    private void updateProducerConfig(String topic, String configKey, int configValue) {
        // Producer config'ini güncelle
        // Bu, Kafka Admin API veya özel bir config yönetimi ile yapılabilir
        // ...
        
        logger.info("Updated producer config for topic: " + topic + ", " + configKey + "=" + configValue);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 67 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 67: Kafka'da exactly-once processing nasıl
                                sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Exactly-once processing, her mesajın tam olarak bir kez işlendiğini garanti eden bir özelliktir. Kafka'da exactly-once processing sağlamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> Aynı mesajın birden fazla kez gönderilmesini önler.</li>
                                    <li><strong>Transactions:</strong> Birden fazla partition'a atomik yazma işlemleri sağlar.</li>
                                    <li><strong>Read Committed Isolation Level:</strong> Sadece commit edilmiş mesajları okur.</li>
                                    <li><strong>Consumer Position Commit:</strong> Mesaj işlendikten sonra offset'leri commit eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Exactly-Once Processing Örneği:</p>
                                <pre class="code-block java mt-2">@Service
public class ExactlyOnceProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @KafkaListener(topics = "input-topic")
    @Transactional
    public void processMessage(ConsumerRecord<String, String> record) {
        try {
            // Mesajı işle
            String result = process(record.value());
            
            // Sonucu output topic'ine gönder
            kafkaTemplate.send(new ProducerRecord<>("output-topic", record.key(), result));
            
            // İşlem başarılı, transaction commit edilecek
        } catch (Exception e) {
            // Hata durumunda transaction rollback edilecek
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private String process(String message) {
        // Mesajı işle ve sonuç döndür
        return "PROCESSED: " + message;
    }
}

// Transactional Producer Örneği
@Service
public class TransactionalProducerService {
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @PostConstruct
    public void init() {
        // Transactional producer'ı başlat
        kafkaTemplate.setTransactionIdPrefix("tx-");
    }
    
    public void sendInTransaction(String topic, String key, String value) {
        // Transaction içinde mesaj gönder
        kafkaTemplate.executeInTransaction(template -> {
            template.send(new ProducerRecord<>(topic, key, value));
            return true;
        });
    }
}

// Exactly-Once Consumer Örneği
@Service
public class ExactlyOnceConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record, Acknowledgment acknowledgment) {
        try {
            // Mesajı işle
            process(record.value());
            
            // İşlem başarılı, acknowledgment'ı onayla
            acknowledgment.acknowledge();
        } catch (Exception e) {
            // Hata durumunda acknowledgment'ı reddet
            acknowledgment.nack(1000); // 1 saniye sonra tekrar dene
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // Mesajı işle
        // ...
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 68 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 68: Kafka'da schema evrimi (schema
                                evolution) nasıl yönetilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Schema evrimi, veri şemalarının zamanla değişmesini yönetme işlemidir. Kafka'da schema evrimi yönetmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Schema Registry:</strong> Şemaları merkezi olarak yönetir.</li>
                                    <li><strong>Uyumluluk Kuralları:</strong> Şema değişikliklerinin uyumluluğunu kontrol eder.</li>
                                    <li><strong>Avro, Protobuf, JSON Schema:</strong> Schema evrimini destekleyen formatlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Schema Evrimi Örneği:</p>
                                <pre class="code-block java mt-2">// İlk schema
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "email", "type": "string"}
  ]
}

// Yeni schema (yeni alan eklenmiş)
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "email", "type": "string"},
    {"name": "age", "type": ["null", "int"], "default": null}
  ]
}

// Java ile Schema Registry kullanımı
public class SchemaEvolutionExample {
    public static void main(String[] args) throws IOException, RestClientException {
        // Schema Registry istemcisi oluştur
        SchemaRegistryClient client = new CachedSchemaRegistryClient("http://localhost:8081", 100);
        
        // Schema'yı kaydet
        String schemaJson = "{\n" +
            "  \"type\": \"record\",\n" +
            "  \"name\": \"User\",\n" +
            "  \"fields\": [\n" +
            "    {\"name\": \"id\", \"type\": \"string\"},\n" +
            "    {\"name\": \"name\", \"type\": \"string\"},\n" +
            "    {\"name\": \"email\", \"type\": \"string\"}\n" +
            "  ]\n" +
            "}";
        
        Schema schema = new Schema.Parser().parse(schemaJson);
        SchemaMetadata metadata = client.register("users-value", schema);
        
        System.out.println("Schema registered with id: " + metadata.getId());
        
        // Schema'yı al
        Schema retrievedSchema = client.getById(metadata.getId());
        System.out.println("Retrieved schema: " + retrievedSchema.toString());
        
        // Yeni schema'yı kaydet (evrim)
        String newSchemaJson = "{\n" +
            "  \"type\": \"record\",\n" +
            "  \"name\": \"User\",\n" +
            "  \"fields\": [\n" +
            "    {\"name\": \"id\", \"type\": \"string\"},\n" +
            "    {\"name\": \"name\", \"type\": \"string\"},\n" +
            "    {\"name\": \"email\", \"type\": \"string\"},\n" +
            "    {\"name\": \"age\", \"type\": [\"null\", \"int\"], \"default\": null}\n" +
            "  ]\n" +
            "}";
        
        Schema newSchema = new Schema.Parser().parse(newSchemaJson);
        SchemaMetadata newMetadata = client.register("users-value", newSchema);
        
        System.out.println("New schema registered with id: " + newMetadata.getId());
        
        // Uyumluluk kontrolü
        boolean isCompatible = client.testCompatibility("users-value", newSchema);
        System.out.println("Is new schema compatible? " + isCompatible);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 69 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 69: Kafka'da multi-tenancy nasıl
                                uygulanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Multi-tenancy, tek bir Kafka kümesinde birden fazla kiracı (tenant) için veri ayırma sağlayan bir yaklaşımdır. Kafka'da multi-tenancy uygulamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Tenant Bazlı Topic'ler:</strong> Her tenant için ayrı topic'ler.</li>
                                    <li><strong>Tenant Bazlı Partition'lar:</strong> Her tenant için ayrı partition'lar.</li>
                                    <li><strong>Tenant Bazlı Consumer Grupları:</strong> Her tenant için ayrı consumer grupları.</li>
                                    <li><strong>Tenant Bazlı Yetkilendirme:</strong> Her tenant için ayrı ACL'ler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Multi-Tenancy Örneği:</p>
                                <pre class="code-block java mt-2">// Tenant bazlı topic isimlendirme
public class TopicNamingStrategy {
    public static String getTenantTopic(String tenantId, String baseTopic) {
        return tenantId + "-" + baseTopic;
    }
}

// Tenant bazlı producer
@Service
public class TenantAwareProducer {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public void sendToTenant(String tenantId, String topic, String key, Object value) {
        String tenantTopic = TopicNamingStrategy.getTenantTopic(tenantId, topic);
        
        // Tenant bilgisini header'a ekle
        ProducerRecord<String, Object> record = new ProducerRecord<>(
            tenantTopic, key, value
        );
        
        record.headers().add("tenant-id", tenantId.getBytes());
        
        kafkaTemplate.send(record);
    }
}

// Tenant bazlı consumer
@Service
public class TenantAwareConsumer {
    @KafkaListener(topics = "#{tenantAwareTopicResolver.getTopics()}")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Tenant ID'sini header'dan al
        String tenantId = getTenantId(record);
        
        // Tenant'a özgü iş mantığını uygula
        processForTenant(tenantId, record.value());
    }
    
    private String getTenantId(ConsumerRecord<String, String> record) {
        // Topic adından tenant ID'sini çıkar
        String topic = record.topic();
        return topic.substring(0, topic.indexOf('-'));
    }
    
    private void processForTenant(String tenantId, String message) {
        // Tenant'a özgü iş mantığı
        // ...
    }
}

// Tenant bazlı yetkilendirme
@Service
public class TenantAwareAuthorizer {
    public boolean authorize(String tenantId, String resource, String operation) {
        // Tenant'ın kaynağa erişim yetkisi olup olmadığını kontrol et
        // ...
        return true;
    }
}

// Tenant bazlı konfigürasyon
@Configuration
public class TenantAwareConfig {
    @Bean
    public KafkaAdmin kafkaAdmin() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        return new KafkaAdmin(configs);
    }
    
    @Bean
    public NewTopic createTenantTopics() {
        // Tenant'lar için topic'leri oluştur
        return TopicBuilder.name("tenant1-orders")
                .partitions(3)
                .replicas(1)
                .build();
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 70 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 70: Kafka'da veri bütünlüğü (data
                                integrity) nasıl sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Veri bütünlüğü, Kafka'da verinin doğru ve tutarlı kalmasını sağlayan önlemlerdir. Kafka'da veri bütünlüğü sağlamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Checksum:</strong> Veriye checksum ekleyerek bozulmayı tespit etme.</li>
                                    <li><strong>Validation:</strong> Veriyi işlemeden önce doğrulama.</li>
                                    <li><strong>Idempotent Operations:</strong> Aynı işlemin birden fazla kez uygulanmasını önleme.</li>
                                    <li><strong>Transactions:</strong> Birden fazla işlemi atomik olarak gerçekleştirme.</li>
                                </ul>
                                <p class="mt-2 font-medium">Veri Bütünlüğü Örneği:</p>
                                <pre class="code-block java mt-2">// Checksum ile veri bütünlüğü
public class DataIntegrityUtils {
    public static String calculateChecksum(String data) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(data.getBytes(StandardCharsets.UTF_8));
            return Hex.encodeHexString(hash);
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("Failed to calculate checksum", e);
        }
    }
    
    public static boolean verifyChecksum(String data, String checksum) {
        String calculatedChecksum = calculateChecksum(data);
        return calculatedChecksum.equals(checksum);
    }
}

// Producer ile checksum gönderme
@Service
public class ChecksumProducer {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public void sendWithChecksum(String topic, String key, String value) {
        // Veri ve checksum'ı içeren bir nesne oluştur
        DataWithChecksum dataWithChecksum = new DataWithChecksum(
            value,
            DataIntegrityUtils.calculateChecksum(value)
        );
        
        // Mesajı gönder
        kafkaTemplate.send(new ProducerRecord<>(topic, key, dataWithChecksum));
    }
}

// Consumer ile checksum doğrulama
@Service
public class ChecksumConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, DataWithChecksum> record) {
        DataWithChecksum dataWithChecksum = record.value();
        
        // Checksum'ı doğrula
        if (!DataIntegrityUtils.verifyChecksum(
            dataWithChecksum.getData(),
            dataWithChecksum.getChecksum()
        )) {
            throw new DataIntegrityException("Checksum verification failed");
        }
        
        // Veriyi işle
        process(dataWithChecksum.getData());
    }
    
    private void process(String data) {
        // Veriyi işle
        // ...
    }
}

// Validation ile veri bütünlüğü
@Service
public class ValidationConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        String data = record.value();
        
        // Veriyi doğrula
        ValidationResult validationResult = validate(data);
        
        if (!validationResult.isValid()) {
            // Geçersiz veriyi DLQ'ya gönder
            sendToDlq(record, validationResult.getErrorMessage());
            return;
        }
        
        // Geçerli veriyi işle
        process(data);
    }
    
    private ValidationResult validate(String data) {
        // Veriyi doğrula
        if (data == null || data.isEmpty()) {
            return ValidationResult.invalid("Data is null or empty");
        }
        
        if (data.length() > 1000) {
            return ValidationResult.invalid("Data is too long");
        }
        
        return ValidationResult.valid();
    }
}

// Transaction ile veri bütünlüğü
@Service
public class TransactionalProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Autowired
    private DatabaseService databaseService;
    
    @Transactional
    public void processInTransaction(String input) {
        // Veriyi işle
        String result = process(input);
        
        // Veritabanına yaz
        databaseService.save(result);
        
        // Output topic'ine gönder
        kafkaTemplate.send(new ProducerRecord<>("output-topic", result));
        
        // İşlem başarılı, transaction commit edilecek
    }
    
    private String process(String input) {
        // Veriyi işle ve sonuç döndür
        return "PROCESSED: " + input;
    }
}</pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- RabbitMQ Soruları -->
        <section id="rabbitmq" class="mb-16">
            <div class="bg-white rounded-lg shadow-md p-6 mb-8">
                <div class="flex items-center mb-6">
                    <div class="rabbit-color p-3 rounded-full mr-4">
                        <i class="fas fa-envelope text-white text-xl"></i>
                    </div>
                    <h2 class="text-2xl font-bold text-gray-800">RabbitMQ Mülakat Soruları</h2>
                </div>
                <p class="text-gray-600 mb-6">Bu dokümanda RabbitMQ mülakatlarında en çok sorulan konular soru-cevap mantığıyla açıklanmış ve örnek kodlar eklenmiştir.</p>

                <div class="space-y-6">
                    <!-- Temel RabbitMQ Kavramları -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 Temel RabbitMQ Kavramları</h3>

                        <!-- Soru 1 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 1: RabbitMQ nedir? Ne işe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ, açık kaynaklı bir mesajlaşma kuyruğu sistemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>AMQP (Advanced Message Queuing Protocol) standardını uygular.</li>
                                    <li>Farklı uygulamalar arasında asenkron iletişim sağlar.</li>
                                    <li>Yüksek performanslı, güvenilir ve ölçeklenebilir bir mesajlaşma çözümüdür.</li>
                                </ul>
                                <p class="mt-2 font-medium">RabbitMQ Sunucusunu Başlatma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmq-server</pre>
                            </div>
                        </div>

                        <!-- Soru 2 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 2: RabbitMQ'da Exchange nedir?
                                Türleri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Exchange, gelen mesajları belirli kurallara göre kuyruklara yönlendiren bir bileşendir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Direct Exchange:</strong> Mesajı routing key'e tam olarak eşleşen kuyruklara yönlendirir.</li>
                                    <li><strong>Topic Exchange:</strong> Mesajı routing key'inin bir desenine (pattern) göre kuyruklara yönlendirir.</li>
                                    <li><strong>Fanout Exchange:</strong> Mesajı bağlı tüm kuyruklara yayınlar.</li>
                                    <li><strong>Headers Exchange:</strong> Mesajı header'lara göre kuyruklara yönlendirir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Direct Exchange Oluşturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare exchange name=direct-exchange type=direct</pre>
                            </div>
                        </div>

                        <!-- Soru 3 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 3: RabbitMQ'da Queue nedir?
                                Türleri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Queue, mesajların depolandığı ve tüketiciye ulaştırıldığı bir yapıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Classic Queue:</strong> Standart kuyruk türü.</li>
                                    <li><strong>Quorum Queue:</strong> Yüksek erişilebilirlik ve veri güvenliği için kullanılan kuyruk türü.</li>
                                    <li><strong>Stream Queue:</strong> Log tabanlı, yüksek performanslı kuyruk türü.</li>
                                </ul>
                                <p class="mt-2 font-medium">Queue Oluşturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare queue name=my-queue</pre>
                            </div>
                        </div>

                        <!-- Soru 4 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 4: RabbitMQ'da Binding nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Binding, bir exchange ile bir kuyruk arasındaki ilişkiyi tanımlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Exchange'ten kuyruğa mesajların nasıl yönlendirileceğini belirler.</li>
                                    <li>Direct ve Topic exchange'lerde routing key veya binding key kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Binding Oluşturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare binding source=direct-exchange destination=my-queue routing_key=my-key</pre>
                            </div>
                        </div>

                        <!-- Soru 5 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 5: RabbitMQ'da Producer ve Consumer
                                arasındaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Producer (Publisher):</strong> RabbitMQ'ya mesaj gönderen uygulamadır.</li>
                                    <li><strong>Consumer:</strong> RabbitMQ'dan mesaj alan uygulamadır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Java Producer Örneği:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
try (Connection connection = factory.newConnection();
     Channel channel = connection.createChannel()) {
    
    channel.exchangeDeclare("direct-exchange", "direct");
    
    String message = "Hello, RabbitMQ!";
    channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());
    System.out.println(" [x] Sent '" + message + "'");
}</pre>
                                <p class="mt-2 font-medium">Java Consumer Örneği:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
try (Connection connection = factory.newConnection();
     Channel channel = connection.createChannel()) {
    
    channel.queueDeclare("my-queue", false, false, false, null);
    channel.queueBind("my-queue", "direct-exchange", "my-key");
    
    DeliverCallback deliverCallback = (consumerTag, delivery) -> {
        String message = new String(delivery.getBody(), "UTF-8");
        System.out.println(" [x] Received '" + message + "'");
    };
    channel.basicConsume("my-queue", true, deliverCallback, consumerTag -> {});
}</pre>
                            </div>
                        </div>

                        <!-- Soru 6 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 6: RabbitMQ'da Routing Key nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Routing Key, bir mesajın hangi kuyruğa yönlendirileceğini belirten bir etikettir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Direct ve Topic exchange'lerde kullanılır.</li>
                                    <li>Direct exchange'te tam eşleşme, Topic exchange'te desen eşleşmesi sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Routing Key ile Mesaj Gönderme:</p>
                                <pre class="code-block java mt-2">String routingKey = "user.created";
channel.basicPublish("topic-exchange", routingKey, null, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 7 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 7: RabbitMQ'da Virtual Host nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Virtual Host, RabbitMQ sunucusu içindeki mantıksal bir bölümdür.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Farklı uygulamalar için izolasyon sağlar.</li>
                                    <li>Her virtual host kendi exchange'lerine, kuyruklarına ve kullanıcılarına sahiptir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Virtual Host Oluşturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl add_vhost my-vhost</pre>
                                <p class="mt-2 font-medium">Virtual Host'a Kullanıcı Ekleme:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_permissions -p my-vhost my-user ".*" ".*" ".*"</pre>
                            </div>
                        </div>

                        <!-- Soru 8 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 8: RabbitMQ'da Connection ve Channel
                                arasındaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Connection:</strong> Uygulama ile RabbitMQ sunucusu arasındaki TCP bağlantısıdır.</li>
                                    <li><strong>Channel:</strong> Bir connection üzerinden açılan sanal bir bağlantıdır.</li>
                                </ul>
                                <p>Her connection birden fazla channel içerebilir. Channel'lar, aynı TCP bağlantısı üzerinden birden fazla işlemi paralel olarak gerçekleştirmek için kullanılır.</p>
                            </div>
                        </div>

                        <!-- Soru 9 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 9: RabbitMQ'da Message Durability
                                (Kalıcılık) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Message Durability, mesajların RabbitMQ sunucusu yeniden başlatıldığında bile kaybolmamasını sağlayan bir özelliktir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Persistent Messages:</strong> Disk üzerinde saklanan mesajlardır.</li>
                                    <li><strong>Transient Messages:</strong> Bellekte saklanan ve sunucu yeniden başlatıldığında kaybolan mesajlardır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kalıcı Mesaj Gönderme:</p>
                                <pre class="code-block java mt-2">channel.basicPublish("direct-exchange", "my-key", 
                     MessageProperties.PERSISTENT_TEXT_PLAIN, 
                     message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 10 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 10: RabbitMQ'da Acknowledgment
                                (Onay) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Acknowledgment, bir mesajın başarıyla işlendiğini RabbitMQ'ya bildiren mekanizmadır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Automatic Acknowledgment:</strong> Mesaj tüketiciye ulaştığında otomatik olarak onaylanır.</li>
                                    <li><strong>Manual Acknowledgment:</strong> Tüketici mesajı işledikten sonra manuel olarak onaylar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Manual Acknowledgment Örneği:</p>
                                <pre class="code-block java mt-2">DeliverCallback deliverCallback = (consumerTag, delivery) -> {
    String message = new String(delivery.getBody(), "UTF-8");
    System.out.println(" [x] Received '" + message + "'");
    
    // Mesajı işle
    processMessage(message);
    
    // Onayla
    channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
};
channel.basicConsume("my-queue", false, deliverCallback, consumerTag -> {});</pre>
                            </div>
                        </div>
                    </div>

                    <!-- RabbitMQ İleri Düzey Konular -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 RabbitMQ İleri Düzey Konular</h3>

                        <!-- Soru 11 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 11: RabbitMQ'da Prefetch Count
                                nedir? Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Prefetch Count, bir tüketiciye aynı anda gönderilebilecek maksimum mesaj sayısıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Tüketici performansını optimize etmek için kullanılır.</li>
                                    <li>Düşük değerler, mesajların daha eşit dağıtılmasını sağlar.</li>
                                    <li>Yüksek değerler, daha yüksek verimlilik sağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prefetch Count Ayarlama:</p>
                                <pre class="code-block java mt-2">channel.basicQos(10); // Her seferinde en fazla 10 mesaj gönder</pre>
                            </div>
                        </div>

                        <!-- Soru 12 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 12: RabbitMQ'da Dead Letter Exchange (DLX)
                                nedir? Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Dead Letter Exchange, işlenemeyen veya reddedilen mesajların yönlendirildiği bir exchange'tir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Mesajlar süresi dolduğunda, kuyruk dolu olduğunda veya reddedildiğinde DLX'e gönderilir.</li>
                                    <li>İşlenemeyen mesajları analiz etmek ve yeniden işlemek için kullanılır.</li>
                                </ul>
                                <p class="mt-2 font-medium">DLX Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-dead-letter-exchange", "dlx-exchange");
args.put("x-dead-letter-routing-key", "dlx-key");

channel.queueDeclare("my-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 13 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 13: RabbitMQ'da Message TTL (Time-To-Live)
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Message TTL, bir mesajın kuyrukta ne kadar süre kalacağını belirten bir süre sınırlamasıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Süre dolduğunda mesaj kuyruktan kaldırılır veya DLX'e gönderilir.</li>
                                    <li>Kuyruk seviyesinde veya mesaj seviyesinde ayarlanabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kuyruk TTL Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-message-ttl", 60000); // 60 saniye

channel.queueDeclare("my-queue", false, false, false, args);</pre>
                                <p class="mt-2 font-medium">Mesaj TTL Ayarlama:</p>
                                <pre class="code-block java mt-2">AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
    .expiration("60000") // 60 saniye
    .build();

channel.basicPublish("direct-exchange", "my-key", properties, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 14 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 14: RabbitMQ'da Publisher Confirms
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Publisher Confirms, bir mesajın RabbitMQ sunucusu tarafından alındığını onaylayan bir mekanizmadır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Mesajların kaybolmamasını sağlar.</li>
                                    <li>Asenkron veya senkron olarak kullanılabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Publisher Confirms Örneği:</p>
                                <pre class="code-block java mt-2">channel.confirmSelect();

// Senkron onay
channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());
channel.waitForConfirmsOrDie(5000); // 5 saniye bekle

// Asenkron onay
channel.addConfirmListener((deliveryTag, multiple) -> {
    System.out.println("Message confirmed with tag: " + deliveryTag);
}, (deliveryTag, multiple) -> {
    System.out.println("Message not confirmed with tag: " + deliveryTag);
});

channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 15 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 15: RabbitMQ'da Alternate Exchange nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Alternate Exchange, bir exchange'e gönderilen mesajların herhangi bir kuyruğa yönlendirilememesi durumunda yönlendirildiği bir exchange'tir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Yanlış routing key ile gönderilen mesajları yakalamak için kullanılır.</li>
                                    <li>Exchange oluşturulurken ayarlanır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Alternate Exchange Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("alternate-exchange", "alternate-exchange");

channel.exchangeDeclare("main-exchange", "direct", true, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 16 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 16: RabbitMQ'da Priority Queue nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Priority Queue, mesajların önceliklerine göre işlendiği bir kuyruk türüdür.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Yüksek öncelikli mesajlar düşük öncelikli mesajlardan önce işlenir.</li>
                                    <li>Kuyruk oluşturulurken maksimum öncelik seviyesi belirlenir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Priority Queue Oluşturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-max-priority", 10); // Maksimum öncelik seviyesi

channel.queueDeclare("priority-queue", false, false, false, args);</pre>
                                <p class="mt-2 font-medium">Öncelikli Mesaj Gönderme:</p>
                                <pre class="code-block java mt-2">AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
    .priority(5) // 1-10 arası öncelik
    .build();

channel.basicPublish("direct-exchange", "my-key", properties, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 17 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 17: RabbitMQ'da Lazy Queues nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Lazy Queues, mesajları disk üzerinde saklayarak bellek kullanımını optimize eden kuyruk türüdür.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Büyük miktarda mesajı saklamak için kullanılır.</li>
                                    <li>Mesajlar tüketiciye gönderilene kadar diskte kalır.</li>
                                </ul>
                                <p class="mt-2 font-medium">Lazy Queue Oluşturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");

channel.queueDeclare("lazy-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 18 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 18: RabbitMQ'da Quorum Queues nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Quorum Queues, yüksek erişilebilirlik ve veri güvenliği için tasarlanmış bir kuyruk türüdür.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Raft konsensus algoritmasını kullanır.</li>
                                    <li>Çoğunluk (quorum) ile karar verir.</li>
                                    <li>Veri kaybını önlemek için en az 3 node gerektirir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Quorum Queue Oluşturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-type", "quorum");

channel.queueDeclare("quorum-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 19 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 19: RabbitMQ'da Shovel eklentisi nedir?
                                Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Shovel eklentisi, bir RabbitMQ sunucusundan diğerine veya başka bir mesajlaşma sistemine mesaj kopyalamak için kullanılır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Farklı sunucular arasında mesaj senkronizasyonu sağlar.</li>
                                    <li>Yedekleme veya veri migrasyonu için kullanılabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Shovel Yapılandırması:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_parameter shovel my-shovel \
'{"src-uri": "amqp://source-server", "src-queue": "source-queue", \
"dest-uri": "amqp://destination-server", "dest-queue": "destination-queue"}'</pre>
                            </div>
                        </div>

                        <!-- Soru 20 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 20: RabbitMQ'da Federation eklentisi nedir?
                                Ne işe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Federation eklentisi, farklı RabbitMQ sunucuları arasında mesajların güvenilir bir şekilde dağıtılmasını sağlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Coğrafi olarak dağılmış sunucular için kullanılır.</li>
                                    <li>Shovel'dan farklı olarak, federation upstream sunucudaki exchange'leri downstream sunucudaki exchange'lere bağlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Federation Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_parameter federation-upstream my-upstream \
'{"uri":"amqp://upstream-server"}'

rabbitmqctl set_parameter federation-upstream-set my-upstream-set \
'{"upstream-set":"my-upstream"}'

rabbitmqctl set_parameter policy federation \
'{"pattern":"", "federation-upstream-set":"my-upstream-set"}'</pre>
                            </div>
                        </div>
                    </div>

                    <!-- RabbitMQ İzleme ve Yönetim -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">🔹 RabbitMQ İzleme ve Yönetim</h3>

                        <!-- Soru 21 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 21: RabbitMQ'da monitoring için
                                hangi araçlar kullanılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ monitoring için kullanılan araçlar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>RabbitMQ Management Plugin:</strong> Web tabanlı yönetim arayüzü.</li>
                                    <li><strong>Prometheus + Grafana:</strong> Metrikleri toplamak ve görselleştirmek için.</li>
                                    <li><strong>rabbitmq_exporter:</strong> Prometheus için metrikleri dışa aktaran bir araç.</li>
                                    <li><strong>ELK Stack:</strong> Logları toplamak ve analiz etmek için.</li>
                                </ul>
                                <p class="mt-2 font-medium">Management Plugin Etkinleştirme:</p>
                                <pre class="code-block bash mt-2">rabbitmq-plugins enable rabbitmq_management</pre>
                                <p class="mt-2 font-medium">Prometheus ile Entegrasyon:</p>
                                <pre class="code-block bash mt-2">rabbitmq-plugins enable rabbitmq_prometheus</pre>
                            </div>
                        </div>

                        <!-- Soru 22 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 22: RabbitMQ'da log yönetimi nasıl
                                yapılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da log yönetimi için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Log Dosyaları:</strong> RabbitMQ log dosyaları /var/log/rabbitmq/ dizininde bulunur.</li>
                                    <li><strong>Log Seviyeleri:</strong> debug, info, warning, error, critical.</li>
                                    <li><strong>Log Döndürme:</strong> Log dosyalarının belirli boyuta ulaştığında döndürülmesi.</li>
                                </ul>
                                <p class="mt-2 font-medium">Log Yapılandırması:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
log.file.level = info
log.file = /var/log/rabbitmq/rabbit.log
log.exchange = true
log.queue = true</pre>
                            </div>
                        </div>

                        <!-- Soru 23 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 23: RabbitMQ'da memory alarm
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Memory alarm, RabbitMQ sunucusunun bellek kullanımı belirli bir eşiği aştığında tetiklenen bir uyarıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Bellek kritik seviyeye ulaştığında, yeni mesajları kabul etmeyi durdurur.</li>
                                    <li>Publisher'lar bloke olur ve mesaj gönderemez.</li>
                                    <li>Memory alarmı temizlendikten sonra normal çalışmaya devam eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Memory Alarm Eşiği Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
vm_memory_high_watermark.relative = 0.6 # %60 bellek kullanımı</pre>
                            </div>
                        </div>

                        <!-- Soru 24 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 24: RabbitMQ'da disk alarm
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Disk alarm, RabbitMQ sunucusunun disk alanı belirli bir eşiği aştığında tetiklenen bir uyarıdır.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Disk alanı kritik seviyeye ulaştığında, yeni mesajları kabul etmeyi durdurur.</li>
                                    <li>Publisher'lar bloke olur ve mesaj gönderemez.</li>
                                    <li>Disk alarmı temizlendikten sonra normal çalışmaya devam eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Disk Alarm Eşiği Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
disk_free_limit.relative = 1.0 # %1 boş disk alanı</pre>
                            </div>
                        </div>

                        <!-- Soru 25 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 25: RabbitMQ'da kullanıcı ve yetki
                                yönetimi nasıl yapılır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da kullanıcı ve yetki yönetimi için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kullanıcı Oluşturma:</strong> rabbitmqctl add_user komutu ile.</li>
                                    <li><strong>Yetki Atama:</strong> rabbitmqctl set_permissions komutu ile.</li>
                                    <li><strong>Rol Atama:</strong> rabbitmqctl set_user_tags komutu ile.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kullanıcı Oluşturma:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl add_user my-user my-password</pre>
                                <p class="mt-2 font-medium">Yetki Atama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_permissions -p my-vhost my-user ".*" ".*" ".*"</pre>
                                <p class="mt-2 font-medium">Rol Atama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_user_tags my-user administrator</pre>
                            </div>
                        </div>

                        <!-- Soru 26 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 26: RabbitMQ'da cluster nasıl
                                kurulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ cluster kurmak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>ERLANG Cookie:</strong> Tüm node'ların aynı ERLANG cookie'ye sahip olması gerekir.</li>
                                    <li><strong>Node'ları Birleştirme:</strong> rabbitmqctl join_cluster komutu ile.</li>
                                    <li><strong>Mirror Queues:</strong> Kuyrukların cluster içindeki tüm node'larda kopyalanması.</li>
                                </ul>
                                <p class="mt-2 font-medium">ERLANG Cookie Ayarlama:</p>
                                <pre class="code-block bash mt-2"># /var/lib/rabbitmq/.erlang.cookie dosyasını tüm node'larda aynı yapın</pre>
                                <p class="mt-2 font-medium">Cluster Oluşturma:</p>
                                <pre class="code-block bash mt-2"># Node 1
rabbitmq-server -detached

# Node 2
rabbitmq-server -detached
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@node1
rabbitmqctl start_app

# Node 3
rabbitmq-server -detached
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@node1
rabbitmqctl start_app</pre>
                            </div>
                        </div>

                        <!-- Soru 27 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 27: RabbitMQ'da yüksek erişilebilirlik
                                (High Availability) nasıl sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da yüksek erişilebilirlik sağlamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Cluster:</strong> Birden fazla node içeren bir cluster oluşturmak.</li>
                                    <li><strong>Mirror Queues:</strong> Kuyrukların cluster içindeki tüm node'larda kopyalanması.</li>
                                    <li><strong>Load Balancer:</strong> Client'ların cluster node'larına dağıtılması için.</li>
                                </ul>
                                <p class="mt-2 font-medium">Mirror Queue Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all"}'</pre>
                                <p class="mt-2 font-medium">Hem Mirror Queue Hem Synchronized Queue Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all","ha-sync-mode":"automatic"}'</pre>
                            </div>
                        </div>

                        <!-- Soru 28 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 28: RabbitMQ'da backup nasıl
                                alınır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da backup almak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Definitions:</strong> Exchange, kuyruk, binding ve kullanıcı tanımlarını dışa aktarmak.</li>
                                    <li><strong>Mnesia Database:</strong> Veritabanını kopyalamak.</li>
                                    <li><strong>Mesajların Backup'ı:</strong> Kuyruklardaki mesajları kurtarmak.</li>
                                </ul>
                                <p class="mt-2 font-medium">Definitions Dışa Aktarma:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl export_definitions > definitions.json</pre>
                                <p class="mt-2 font-medium">Mnesia Database Backup:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl stop
cd /var/lib/rabbitmq/mnesia/rabbit@$(hostname)
cp -r * /backup/location/
rabbitmq-server -detached</pre>
                            </div>
                        </div>

                        <!-- Soru 29 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 29: RabbitMQ'da performans nasıl
                                optimize edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ performansını optimize etmek için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Prefetch Count:</strong> Tüketiciye gönderilecek mesaj sayısını ayarlamak.</li>
                                    <li><strong>Batch Processing:</strong> Mesajları toplu olarak işlemek.</li>
                                    <li><strong>Persistent vs. Non-Persistent:</strong> Gerekmedikçe kalıcı mesajlar kullanmamak.</li>
                                    <li><strong>Lazy Queues:</strong> Büyük miktarda mesaj için lazy kuyruklar kullanmak.</li>
                                    <li><strong>Connection Pooling:</strong> Bağlantı havuzu kullanmak.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prefetch Count Ayarlama:</p>
                                <pre class="code-block java mt-2">channel.basicQos(100); // Her seferinde en fazla 100 mesaj gönder</pre>
                                <p class="mt-2 font-medium">Lazy Queue Oluşturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");

channel.queueDeclare("lazy-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 30 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">❓ Soru 30: RabbitMQ'da güvenlik nasıl
                                sağlanır?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da güvenlik sağlamak için:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>SSL/TLS:</strong> Client ile sunucu arasındaki iletişimi şifrelemek.</li>
                                    <li><strong>Kullanıcı Doğrulama:</strong> Kullanıcı adı ve şifre ile doğrulama.</li>
                                    <li><strong>Yetkilendirme:</strong> Kullanıcıların kaynaklara erişimini kontrol etmek.</li>
                                    <li><strong>Virtual Hosts:</strong> Farklı uygulamaları izole etmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL/TLS Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
listeners.ssl.default = 5671
ssl_options.cacertfile = /path/to/cacert.pem
ssl_options.certfile = /path/to/cert.pem
ssl_options.keyfile = /path/to/key.pem</pre>
                                <p class="mt-2 font-medium">Java Client SSL Ayarlama:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
factory.setPort(5671);
factory.useSslProtocol();
factory.setUsername("my-user");
factory.setPassword("my-password");</pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <footer class="text-center py-8 text-gray-600">
            <p>© 2025 Hacı Celal Aygar. All rights reserved. Kafka ve RabbitMQ Mülakat Soruları</p>
        </footer>
    </div>

    <script>
        function scrollToCategory(categoryId) {
            const element = document.getElementById(categoryId);
            element.scrollIntoView({ behavior: 'smooth' });
        }
    </script>
</body>

</html>
