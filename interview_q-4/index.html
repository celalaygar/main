<!DOCTYPE html>
<html lang="tr">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka ve RabbitMQ MÃ¼lakat SorularÄ±</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        .code-block {
            border-radius: 0.5rem;
            padding: 1rem;
            overflow-x: auto;
            font-family: monospace;
            font-size: 0.875rem;
        }

        .code-block.bash {
            background-color: #1e293b;
            color: #e2e8f0;
        }

        .code-block.json {
            background-color: #1e3a5f;
            color: #e2e8f0;
        }

        .code-block.yaml {
            background-color: #1e3a1e;
            color: #e2e8f0;
        }

        .code-block.java {
            background-color: #3a1e3a;
            color: #e2e8f0;
        }

        .code-block.xml {
            background-color: #3a1e1e;
            color: #e2e8f0;
        }

        .code-block.properties {
            background-color: #1e293b;
            color: #e2e8f0;
        }

        .category-card {
            transition: transform 0.3s ease;
        }

        .category-card:hover {
            transform: translateY(-5px);
        }

        .question-card {
            transition: all 0.3s ease;
        }

        .question-card:hover {
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }

        .kafka-color {
            background-color: #2a3f5f;
        }

        .rabbit-color {
            background-color: #ff6600;
        }
    </style>
</head>

<body class="bg-gray-100 min-h-screen">
    <div class="container mx-auto px-4 py-8">
        <header class="text-center mb-12">
            <h1 class="text-4xl font-bold text-gray-800 mb-2">Kafka ve RabbitMQ MÃ¼lakat SorularÄ±</h1>
            <p class="text-gray-600">100 adet ileri seviye soru ve cevapla hazÄ±rlanmÄ±ÅŸ kapsamlÄ± arÅŸiv</p>
        </header>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-12">
            <div class="category-card bg-white rounded-lg shadow-md p-6">
                <div class="flex items-center mb-4">
                    <div class="bg-blue-100 p-3 rounded-full mr-4">
                        <i class="fas fa-stream text-blue-600 text-xl"></i>
                    </div>
                    <h2 class="text-xl font-bold text-gray-800">Apache Kafka</h2>
                </div>
                <p class="text-gray-600 mb-4">70 adet ileri seviye Kafka mÃ¼lakat sorusu ve cevabÄ±</p>
                <button onclick="scrollToCategory('kafka')"
                    class="text-blue-600 font-medium hover:text-blue-800">SorularÄ± GÃ¶rÃ¼ntÃ¼le <i
                        class="fas fa-arrow-right ml-1"></i></button>
            </div>

            <div class="category-card bg-white rounded-lg shadow-md p-6">
                <div class="flex items-center mb-4">
                    <div class="bg-orange-100 p-3 rounded-full mr-4">
                        <i class="fas fa-envelope text-orange-600 text-xl"></i>
                    </div>
                    <h2 class="text-xl font-bold text-gray-800">RabbitMQ</h2>
                </div>
                <p class="text-gray-600 mb-4">30 adet ileri seviye RabbitMQ mÃ¼lakat sorusu ve cevabÄ±</p>
                <button onclick="scrollToCategory('rabbitmq')"
                    class="text-orange-600 font-medium hover:text-orange-800">SorularÄ± GÃ¶rÃ¼ntÃ¼le <i
                        class="fas fa-arrow-right ml-1"></i></button>
            </div>
        </div>

        <!-- Kafka SorularÄ± -->
        <section id="kafka" class="mb-16">
            <div class="bg-white rounded-lg shadow-md p-6 mb-8">
                <div class="flex items-center mb-6">
                    <div class="kafka-color p-3 rounded-full mr-4">
                        <i class="fas fa-stream text-white text-xl"></i>
                    </div>
                    <h2 class="text-2xl font-bold text-gray-800">Apache Kafka MÃ¼lakat SorularÄ±</h2>
                </div>
                <p class="text-gray-600 mb-6">Bu dokÃ¼manda Apache Kafka mÃ¼lakatlarÄ±nda en Ã§ok sorulan konular soru-cevap mantÄ±ÄŸÄ±yla aÃ§Ä±klanmÄ±ÅŸ ve Ã¶rnek kodlar eklenmiÅŸtir.</p>

                <div class="space-y-6">
                    <!-- Temel Kafka KavramlarÄ± -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Temel Kafka KavramlarÄ±</h3>

                        <!-- Soru 1 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 1: Apache Kafka nedir? Ne iÅŸe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Apache Kafka, aÃ§Ä±k kaynaklÄ± bir daÄŸÄ±tÄ±k olay akÄ±ÅŸÄ± platformudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>YÃ¼ksek verimli, gerÃ§ek zamanlÄ± veri akÄ±ÅŸlarÄ± iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Pub-sub modeli temelinde Ã§alÄ±ÅŸÄ±r.</li>
                                    <li>Veri kalÄ±cÄ±lÄ±ÄŸÄ± saÄŸlar (persistent messaging).</li>
                                    <li>BÃ¼yÃ¼k Ã¶lÃ§ekli veri iÅŸleme sistemlerinde kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Sunucusunu BaÅŸlatma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-server-start.sh config/server.properties</pre>
                            </div>
                        </div>

                        <!-- Soru 2 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 2: Kafka'da Topic nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Topic, Kafka'da mesajlarÄ±n kategorize edildiÄŸi mantÄ±ksal birimdir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Mesajlar topic'ler aracÄ±lÄ±ÄŸÄ±yla yayÄ±nlanÄ±r ve tÃ¼ketilir.</li>
                                    <li>Her topic birden fazla partition iÃ§erebilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Topic OluÅŸturma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3 --topic my-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 3 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 3: Partition nedir? Neden
                                Ã¶nemlidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Partition, bir topic'in bÃ¶lÃ¼mleridir ve paralel iÅŸlemeye olanak tanÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her partition, bir broker Ã¼zerinde fiziksel olarak depolanÄ±r.</li>
                                    <li>Partition sayÄ±sÄ± arttÄ±kÃ§a okuma ve yazma iÅŸlemi paralel olarak yapÄ±labilir.</li>
                                    <li>Veri daÄŸÄ±tÄ±mÄ± ve yÃ¼k dengeleme iÃ§in Ã¶nemlidir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 4 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 4: Producer ve Consumer
                                arasÄ±ndaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Producer:</strong> Kafka'ya mesaj gÃ¶nderen uygulamadÄ±r.</li>
                                    <li><strong>Consumer:</strong> Kafka'dan mesaj alan uygulamadÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Java Producer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
producer.send(new ProducerRecord<>("my-topic", "key", "value"));
producer.close();</pre>
                            </div>
                        </div>

                        <!-- Soru 5 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 5: Consumer Group nedir? Ne iÅŸe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer Group, aynÄ± topic'i tÃ¼keten consumer'larÄ±n koleksiyonudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Bir topic'teki partition'lar consumer group iÃ§indeki consumer'lara daÄŸÄ±tÄ±lÄ±r.</li>
                                    <li>Her partition sadece bir consumer tarafÄ±ndan tÃ¼ketilebilir.</li>
                                    <li>Load balancing ve fault tolerance saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Group ile Consumer BaÅŸlatma:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("group.id", "test-group");
props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Collections.singletonList("my-topic"));</pre>
                            </div>
                        </div>

                        <!-- Soru 6 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 6: Broker nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Broker, Kafka kÃ¼mesindeki bir sunucudur.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her broker, cluster iÃ§inde benzersiz bir ID'ye sahiptir.</li>
                                    <li>Partition'larÄ± barÄ±ndÄ±rÄ±r ve client isteklerini yÃ¶netir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 7 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 7: Zookeeper Kafka'da ne iÅŸe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Zookeeper, Kafka kÃ¼mesi iÃ§in koordinasyon hizmeti saÄŸlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Broker'larÄ±n, topic'lerin ve partition'larÄ±n metadata'sÄ±nÄ± saklar.</li>
                                    <li>Leader seÃ§imi ve cluster yÃ¶netimi iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Kafka 3.0 ve sonrasÄ± iÃ§in KIP-500 ile Zookeepersiz mod de desteklenmektedir.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 8 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 8: Offset nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Offset, bir partition iÃ§indeki her mesajÄ±n benzersiz konumunu belirten bir sayÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Her partition kendi offset'lerini yÃ¶netir.</li>
                                    <li>Consumer'lar hangi mesaja kadar okuduklarÄ±nÄ± offset'ler aracÄ±lÄ±ÄŸÄ±yla takip ederler.</li>
                                    <li>Offset'ler __consumer_offsets topic'inde saklanÄ±r.</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Soru 9 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 9: Replication nedir? Neden
                                Ã¶nemlidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Replication, veri kopyalarÄ±nÄ±n farklÄ± broker'lar Ã¼zerinde saklanmasÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Veri gÃ¼venliÄŸi ve dayanÄ±klÄ±lÄ±k saÄŸlar.</li>
                                    <li>Bir broker Ã§Ã¶ktÃ¼ÄŸÃ¼nde, veri kaybÄ± Ã¶nlenmiÅŸ olur.</li>
                                    <li>Replication faktÃ¶rÃ¼, her partition iÃ§in kaÃ§ kopya olacaÄŸÄ±nÄ± belirtir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Replication FaktÃ¶rÃ¼ AyarlarÄ±:</p>
                                <pre class="code-block bash mt-2"># Topic oluÅŸtururken replication faktÃ¶rÃ¼ belirtme
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 3 --partitions 3 --topic replicated-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 10 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 10: Leader ve Follower
                                partition'lar arasÄ±ndaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Leader Partition:</strong> Bir partition iÃ§in tÃ¼m okuma ve yazma iÅŸlemlerinden sorumlu olan partition'dÄ±r.</li>
                                    <li><strong>Follower Partition:</strong> Leader partition'dan veriyi Ã§oÄŸaltan (replicate eden) partition'lardÄ±r.</li>
                                </ul>
                                <p>Leader partition Ã§Ã¶ktÃ¼ÄŸÃ¼nde, follower'lardan biri yeni leader olarak seÃ§ilir.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Ä°leri DÃ¼zey Konular -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka Ä°leri DÃ¼zey Konular</h3>

                        <!-- Soru 11 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 11: Kafka'nÄ±n mesajlaÅŸma
                                garantileri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka Ã¼Ã§ farklÄ± mesajlaÅŸma garantisi sunar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>At most once:</strong> MesajlarÄ±n en fazla bir kez teslim edildiÄŸi, kaybolabileceÄŸi garanti.</li>
                                    <li><strong>At least once:</strong> MesajlarÄ±n en az bir kez teslim edildiÄŸi, tekrarlanabileceÄŸi garanti.</li>
                                    <li><strong>Exactly once:</strong> MesajlarÄ±n tam olarak bir kez teslim edildiÄŸi garanti (Kafka Streams ve Transactions ile).</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer iÃ§in Acks AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// At most once
props.put("acks", "0");

// At least once (default)
props.put("acks", "1");

// Exactly once / En gÃ¼venli
props.put("acks", "all");</pre>
                            </div>
                        </div>

                        <!-- Soru 12 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 12: Kafka Connector'lar
                                nelerdir? Ne iÅŸe yararlar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka Connector'lar, Kafka'yÄ± diÄŸer sistemlerle entegre etmek iÃ§in kullanÄ±lan bileÅŸenlerdir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Source Connector:</strong> DiÄŸer sistemlerden Kafka'ya veri aktarÄ±r.</li>
                                    <li><strong>Sink Connector:</strong> Kafka'dan diÄŸer sistemlere veri aktarÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Ã–rnek Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "jdbc-source-connector",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url": "jdbc:postgresql://localhost:5432/mydb",
    "connection.user": "user",
    "connection.password": "password",
    "mode": "bulk",
    "topic.prefix": "jdbc-",
    "tasks.max": "1"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 13 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 13: Kafka Streams nedir? Ne
                                iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka Streams, Kafka Ã¼zerinde gerÃ§ek zamanlÄ± veri iÅŸleme uygulamalarÄ± geliÅŸtirmek iÃ§in kullanÄ±lan bir kÃ¼tÃ¼phanedir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Stream Processing (akÄ±ÅŸ iÅŸleme) iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Scala veya Java ile yazÄ±labilir.</li>
                                    <li>Stateful ve stateless iÅŸlemleri destekler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Basit Kafka Stream Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount-app");
props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
props.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
props.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

KStream<String, String> source = builder.stream("text-input");
KTable<String, Long> counts = source
    .flatMapValues(value -> Arrays.asList(value.toLowerCase().split("\\W+")))
    .groupBy((key, value) -> value)
    .count();
counts.toStream().to("word-count-output", Produced.with(Serdes.String(), Serdes.Long()));</pre>
                            </div>
                        </div>

                        <!-- Soru 14 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 14: Kafka'da Compaction nedir?
                                Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Compaction, bir topic'te aynÄ± anahtara sahip mesajlarÄ±n sadece en sonuncusunu tutma iÅŸlemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Log compaction olarak da bilinir.</li>
                                    <li>DeÄŸiÅŸen veriler iÃ§in kullanÄ±ÅŸlÄ±dÄ±r (Ã¶rneÄŸin, kullanÄ±cÄ± profilleri).</li>
                                    <li>Topic'in son durumunu korurken depolama alanÄ±ndan tasarruf saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Compaction Ã–zellikli Topic OluÅŸturma:</p>
                                <pre class="code-block bash mt-2">bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic compacted-topic --config cleanup.policy=compact</pre>
                            </div>
                        </div>

                        <!-- Soru 15 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 15: Kafka'da Retention Period
                                nedir? NasÄ±l ayarlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Retention Period, mesajlarÄ±n Kafka'da ne kadar sÃ¼re kalacaÄŸÄ±nÄ± belirten sÃ¼redir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Zamana dayalÄ± (Ã¶rneÄŸin, 7 gÃ¼n) veya boyuta dayalÄ± (Ã¶rneÄŸin, 1GB) olabilir.</li>
                                    <li>SÃ¼re dolduÄŸunda mesajlar otomatik olarak silinir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Retention AyarlarÄ±:</p>
                                <pre class="code-block bash mt-2"># Topic oluÅŸtururken retention ayarlama
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic retention-topic --config retention.ms=604800000

# Mevcut topic'in retention sÃ¼resini deÄŸiÅŸtirme
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name retention-topic --alter --add-config retention.ms=259200000</pre>
                            </div>
                        </div>

                        <!-- Soru 16 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 16: Kafka'da Schema Registry
                                nedir? Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Schema Registry, Kafka'da kullanÄ±lan veri ÅŸemalarÄ±nÄ± (Avro, JSON, Protobuf) yÃ¶netmek iÃ§in kullanÄ±lan bir servistir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Veri ÅŸemalarÄ±nÄ±n merkezi olarak saklanmasÄ±nÄ± saÄŸlar.</li>
                                    <li>Producer ve Consumer arasÄ±ndaki uyumluluÄŸu kontrol eder.</li>
                                    <li>Åema evrimini (evolution) yÃ¶netir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Schema Registry KullanÄ±mÄ±:</p>
                                <pre class="code-block bash mt-2"># Schema yÃ¼kleme
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  --data '{"schema": "{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"name\",\"type\":\"string\"},{\"name\":\"age\",\"type\":\"int\"}]}"}' \
  http://localhost:8081/subjects/users-value/versions</pre>
                            </div>
                        </div>

                        <!-- Soru 17 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 17: Kafka'da ISR (In-Sync
                                Replicas) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> ISR, leader partition ile senkronize olan replikalarÄ±n kÃ¼mesidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>ISR'deki replikalar, leader partition'daki tÃ¼m mesajlarÄ± kopyalamÄ±ÅŸlardÄ±r.</li>
                                    <li>Bir replica, belirli bir sÃ¼re iÃ§inde leader ile senkronize olamazsa ISR'den Ã§Ä±karÄ±lÄ±r.</li>
                                    <li>Leader seÃ§imi ISR iÃ§indeki replikalar arasÄ±ndan yapÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">ISR Ä°le Ä°lgili Ayarlar:</p>
                                <pre class="code-block properties mt-2"># Minimum ISR boyutu
min.insync.replicas=2

# Replica senkronizasyon zaman aÅŸÄ±mÄ±
replica.lag.time.max.ms=30000</pre>
                            </div>
                        </div>

                        <!-- Soru 18 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 18: Kafka'da Consumer Rebalance
                                nedir? Ne zaman gerÃ§ekleÅŸir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer Rebalance, bir consumer grubundaki partition'larÄ±n consumer'lar arasÄ±nda yeniden daÄŸÄ±tÄ±lmasÄ± iÅŸlemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Yeni bir consumer gruba katÄ±ldÄ±ÄŸÄ±nda.</li>
                                    <li>Bir consumer gruptan ayrÄ±ldÄ±ÄŸÄ±nda veya Ã§Ã¶ktÃ¼ÄŸÃ¼nde.</li>
                                    <li>Bir topic'in partition sayÄ±sÄ± deÄŸiÅŸtiÄŸinde.</li>
                                </ul>
                                <p>Rebalance sÄ±rasÄ±nda, consumer'lar geÃ§ici olarak veri iÅŸlemezler. Bu nedenle, uzun sÃ¼rebilecek iÅŸlemler iÃ§in dikkatli olunmalÄ±dÄ±r.</p>
                            </div>
                        </div>

                        <!-- Soru 19 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 19: Kafka'da Static ve Dynamic
                                Membership arasÄ±ndaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Static Membership:</strong> Consumer'larÄ±n sabit bir kimlik (group.instance.id) ile gruba katÄ±ldÄ±ÄŸÄ± bir moddur. Bu modda, bir consumer geÃ§ici olarak ayrÄ±lÄ±p geri dÃ¶ndÃ¼ÄŸÃ¼nde, aynÄ± partition'larÄ± alÄ±r.</li>
                                    <li><strong>Dynamic Membership:</strong> Consumer'larÄ±n geÃ§ici kimliklerle gruba katÄ±ldÄ±ÄŸÄ± varsayÄ±lan moddur. Bir consumer ayrÄ±lÄ±p geri dÃ¶ndÃ¼ÄŸÃ¼nde, farklÄ± partition'lar alabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Static Membership AyarÄ±:</p>
                                <pre class="code-block java mt-2">props.put("group.instance.id", "consumer-1-instance");</pre>
                            </div>
                        </div>

                        <!-- Soru 20 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 20: Kafka'da Exactly-Once
                                Semantics nasÄ±l saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da exactly-once semantik, iki mekanizma ile saÄŸlanÄ±r:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> AynÄ± mesajÄ±n birden fazla kez gÃ¶nderilmesini Ã¶nler.</li>
                                    <li><strong>Transactions:</strong> Birden fazla partition'a atomik yazma iÅŸlemleri saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Producer AyarÄ±:</p>
                                <pre class="code-block java mt-2">props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Transactional Producer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">props.put("transactional.id", "my-transactional-id");
Producer<String, String> producer = new KafkaProducer<>(props);

producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic1", "key", "value"));
    producer.send(new ProducerRecord<>("topic2", "key", "value"));
    producer.commitTransaction();
} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
    producer.close();
} catch (KafkaException e) {
    producer.abortTransaction();
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Performans ve Ã–lÃ§eklendirme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka Performans ve Ã–lÃ§eklendirme</h3>

                        <!-- Soru 21 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 21: Kafka kÃ¼mesini Ã¶lÃ§eklendirmek
                                iÃ§in nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kÃ¼mesini Ã¶lÃ§eklendirirken dikkat edilmesi gereken Ã¶nemli noktalar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker Ekleme:</strong> Yeni broker'lar kÃ¼me eklendikten sonra partition'lar yeniden daÄŸÄ±tÄ±lmalÄ±dÄ±r.</li>
                                    <li><strong>Partition SayÄ±sÄ±:</strong> Daha fazla paralel iÅŸlem iÃ§in partition sayÄ±sÄ± artÄ±rÄ±labilir, ancak bu sayÄ± azaltÄ±lamaz.</li>
                                    <li><strong>Replication FaktÃ¶rÃ¼:</strong> Artan broker sayÄ±sÄ±yla birlikte replication faktÃ¶rÃ¼ artÄ±rÄ±labilir.</li>
                                    <li><strong>Network ve Disk I/O:</strong> Yeni broker'larÄ±n aÄŸ ve disk kapasitesi mevcut broker'larla uyumlu olmalÄ±dÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Partition Yeniden DaÄŸÄ±tma Komutu:</p>
                                <pre class="code-block bash mt-2">bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file reassign.json --execute</pre>
                            </div>
                        </div>

                        <!-- Soru 22 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 22: Kafka'da batch processing
                                nedir? PerformansÄ± nasÄ±l etkiler?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Batch processing, Kafka'da birden fazla mesajÄ±n tek bir network isteÄŸiyle gÃ¶nderilmesidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Network trafiÄŸini azaltÄ±r ve verimliliÄŸi artÄ±rÄ±r.</li>
                                    <li>Gecikme (latency) ile verimlilik (throughput) arasÄ±nda bir denge kurar.</li>
                                    <li>Batch boyutu arttÄ±kÃ§a verimlilik artar, ancak gecikme de artar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Batch AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Batch boyutu (bayt cinsinden)
props.put("batch.size", 16384);

// Bir mesajÄ±n ne kadar bekleneceÄŸi (milisaniye)
props.put("linger.ms", 5);</pre>
                            </div>
                        </div>

                        <!-- Soru 23 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 23: Kafka'da partition sayÄ±sÄ±nÄ±
                                belirlerken nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Partition sayÄ±sÄ±nÄ± belirlerken dikkat edilmesi gereken faktÃ¶rler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>TÃ¼ketim HÄ±zÄ±:</strong> Partition sayÄ±sÄ±, paralel tÃ¼ketim iÃ§in maksimum consumer sayÄ±sÄ±nÄ± belirler.</li>
                                    <li><strong>Ãœretim HÄ±zÄ±:</strong> Daha fazla partition, daha yÃ¼ksek paralel yazma imkanÄ± saÄŸlar.</li>
                                    <li><strong>Depolama ve Bellek:</strong> Her partition, broker'larda ek depolama ve bellek gerektirir.</li>
                                    <li><strong>Gelecek BÃ¼yÃ¼me:</strong> Partition sayÄ±sÄ± azaltÄ±lamayacaÄŸÄ± iÃ§in gelecekteki ihtiyaÃ§lar dikkate alÄ±nmalÄ±dÄ±r.</li>
                                </ul>
                                <p>Genel bir kural olarak, partition sayÄ±sÄ±, beklenen maksimum paralel consumer sayÄ±sÄ±ndan biraz fazla olmalÄ±dÄ±r.</p>
                            </div>
                        </div>

                        <!-- Soru 24 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 24: Kafka'da compression nasÄ±l
                                Ã§alÄ±ÅŸÄ±r? Hangi compression algoritmalarÄ± desteklenir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka, mesajlarÄ± gÃ¶ndermeden Ã¶nce sÄ±kÄ±ÅŸtÄ±rabilir, bu da network trafiÄŸini azaltÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Compression, producer tarafÄ±nda yapÄ±lÄ±r ve consumer tarafÄ±nda otomatik olarak aÃ§Ä±lÄ±r.</li>
                                    <li>Desteklenen algoritmalar: gzip, snappy, lz4, zstd.</li>
                                </ul>
                                <p class="mt-2 font-medium">Compression AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Compression tÃ¼rÃ¼
props.put("compression.type", "lz4");

// SÄ±kÄ±ÅŸtÄ±rma seviyesi (sadece gzip ve zstd iÃ§in)
props.put("compression.level", "5");</pre>
                            </div>
                        </div>

                        <!-- Soru 25 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 25: Kafka'da consumer
                                performansÄ±nÄ± artÄ±rmak iÃ§in neler yapÄ±labilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer performansÄ±nÄ± artÄ±rmak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>fetch.min.bytes ve fetch.max.wait.ms:</strong> Consumer'Ä±n ne kadar veri bekleyeceÄŸini kontrol eder.</li>
                                    <li><strong>max.partition.fetch.bytes:</strong> Bir partition'dan Ã§ekilebilecek maksimum veri boyutu.</li>
                                    <li><strong>max.poll.records:</strong> Bir poll() Ã§aÄŸrÄ±sÄ±nda dÃ¶ndÃ¼rÃ¼len maksimum kayÄ±t sayÄ±sÄ±.</li>
                                    <li><strong>Concurrent Processing:</strong> Veriyi paralel iÅŸlemek iÃ§in thread'ler kullanÄ±labilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Performans AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Minimum byte bekleme
props.put("fetch.min.bytes", 1024);

// Maksimum bekleme sÃ¼resi
props.put("fetch.max.wait.ms", 500);

// Bir partition'dan Ã§ekilecek maksimum veri
props.put("max.partition.fetch.bytes", 1048576);

// Bir poll'da dÃ¶ndÃ¼rÃ¼lecek maksimum kayÄ±t
props.put("max.poll.records", 500);</pre>
                            </div>
                        </div>

                        <!-- Soru 26 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 26: Kafka'da producer
                                performansÄ±nÄ± artÄ±rmak iÃ§in neler yapÄ±labilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Producer performansÄ±nÄ± artÄ±rmak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>batch.size ve linger.ms:</strong> Daha bÃ¼yÃ¼k batch'ler ve daha uzun bekleme sÃ¼releri verimliliÄŸi artÄ±rÄ±r.</li>
                                    <li><strong>compression.type:</strong> Veri sÄ±kÄ±ÅŸtÄ±rma network trafiÄŸini azaltÄ±r.</li>
                                    <li><strong>buffer.memory:</strong> Toplam buffer belleÄŸini artÄ±rmak.</li>
                                    <li><strong>acks:</strong> Daha dÃ¼ÅŸÃ¼k acks seviyeleri (0 veya 1) gecikmeyi azaltÄ±r.</li>
                                    <li><strong>retries ve retry.backoff.ms:</strong> GeÃ§ici hatalarda yeniden deneme mekanizmasÄ±.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer Performans AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Toplam buffer belleÄŸi
props.put("buffer.memory", 67108864);

// Yeniden deneme sayÄ±sÄ±
props.put("retries", 3);

// Yeniden deneme aralÄ±ÄŸÄ±
props.put("retry.backoff.ms", 100);</pre>
                            </div>
                        </div>

                        <!-- Soru 27 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 27: Kafka'da disk I/O
                                performansÄ±nÄ± optimize etmek iÃ§in nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Disk I/O performansÄ±nÄ± optimize etmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>log.dirs:</strong> FarklÄ± disklerde birden fazla log dizini kullanmak.</li>
                                    <li><strong>log.segment.bytes:</strong> Segment boyutunu artÄ±rmak.</li>
                                    <li><strong>log.flush.interval.messages ve log.flush.interval.ms:</strong> Disk flush sÄ±klÄ±ÄŸÄ±nÄ± ayarlamak.</li>
                                    <li><strong>num.io.threads:</strong> I/O iÅŸlemleri iÃ§in thread sayÄ±sÄ±nÄ± artÄ±rmak.</li>
                                    <li><strong>SSD Diskler:</strong> Mekanik disklere gÃ¶re daha iyi I/O performansÄ± saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Disk I/O AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2"># FarklÄ± disklerde log dizinleri
log.dirs=/disk1/kafka-logs,/disk2/kafka-logs

# Segment boyutu (varsayÄ±lan: 1GB)
log.segment.bytes=1073741824

# I/O thread sayÄ±sÄ±
num.io.threads=8

# Flush aralÄ±ÄŸÄ± (mesaj sayÄ±sÄ±)
log.flush.interval.messages=10000

# Flush aralÄ±ÄŸÄ± (milisaniye)
log.flush.interval.ms=1000</pre>
                            </div>
                        </div>

                        <!-- Soru 28 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 28: Kafka'da network
                                performansÄ±nÄ± optimize etmek iÃ§in nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Network performansÄ±nÄ± optimize etmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>socket.send.buffer.bytes ve socket.receive.buffer.bytes:</strong> Socket buffer boyutlarÄ±nÄ± artÄ±rmak.</li>
                                    <li><strong>socket.request.max.bytes:</strong> Maksimum istek boyutunu artÄ±rmak.</li>
                                    <li><strong>num.network.threads:</strong> Network iÅŸlemleri iÃ§in thread sayÄ±sÄ±nÄ± artÄ±rmak.</li>
                                    <li><strong>compression.type:</strong> Veri sÄ±kÄ±ÅŸtÄ±rma kullanarak network trafiÄŸini azaltmak.</li>
                                    <li><strong>batch.size:</strong> Daha bÃ¼yÃ¼k batch'ler ile daha az network isteÄŸi.</li>
                                </ul>
                                <p class="mt-2 font-medium">Network AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2"># Socket buffer boyutlarÄ±
socket.send.buffer.bytes=1024000
socket.receive.buffer.bytes=1024000

# Maksimum istek boyutu
socket.request.max.bytes=104857600

# Network thread sayÄ±sÄ±
num.network.threads=4</pre>
                            </div>
                        </div>

                        <!-- Soru 29 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 29: Kafka'da JVM ayarlarÄ±nÄ±
                                optimize etmek iÃ§in nelere dikkat etmek gerekir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> JVM ayarlarÄ±nÄ± optimize etmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Heap Boyutu:</strong> Yeterli heap boyutu ayarlamak (genellikle 6GB ve Ã¼zeri).</li>
                                    <li><strong>Garbage Collector:</strong> G1GC kullanmak, bÃ¼yÃ¼k heap boyutlarÄ± iÃ§in daha uygundur.</li>
                                    <li><strong>JMX Port:</strong> Monitoring iÃ§in JMX portunu aÃ§mak.</li>
                                    <li><strong>GC Logging:</strong> GC performansÄ±nÄ± izlemek iÃ§in GC loglarÄ±nÄ± etkinleÅŸtirmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">JVM AyarlarÄ±:</p>
                                <pre class="code-block bash mt-2"># Kafka baÅŸlatma komutunda JVM ayarlarÄ±
export KAFKA_HEAP_OPTS="-Xmx6G -Xms6G"
export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -Djava.awt.headless=true"</pre>
                            </div>
                        </div>

                        <!-- Soru 30 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 30: Kafka'da monitoring iÃ§in
                                hangi metrikler izlenmelidir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka monitoring iÃ§in Ã¶nemli metrikler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>UnderReplicatedPartitions:</strong> Yeterli replikasÄ± olmayan partition sayÄ±sÄ±.</li>
                                    <li><strong>UnderMinIsrPartitionCount:</strong> Minimum ISR sayÄ±sÄ±nÄ±n altÄ±ndaki partition sayÄ±sÄ±.</li>
                                    <li><strong>IsrShrinksPerSec ve IsrExpandsPerSec:</strong> ISR'deki deÄŸiÅŸim oranÄ±.</li>
                                    <li><strong>ActiveControllerCount:</strong> Aktif controller sayÄ±sÄ± (1 olmalÄ±).</li>
                                    <li><strong>OfflinePartitionsCount:</strong> Ã‡evrimdÄ±ÅŸÄ± partition sayÄ±sÄ± (0 olmalÄ±).</li>
                                    <li><strong>RequestHandlerAvgIdlePercent:</strong> Network thread'lerin boÅŸta kalma oranÄ±.</li>
                                    <li><strong>BytesInPerSec ve BytesOutPerSec:</strong> Network trafiÄŸi.</li>
                                    <li><strong>MessagesInPerSec:</strong> Mesaj giriÅŸ hÄ±zÄ±.</li>
                                </ul>
                                <p>Bu metrikler, Kafka kÃ¼mesinin saÄŸlÄ±ÄŸÄ± ve performansÄ± hakkÄ±nda Ã¶nemli bilgiler saÄŸlar.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka GÃ¼venlik ve Ä°zleme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka GÃ¼venlik ve Ä°zleme</h3>

                        <!-- Soru 31 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 31: Kafka'da gÃ¼venlik nasÄ±l
                                saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da gÃ¼venlik saÄŸlamak iÃ§in kullanÄ±lan yÃ¶ntemler:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>SSL/TLS:</strong> Broker'lar arasÄ± ve client-broker arasÄ± iletiÅŸim iÃ§in ÅŸifreleme.</li>
                                    <li><strong>SASL:</strong> Kimlik doÄŸrulama mekanizmalarÄ± (PLAIN, SCRAM, GSSAPI/Kerberos).</li>
                                    <li><strong>ACL (Access Control Lists):</strong> KullanÄ±cÄ± ve yetkilendirme yÃ¶netimi.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2"># Broker SSL ayarlarÄ±
listeners=SSL://:9093
ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
ssl.truststore.password=test1234</pre>
                                <p class="mt-2 font-medium">SASL AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2"># Broker SASL ayarlarÄ±
listeners=SASL_SSL://:9093
sasl.mechanism.inter.broker.protocol=GSSAPI
sasl.enabled.mechanisms=GSSAPI
security.inter.broker.protocol=SASL_SSL</pre>
                            </div>
                        </div>

                        <!-- Soru 32 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 32: Kafka'da ACL (Access Control
                                List) nasÄ±l yapÄ±landÄ±rÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> ACL, Kafka'da kaynaklara (topic, cluster, group vb.) eriÅŸimi kontrol etmek iÃ§in kullanÄ±lÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Principal (kullanÄ±cÄ± veya servis), kaynak ve iÅŸlem (READ, WRITE, CREATE, DESCRIBE vb.) bazÄ±nda eriÅŸim kontrolÃ¼ saÄŸlar.</li>
                                    <li>ACL'ler kafka-acls.sh komutu ile yÃ¶netilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">ACL Ã–rnekleri:</p>
                                <pre class="code-block bash mt-2"># User1'in test-topic Ã¼zerinde WRITE izni
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --operation Write --topic test-topic

# User1'in test-consumer-group Ã¼zerinde READ izni
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user1 --operation Read --group test-consumer-group

# User2'nin tÃ¼m topic'leri DESCRIBE etmesine izin verme
bin/kafka-acls.sh --bootstrap-server localhost:9092 --add --allow-principal User:user2 --operation Describe --topic *</pre>
                            </div>
                        </div>

                        <!-- Soru 33 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 33: Kafka'da SASL/SCRAM
                                kimlik doÄŸrulama nasÄ±l yapÄ±landÄ±rÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> SASL/SCRAM, kullanÄ±cÄ± adÄ± ve ÅŸifre ile kimlik doÄŸrulama saÄŸlayan bir mekanizmadÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>KullanÄ±cÄ± bilgileri Zookeeper'da saklanÄ±r.</li>
                                    <li>SCRAM mekanizmasÄ±, ÅŸifrelerin dÃ¼z metin olarak saklanmasÄ±nÄ± Ã¶nler.</li>
                                </ul>
                                <p class="mt-2 font-medium">SCRAM YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block properties mt-2"># Broker ayarlarÄ±
listeners=SASL_SSL://:9093
sasl.enabled.mechanisms=SCRAM-SHA-256,SCRAM-SHA-512
sasl.mechanism.inter.broker.protocol=SCRAM-SHA-256
security.inter.broker.protocol=SASL_SSL

# JAAS konfigÃ¼rasyonu
listener.name.sasl_ssl.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
  username="admin" \
  password="admin-secret";</pre>
                                <p class="mt-2 font-medium">KullanÄ±cÄ± OluÅŸturma:</p>
                                <pre class="code-block bash mt-2"># KullanÄ±cÄ± ekleme
bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-256=[password=alice-secret],SCRAM-SHA-512=[password=alice-secret]' --entity-type users --entity-name alice</pre>
                            </div>
                        </div>

                        <!-- Soru 34 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 34: Kafka'da SSL/TLS nasÄ±l
                                yapÄ±landÄ±rÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> SSL/TLS, Kafka'da iletiÅŸimi ÅŸifrelemek iÃ§in kullanÄ±lÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Broker'lar arasÄ± iletiÅŸimi ÅŸifrelemek iÃ§in.</li>
                                    <li>Client-broker arasÄ± iletiÅŸimi ÅŸifrelemek iÃ§in.</li>
                                    <li>Ä°ki yÃ¶nlÃ¼ kimlik doÄŸrulama (mutual TLS) iÃ§in.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL SertifikasÄ± OluÅŸturma:</p>
                                <pre class="code-block bash mt-2"># CA sertifikasÄ± oluÅŸturma
openssl req -new -newkey rsa:2048 -days 365 -x509 -keyout ca-key -out ca-cert -subj "/C=TR/ST=Istanbul/L=Istanbul/O=MyOrg/CN=CA"

# Broker sertifikasÄ± oluÅŸturma
keytool -genkey -keystore kafka.server.keystore.jks -alias localhost -keyalg RSA -validity 365 -storepass test1234 -keypass test1234 -dname "CN=localhost"

# CA ile sertifikayÄ± imzalama
keytool -keystore kafka.server.keystore.jks -alias localhost -certreq -file cert-file
openssl x509 -req -CA ca-cert -CAkey ca-key -in cert-file -out cert-signed -days 365 -CAcreateserial
keytool -keystore kafka.server.keystore.jks -alias CARoot -import -file ca-cert
keytool -keystore kafka.server.keystore.jks -alias localhost -import -file cert-signed

# Truststore oluÅŸturma
keytool -keystore kafka.server.truststore.jks -alias CARoot -import -file ca-cert -storepass test1234</pre>
                                <p class="mt-2 font-medium">Broker SSL AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2">listeners=SSL://:9093
ssl.keystore.location=/var/private/ssl/kafka.server.keystore.jks
ssl.keystore.password=test1234
ssl.key.password=test1234
ssl.truststore.location=/var/private/ssl/kafka.server.truststore.jks
ssl.truststore.password=test1234</pre>
                            </div>
                        </div>

                        <!-- Soru 35 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 35: Kafka'da veri ÅŸifreleme
                                (encryption) nasÄ±l saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da veri ÅŸifreleme iÃ§in iki yaklaÅŸÄ±m vardÄ±r:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Transport Level Encryption (SSL/TLS):</strong> Verinin network Ã¼zerinde ÅŸifrelenmesi.</li>
                                    <li><strong>Application Level Encryption:</strong> Verinin uygulama katmanÄ±nda ÅŸifrelenmesi.</li>
                                </ul>
                                <p class="mt-2 font-medium">Uygulama KatmanÄ±nda Åifreleme Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">import javax.crypto.Cipher;
import javax.crypto.KeyGenerator;
import javax.crypto.SecretKey;
import javax.crypto.spec.SecretKeySpec;
import java.util.Base64;

public class EncryptionUtil {
    private static final String ALGORITHM = "AES";
    
    public static String encrypt(String data, String key) throws Exception {
        SecretKeySpec secretKey = new SecretKeySpec(key.getBytes(), ALGORITHM);
        Cipher cipher = Cipher.getInstance(ALGORITHM);
        cipher.init(Cipher.ENCRYPT_MODE, secretKey);
        byte[] encryptedBytes = cipher.doFinal(data.getBytes());
        return Base64.getEncoder().encodeToString(encryptedBytes);
    }
    
    public static String decrypt(String encryptedData, String key) throws Exception {
        SecretKeySpec secretKey = new SecretKeySpec(key.getBytes(), ALGORITHM);
        Cipher cipher = Cipher.getInstance(ALGORITHM);
        cipher.init(Cipher.DECRYPT_MODE, secretKey);
        byte[] decryptedBytes = cipher.doFinal(Base64.getDecoder().decode(encryptedData));
        return new String(decryptedBytes);
    }
}

// Producer kullanÄ±mÄ±
String encryptedData = EncryptionUtil.encrypt("sensitive data", "my-secret-key");
producer.send(new ProducerRecord<>("encrypted-topic", encryptedData));</pre>
                            </div>
                        </div>

                        <!-- Soru 36 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 36: Kafka'da izleme
                                (monitoring) iÃ§in hangi araÃ§lar kullanÄ±labilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka monitoring iÃ§in kullanÄ±lan araÃ§lar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafkaå†…ç½®æŒ‡æ ‡:</strong> Kafka'nÄ±n JMX aracÄ±lÄ±ÄŸÄ±yla saÄŸladÄ±ÄŸÄ± metrikler.</li>
                                    <li><strong>Prometheus + Grafana:</strong> Metrikleri toplamak ve gÃ¶rselleÅŸtirmek iÃ§in.</li>
                                    <li><strong>Confluent Control Center:</strong> Confluent Platform'un saÄŸladÄ±ÄŸÄ± komerciyel monitoring aracÄ±.</li>
                                    <li><strong>Kafka Manager (CMAK):</strong> AÃ§Ä±k kaynaklÄ± Kafka kÃ¼me yÃ¶netim aracÄ±.</li>
                                    <li><strong>Elasticsearch + Kibana:</strong> LoglarÄ± toplamak ve analiz etmek iÃ§in.</li>
                                    <li><strong>Jaeger/Zipkin:</strong> DaÄŸÄ±tÄ±k izleme (distributed tracing) iÃ§in.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prometheus JMX Exporter YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block yaml mt-2"># prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'kafka'
    static_configs:
      - targets: ['localhost:7071'] # JMX Exporter portu</pre>
                            </div>
                        </div>

                        <!-- Soru 37 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 37: Kafka'da log yÃ¶netimi nasÄ±l
                                yapÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da log yÃ¶netimi iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>log4j veya logback:</strong> Loglama iÃ§in kullanÄ±lan kÃ¼tÃ¼phaneler.</li>
                                    <li><strong>Log Aggregation:</strong> LoglarÄ± merkezi bir sistemde toplamak (ELK, Splunk vb.).</li>
                                    <li><strong>Log Rotation:</strong> Log dosyalarÄ±nÄ±n dÃ¶ndÃ¼rÃ¼lmesi.</li>
                                    <li><strong>Structured Logging:</strong> JSON formatÄ±nda loglama.</li>
                                </ul>
                                <p class="mt-2 font-medium">log4j YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block xml mt-2">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;Configuration status="WARN"&gt;
  &lt;Appenders&gt;
    &lt;Console name="Console" target="SYSTEM_OUT"&gt;
      &lt;PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n"/&gt;
    &lt;/Console&gt;
    &lt;RollingFile name="RollingFile" fileName="logs/kafka.log" filePattern="logs/kafka-%d{yyyy-MM-dd}-%i.log"&gt;
      &lt;PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss} %-5level %logger{36} - %msg%n"/&gt;
      &lt;Policies&gt;
        &lt;TimeBasedTriggeringPolicy interval="1" modulate="true"/&gt;
        &lt;SizeBasedTriggeringPolicy size="100 MB"/&gt;
      &lt;/Policies&gt;
      &lt;DefaultRolloverStrategy max="10"/&gt;
    &lt;/RollingFile&gt;
  &lt;/Appenders&gt;
  &lt;Loggers&gt;
    &lt;Root level="INFO"&gt;
      &lt;AppenderRef ref="Console"/&gt;
      &lt;AppenderRef ref="RollingFile"/&gt;
    &lt;/Root&gt;
  &lt;/Loggers&gt;
&lt;/Configuration&gt;</pre>
                            </div>
                        </div>

                        <!-- Soru 38 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 38: Kafka'da uyarÄ± (alerting)
                                sistemi nasÄ±l kurulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da uyarÄ± sistemi kurmak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Prometheus Alertmanager:</strong> Prometheus metriklerine dayalÄ± uyarÄ±lar oluÅŸturmak.</li>
                                    <li><strong>Grafana Alerting:</strong> Grafana Ã¼zerinden uyarÄ± oluÅŸturmak.</li>
                                    <li><strong>Burrow:</strong> Consumer lag izleme ve uyarÄ± iÃ§in Ã¶zel araÃ§.</li>
                                    <li><strong>Custom Scripts:</strong> Kafka metriklerini kontrol eden Ã¶zel betikler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prometheus Alertmanager YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block yaml mt-2"># alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alertmanager@example.com'

route:
  group_by: ['alertname', 'severity']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  email_configs:
  - to: 'admin@example.com'

# Prometheus alert rules
groups:
- name: kafka.rules
  rules:
  - alert: KafkaUnderReplicatedPartitions
    expr: kafka_server_replicamanager_underreplicatedpartitions > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Kafka under-replicated partitions (instance {{ $labels.instance }})"
      description: "Kafka has {{ $value }} under-replicated partitions for more than 5 minutes."</pre>
                            </div>
                        </div>

                        <!-- Soru 39 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 39: Kafka'da JMX metrikleri nasÄ±l
                                izlenir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da JMX metriklerini izlemek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>JMX Portu AÃ§ma:</strong> Kafka broker'larÄ± iÃ§in JMX portunu aÃ§mak.</li>
                                    <li><strong>JMX Konsolu:</strong> JConsole veya JVisualVM kullanarak metrikleri gÃ¶rÃ¼ntÃ¼lemek.</li>
                                    <li><strong>JMX Exporter:</strong> JMX metriklerini Prometheus formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">JMX Portu AÃ§ma:</p>
                                <pre class="code-block bash mt-2"># Kafka baÅŸlatma komutunda JMX ayarlarÄ±
export KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false"</pre>
                                <p class="mt-2 font-medium">JMX Exporter YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block yaml mt-2"># jmx-exporter-config.yml
rules:
- pattern: "kafka.server&lt;type=ReplicaManager, name=UnderReplicatedPartitions&gt;&lt;&gt;Value"
  name: "kafka_server_replicamanager_underreplicatedpartitions"
  type: GAUGE
  value: "{{ $value }}"</pre>
                            </div>
                        </div>

                        <!-- Soru 40 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 40: Kafka'da audit log nasÄ±l
                                oluÅŸturulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka'da audit log oluÅŸturmak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Authorizer:</strong> Kimlik doÄŸrulama ve yetkilendirme olaylarÄ±nÄ± loglamak.</li>
                                    <li><strong>Custom Interceptor:</strong> Producer ve Consumer interceptor'larÄ± ile Ã¶zel loglama.</li>
                                    <li><strong>Audit Topic:</strong> Audit olaylarÄ±nÄ± Ã¶zel bir topic'e gÃ¶ndermek.</li>
                                </ul>
                                <p class="mt-2 font-medium">Audit Log YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block properties mt-2"># Broker ayarlarÄ±
authorizer.class.name=kafka.security.authorizer.AclAuthorizer

# Audit log ayarlarÄ±
kafka.authorizer.logger.listeners=kafka.security.authorizer.AclAuthorizer$AuditLogListener
kafka.authorizer.logger.listeners.log.dir=/var/log/kafka/audit</pre>
                                <p class="mt-2 font-medium">Custom Interceptor Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">public class AuditProducerInterceptor implements ProducerInterceptor<String, String> {
    private static final Logger LOG = LoggerFactory.getLogger(AuditProducerInterceptor.class);
    
    @Override
    public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
        LOG.info("Sending message to topic: {}, key: {}, value: {}", 
                record.topic(), record.key(), record.value());
        return record;
    }
    
    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            LOG.error("Error sending message", exception);
        } else {
            LOG.info("Message sent successfully to topic: {}, partition: {}, offset: {}", 
                    metadata.topic(), metadata.partition(), metadata.offset());
        }
    }
    
    @Override
    public void close() {}
    
    @Override
    public void configure(Map<String, ?> configs) {}
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Senaryo ve Problem Ã‡Ã¶zme -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka Senaryo ve Problem Ã‡Ã¶zme</h3>

                        <!-- Soru 41 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 41: Consumer sÃ¼rekli
                                rebalance oluyor, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer sÃ¼rekli rebalance oluyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>max.poll.interval.ms:</strong> Bu sÃ¼reden daha uzun sÃ¼ren iÅŸlemler iÃ§in deÄŸeri artÄ±rÄ±n.</li>
                                    <li><strong>heartbeat.interval.ms:</strong> Heartbeat aralÄ±ÄŸÄ±nÄ± kÄ±saltÄ±n.</li>
                                    <li><strong>session.timeout.ms:</strong> Oturum zaman aÅŸÄ±mÄ±nÄ± artÄ±rÄ±n.</li>
                                    <li><strong>Ä°ÅŸlem SÃ¼resi:</strong> Veri iÅŸleme sÃ¼resini optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Poll aralÄ±ÄŸÄ± (varsayÄ±lan: 300000 ms)
props.put("max.poll.interval.ms", 600000);

// Heartbeat aralÄ±ÄŸÄ± (varsayÄ±lan: 3000 ms)
props.put("heartbeat.interval.ms", 1000);

// Oturum zaman aÅŸÄ±mÄ± (varsayÄ±lan: 10000 ms)
props.put("session.timeout.ms", 30000);</pre>
                            </div>
                        </div>

                        <!-- Soru 42 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 42: Kafka'da mesaj kaybÄ±
                                yaÅŸÄ±yorum, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesaj kaybÄ±nÄ± Ã¶nlemek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>acks=all:</strong> Producer iÃ§in tÃ¼m replikalarÄ±n onayÄ±nÄ± bekle.</li>
                                    <li><strong>min.insync.replicas:</strong> Minimum ISR sayÄ±sÄ±nÄ± artÄ±r.</li>
                                    <li><strong>retries:</strong> Producer iÃ§in yeniden deneme sayÄ±sÄ±nÄ± artÄ±r.</li>
                                    <li><strong>enable.idempotence:</strong> Idempotent producer'Ä± etkinleÅŸtir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// TÃ¼m replikalarÄ±n onayÄ±nÄ± bekle
props.put("acks", "all");

// Yeniden deneme sayÄ±sÄ±
props.put("retries", 3);

// Idempotent producer
props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Broker AyarlarÄ±:</p>
                                <pre class="code-block properties mt-2"># Minimum ISR sayÄ±sÄ±
min.insync.replicas=2</pre>
                            </div>
                        </div>

                        <!-- Soru 43 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 43: Kafka'da consumer lag
                                (geride kalma) sorunu yaÅŸÄ±yorum, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Consumer lag sorununu Ã§Ã¶zmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer SayÄ±sÄ±nÄ± ArtÄ±rma:</strong> Daha fazla consumer ekleyin.</li>
                                    <li><strong>Partition SayÄ±sÄ±nÄ± ArtÄ±rma:</strong> Topic iÃ§in daha fazla partition oluÅŸturun.</li>
                                    <li><strong>Ä°ÅŸlem SÃ¼resini Optimize Etme:</strong> Veri iÅŸleme sÃ¼resini azaltÄ±n.</li>
                                    <li><strong>Batch Ä°ÅŸleme:</strong> Veriyi toplu olarak iÅŸleyin.</li>
                                    <li><strong>Consumer AyarlarÄ±:</strong> fetch.min.bytes, max.poll.records gibi ayarlarÄ± optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Lag KontrolÃ¼:</p>
                                <pre class="code-block bash mt-2"># Consumer lag kontrolÃ¼
bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group my-consumer-group</pre>
                                <p class="mt-2 font-medium">Partition SayÄ±sÄ±nÄ± ArtÄ±rma:</p>
                                <pre class="code-block bash mt-2"># Partition sayÄ±sÄ±nÄ± artÄ±rma
bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic my-topic --partitions 10</pre>
                            </div>
                        </div>

                        <!-- Soru 44 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 44: Kafka broker'Ä± disk alanÄ±
                                doldu, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Broker disk alanÄ± dolduÄŸunda:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Retention SÃ¼resini Azaltma:</strong> MesajlarÄ±n daha hÄ±zlÄ± silinmesi iÃ§in retention sÃ¼resini azaltÄ±n.</li>
                                    <li><strong>Log Segment Boyutunu Azaltma:</strong> Segment boyutunu kÃ¼Ã§Ã¼ltÃ¼n.</li>
                                    <li><strong>Disk Temizleme:</strong> Eski log dosyalarÄ±nÄ± manuel olarak silin.</li>
                                    <li><strong>Yeni Disk Ekleme:</strong> Broker'a yeni disk ekleyin.</li>
                                    <li><strong>Topic'leri TaÅŸÄ±ma:</strong> BazÄ± topic'leri baÅŸka broker'lara taÅŸÄ±yÄ±n.</li>
                                </ul>
                                <p class="mt-2 font-medium">Retention SÃ¼resini Azaltma:</p>
                                <pre class="code-block bash mt-2"># Topic iÃ§in retention sÃ¼resini azaltma
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config retention.ms=86400000</pre>
                                <p class="mt-2 font-medium">Log Segment Boyutunu Ayarlama:</p>
                                <pre class="code-block bash mt-2"># Topic iÃ§in log segment boyutunu ayarlama
bin/kafka-configs.sh --bootstrap-server localhost:9092 --entity-type topics --entity-name my-topic --alter --add-config log.segment.bytes=536870912</pre>
                            </div>
                        </div>

                        <!-- Soru 45 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 45: Kafka kÃ¼mesinde broker
                                Ã§Ã¶ktÃ¼, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kÃ¼mesinde broker Ã§Ã¶ktÃ¼ÄŸÃ¼nde:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker'Ä± Yeniden BaÅŸlatma:</strong> Broker'Ä± yeniden baÅŸlatÄ±n.</li>
                                    <li><strong>LoglarÄ± Ä°nceleme:</strong> Neden Ã§Ã¶ktÃ¼ÄŸÃ¼nÃ¼ anlamak iÃ§in loglarÄ± inceleyin.</li>
                                    <li><strong>Replication FaktÃ¶rÃ¼nÃ¼ Kontrol Etme:</strong> Partition'larÄ±n replikalarÄ± var mÄ± kontrol edin.</li>
                                    <li><strong>Leader SeÃ§imini Ä°zleme:</strong> Yeni leader'larÄ±n seÃ§ilip seÃ§ilmediÄŸini izleyin.</li>
                                    <li><strong>Under-Replicated Partition'larÄ± Ä°zleme:</strong> Yeterli replikasÄ± olmayan partition'larÄ± izleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Broker Durumunu Kontrol Etme:</p>
                                <pre class="code-block bash mt-2"># Broker durumunu kontrol etme
bin/kafka-broker-api-versions --bootstrap-server localhost:9092

# Topic durumunu kontrol etme
bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic my-topic</pre>
                            </div>
                        </div>

                        <!-- Soru 46 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 46: Kafka'da duplicate mesajlar
                                alÄ±yorum, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Duplicate mesajlarÄ± Ã¶nlemek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> Producer'Ä± idempotent hale getirin.</li>
                                    <li><strong>Exactly-Once Semantics:</strong> Transaction kullanarak tam olarak bir kez teslimat saÄŸlayÄ±n.</li>
                                    <li><strong>Consumer TarafÄ±nda TekilleÅŸtirme:</strong> AynÄ± mesajÄ±n tekrar iÅŸlenmesini Ã¶nleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Producer AyarÄ±:</p>
                                <pre class="code-block java mt-2">props.put("enable.idempotence", "true");</pre>
                                <p class="mt-2 font-medium">Transactional Producer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">props.put("transactional.id", "my-transactional-id");
Producer<String, String> producer = new KafkaProducer<>(props);

producer.initTransactions();
try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic1", "key", "value"));
    producer.commitTransaction();
} catch (ProducerFencedException | OutOfOrderSequenceException | AuthorizationException e) {
    producer.close();
} catch (KafkaException e) {
    producer.abortTransaction();
}</pre>
                                <p class="mt-2 font-medium">Consumer TarafÄ±nda TekilleÅŸtirme:</p>
                                <pre class="code-block java mt-2">public class DeduplicatingConsumer {
    private Set<String> processedIds = new HashSet<>();
    
    public void process(ConsumerRecord<String, String> record) {
        String messageId = record.key() + "-" + record.offset();
        if (processedIds.contains(messageId)) {
            return; // Zaten iÅŸlenmiÅŸ
        }
        
        // MesajÄ± iÅŸle
        processMessage(record.value());
        
        // Ä°ÅŸlenmiÅŸ olarak iÅŸaretle
        processedIds.add(messageId);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 47 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 47: Kafka'da mesajlarÄ±n sÄ±rasÄ±
                                bozuluyor, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesaj sÄ±rasÄ±nÄ± korumak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Partition SayÄ±sÄ±:</strong> SÄ±ralÄ± mesajlar iÃ§in tek partition kullanÄ±n.</li>
                                    <li><strong>Key Kullanma:</strong> AynÄ± key'e sahip mesajlar aynÄ± partition'a gider.</li>
                                    <li><strong>Max In Flight Requests:</strong> Producer'da max.in.flight.requests.per.connection=1 ayarlayÄ±n.</li>
                                    <li><strong>Ä°ÅŸlem SÄ±rasÄ±:</strong> Consumer'da mesajlarÄ± sÄ±ralÄ± olarak iÅŸleyin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Producer AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// SÄ±ralÄ± gÃ¶nderim iÃ§in
props.put("max.in.flight.requests.per.connection", "1");
props.put("retries", Integer.MAX_VALUE);
props.put("enable.idempotence", "true");

// AynÄ± key'e sahip mesajlar aynÄ± partition'a gider
producer.send(new ProducerRecord<>("my-topic", "same-key", "value1"));
producer.send(new ProducerRecord<>("my-topic", "same-key", "value2"));</pre>
                                <p class="mt-2 font-medium">Consumer TarafÄ±nda SÄ±ralÄ± Ä°ÅŸleme:</p>
                                <pre class="code-block java mt-2">public class OrderedConsumer {
    public void consume() {
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                // SÄ±ralÄ± olarak iÅŸle
                processInOrder(record);
            }
        }
    }
    
    private void processInOrder(ConsumerRecord<String, String> record) {
        // MesajÄ± sÄ±ralÄ± olarak iÅŸle
        System.out.println("Processing: " + record.value());
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 48 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 48: Kafka'da mesajlar tÃ¼keticiye
                                ulaÅŸÄ±yor ama iÅŸlenmiyor, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Mesajlar tÃ¼keticiye ulaÅŸÄ±yor ama iÅŸlenmiyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer LoglarÄ±nÄ± Ä°nceleme:</strong> Hata veya exception olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Deserializasyon HatalarÄ±:</strong> Mesaj formatÄ±nÄ±n doÄŸru olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Ä°ÅŸlem HatasÄ±:</strong> Mesaj iÅŸlenirken hata oluÅŸuyor mu kontrol edin.</li>
                                    <li><strong>Offset Commit:</strong> Offset'lerin commit edilip edilmediÄŸini kontrol edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Consumer Hata AyÄ±klama:</p>
                                <pre class="code-block java mt-2">try {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        try {
            // MesajÄ± iÅŸle
            processMessage(record);
        } catch (Exception e) {
            // Hata durumunda log yaz
            logger.error("Error processing message: " + record.value(), e);
            
            // HatalÄ± mesajÄ± Ã¶zel bir topic'e gÃ¶nder
            sendToDlq(record);
        }
    }
    
    // BaÅŸarÄ±lÄ± mesajlarÄ± commit et
    consumer.commitSync();
} catch (Exception e) {
    logger.error("Error in consumer", e);
}</pre>
                            </div>
                        </div>

                        <!-- Soru 49 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 49: Kafka'da producer mesaj
                                gÃ¶nderemiyor, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Producer mesaj gÃ¶nderemiyorsa:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Broker BaÄŸlantÄ±sÄ±:</strong> Broker'a baÄŸlanÄ±p baÄŸlanamadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Topic VarlÄ±ÄŸÄ±:</strong> Topic'in var olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Yetkilendirme:</strong> Producer'Ä±n topic'e yazma yetkisinin olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Producer AyarlarÄ±:</strong> Bootstrap servers, serializer gibi ayarlarÄ±n doÄŸru olup olmadÄ±ÄŸÄ±nÄ± kontrol edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">BaÄŸlantÄ± Testi:</p>
                                <pre class="code-block bash mt-2"># Broker'a baÄŸlantÄ± testi
telnet localhost 9092

# Topic listesini kontrol etme
bin/kafka-topics.sh --bootstrap-server localhost:9092 --list</pre>
                                <p class="mt-2 font-medium">Producer Hata AyÄ±klama:</p>
                                <pre class="code-block java mt-2">try {
    ProducerRecord<String, String> record = new ProducerRecord<>("my-topic", "key", "value");
    
    // Senkron gÃ¶nderim ve hata kontrolÃ¼
    RecordMetadata metadata = producer.send(record).get();
    
    System.out.println("Message sent to partition " + metadata.partition() + 
                      " with offset " + metadata.offset());
} catch (InterruptedException | ExecutionException e) {
    // Hata durumunda detaylÄ± bilgi
    if (e.getCause() instanceof TimeoutException) {
        System.err.println("Timeout while sending message");
    } else if (e.getCause() instanceof NotLeaderForPartitionException) {
        System.err.println("Not leader for partition");
    } else {
        System.err.println("Error sending message: " + e.getCause().getMessage());
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 50 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 50: Kafka kÃ¼mesi yÃ¼ksek
                                gecikme (latency) yaÅŸÄ±yor, ne yapmalÄ±yÄ±m?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka kÃ¼mesinde yÃ¼ksek gecikme yaÅŸÄ±yorsanÄ±z:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Network Gecikmesi:</strong> Broker'lar arasÄ± ve client-broker arasÄ± network gecikmesini Ã¶lÃ§Ã¼n.</li>
                                    <li><strong>Disk I/O:</strong> Disk I/O performansÄ±nÄ± kontrol edin.</li>
                                    <li><strong>GC Pauses:</strong> JVM garbage collection sÃ¼relerini izleyin.</li>
                                    <li><strong>Broker KaynaklarÄ±:</strong> CPU, bellek ve disk kullanÄ±mÄ±nÄ± kontrol edin.</li>
                                    <li><strong>Producer ve Consumer AyarlarÄ±:</strong> Batch boyutu, buffer boyutu gibi ayarlarÄ± optimize edin.</li>
                                </ul>
                                <p class="mt-2 font-medium">Gecikme Ã–lÃ§Ã¼mÃ¼:</p>
                                <pre class="code-block bash mt-2"># Producer gecikmesi Ã¶lÃ§Ã¼mÃ¼
bin/kafka-run-class.sh kafka.tools.EndToEndLatency \
  broker-list localhost:9092 \
  topic test-topic \
  num-records 1000 \
  record-size 1000 \
  producer-props acks=all,linger.ms=0 \
  consumer-props group.id=test-group

# Network gecikmesi testi
ping -c 10 kafka-broker-host</pre>
                                <p class="mt-2 font-medium">Producer ve Consumer AyarlarÄ±:</p>
                                <pre class="code-block java mt-2">// Producer iÃ§in dÃ¼ÅŸÃ¼k gecikme ayarlarÄ±
props.put("linger.ms", 0); // Bekleme sÃ¼resini sÄ±fÄ±rla
props.put("batch.size", 0); // Batch'leri devre dÄ±ÅŸÄ± bÄ±rak
props.put("compression.type", "none"); // SÄ±kÄ±ÅŸtÄ±rmayÄ± devre dÄ±ÅŸÄ± bÄ±rak

// Consumer iÃ§in dÃ¼ÅŸÃ¼k gecikme ayarlarÄ±
props.put("fetch.min.bytes", 1); // Minimum bekleme boyutu
props.put("fetch.max.wait.ms", 100); // Maksimum bekleme sÃ¼resi</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Entegrasyon ve KullanÄ±m SenaryolarÄ± -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka Entegrasyon ve KullanÄ±m SenaryolarÄ±</h3>

                        <!-- Soru 51 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 51: Kafka ve Spark Streaming nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Spark Streaming entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Spark Kafka Connector:</strong> Spark'Ä±n Kafka ile iletiÅŸim kurmasÄ±nÄ± saÄŸlar.</li>
                                    <li><strong>Structured Streaming:</strong> Spark'Ä±n yapÄ±sal akÄ±ÅŸ iÅŸleme API'si.</li>
                                </ul>
                                <p class="mt-2 font-medium">Spark Streaming Kafka Entegrasyonu:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import org.apache.spark.sql.types._

val spark = SparkSession.builder()
  .appName("KafkaSparkIntegration")
  .master("local[*]")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()

// Mesaj deÄŸerlerini string olarak dÃ¶nÃ¼ÅŸtÃ¼rme
val values = df.selectExpr("CAST(value AS STRING)")

// Veriyi iÅŸleme
val processed = values.withColumn("processed", upper(col("value")))

// Kafka'ya yazma
val query = processed.writeStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("topic", "output-topic")
  .option("checkpointLocation", "/tmp/checkpoint")
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 52 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 52: Kafka ve Flink nasÄ±l entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Flink entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Flink Kafka Connector:</strong> Flink'in Kafka ile iletiÅŸim kurmasÄ±nÄ± saÄŸlar.</li>
                                    <li><strong>FlinkKafkaConsumer ve FlinkKafkaProducer:</strong> Kafka'dan veri okuma ve yazma sÄ±nÄ±flarÄ±.</li>
                                </ul>
                                <p class="mt-2 font-medium">Flink Kafka Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import java.util.Properties;

public class KafkaFlinkIntegration {
    public static void main(String[] args) throws Exception {
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        Properties properties = new Properties();
        properties.setProperty("bootstrap.servers", "localhost:9092");
        properties.setProperty("group.id", "flink-consumer");
        
        // Kafka'dan veri okuma
        FlinkKafkaConsumer<String> consumer = new FlinkKafkaConsumer<>(
            "input-topic",
            new SimpleStringSchema(),
            properties
        );
        
        DataStream<String> stream = env.addSource(consumer);
        
        // Veriyi iÅŸleme
        DataStream<String> processed = stream.map(String::toUpperCase);
        
        // Kafka'ya yazma
        FlinkKafkaProducer<String> producer = new FlinkKafkaProducer<>(
            "localhost:9092",
            "output-topic",
            new SimpleStringSchema()
        );
        
        processed.addSink(producer);
        
        env.execute("Kafka Flink Integration");
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 53 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 53: Kafka ve Storm nasÄ±l entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Storm entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>KafkaSpout:</strong> Kafka'dan veri okumak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>KafkaBolt:</strong> Kafka'ya veri yazmak iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Storm Kafka Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.storm.kafka.BrokerHosts;
import org.apache.storm.kafka.SpoutConfig;
import org.apache.storm.kafka.StringScheme;
import org.apache.storm.kafka.ZkHosts;
import org.apache.storm.kafka.bolt.KafkaBolt;
import org.apache.storm.kafka.bolt.StringKeyValueScheme;
import org.apache.storm.topology.TopologyBuilder;

public class KafkaStormIntegration {
    public static void main(String[] args) throws Exception {
        BrokerHosts hosts = new ZkHosts("localhost:2181");
        
        // Kafka Spout yapÄ±landÄ±rmasÄ±
        SpoutConfig spoutConfig = new SpoutConfig(hosts, "input-topic", "/zookeeper", "storm-consumer");
        spoutConfig.scheme = new SchemeAsMultiScheme(new StringScheme());
        
        // Kafka Bolt yapÄ±landÄ±rmasÄ±
        KafkaBolt<String, String> kafkaBolt = new KafkaBolt<String, String>()
            .withProducerProperties(new Properties() {{
                put("bootstrap.servers", "localhost:9092");
                put("acks", "1");
                put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
                put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
            }})
            .withTopicSelector("output-topic")
            .withTupleToKafkaMapper(new FieldNameTupleToKafkaMapper<String, String>("key", "value"));
        
        // Topoloji oluÅŸturma
        TopologyBuilder builder = new TopologyBuilder();
        builder.setSpout("kafka-spout", new KafkaSpout(spoutConfig), 1);
        builder.setBolt("upper-bolt", new UpperCaseBolt(), 1).shuffleGrouping("kafka-spout");
        builder.setBolt("kafka-bolt", kafkaBolt, 1).shuffleGrouping("upper-bolt");
        
        // Topolojiyi Ã§alÄ±ÅŸtÄ±rma
        Config config = new Config();
        config.setDebug(true);
        
        LocalCluster cluster = new LocalCluster();
        cluster.submitTopology("kafka-storm-integration", config, builder.createTopology());
        
        Thread.sleep(10000);
        cluster.shutdown();
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 54 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 54: Kafka ve Elasticsearch nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Elasticsearch entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Elasticsearch Connector:</strong> Kafka'dan Elasticsearch'e veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Logstash:</strong> Kafka'dan veri okuyup Elasticsearch'e yazmak iÃ§in kullanÄ±labilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Elasticsearch Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "elasticsearch-sink",
  "config": {
    "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "http://localhost:9200",
    "type.name": "_doc",
    "key.ignore": "true",
    "schema.ignore": "true",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Logstash KonfigÃ¼rasyonu:</p>
                                <pre class="code-block ruby mt-2"># logstash.conf
input {
  kafka {
    bootstrap_servers => "localhost:9092"
    topics => ["input-topic"]
  }
}

filter {
  # Gerekli dÃ¶nÃ¼ÅŸÃ¼mleri burada yapÄ±n
  mutate {
    rename => { "message" => "event_message" }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "kafka-events"
    document_type => "_doc"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 55 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 55: Kafka ve Cassandra nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Cassandra entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Cassandra Connector:</strong> Kafka'dan Cassandra'ya veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Spark Cassandra Connector:</strong> Spark ile Kafka'dan okunan veriyi Cassandra'ya yazmak iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Cassandra Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "cassandra-sink",
  "config": {
    "connector.class": "com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connect.cassandra.contact.points": "localhost",
    "connect.cassandra.port": "9042",
    "connect.cassandra.key.space": "test_keyspace",
    "connect.cassandra.consistency.level": "ONE",
    "connect.cassandra.error.policy": "NOOP",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark Cassandra Connector Ã–rneÄŸi:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import com.datastax.spark.connector.cql.CassandraConnector
import com.datastax.spark.connector._

val spark = SparkSession.builder()
  .appName("KafkaCassandraIntegration")
  .master("local[*]")
  .config("spark.cassandra.connection.host", "localhost")
  .config("spark.cassandra.connection.port", "9042")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING) as json")
  .select(from_json("json", "name STRING, age INT").as("data"))
  .select("data.*")

// Cassandra'ya yazma
val query = df.writeStream
  .foreachBatch { (batchDF: org.apache.spark.sql.DataFrame, batchId: Long) =>
    batchDF.write
      .format("org.apache.spark.sql.cassandra")
      .options(Map("table" -> "users", "keyspace" -> "test_keyspace"))
      .mode("append")
      .save()
  }
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 56 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 56: Kafka ve Hadoop HDFS nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Hadoop HDFS entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect HDFS Connector:</strong> Kafka'dan HDFS'e veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Spark HDFS Connector:</strong> Spark ile Kafka'dan okunan veriyi HDFS'e yazmak iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect HDFS Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "hdfs-sink",
  "config": {
    "connector.class": "io.confluent.connect.hdfs.HdfsSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "hdfs.url": "hdfs://localhost:9000",
    "hadoop.conf.dir": "/etc/hadoop/conf",
    "flush.size": "3",
    "rotate.interval.ms": "1000",
    "logs.dir": "/kafka-data",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark HDFS Ã–rneÄŸi:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder()
  .appName("KafkaHdfsIntegration")
  .master("local[*]")
  .config("spark.hadoop.fs.defaultFS", "hdfs://localhost:9000")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING)")

// HDFS'e yazma
val query = df.writeStream
  .format("parquet")
  .option("path", "hdfs://localhost:9000/kafka-data")
  .option("checkpointLocation", "/tmp/checkpoint")
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 57 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 57: Kafka ve MongoDB nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve MongoDB entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect MongoDB Connector:</strong> Kafka'dan MongoDB'ye veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Spark MongoDB Connector:</strong> Spark ile Kafka'dan okunan veriyi MongoDB'ye yazmak iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect MongoDB Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "mongodb-sink",
  "config": {
    "connector.class": "com.mongodb.kafka.connect.MongoSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.uri": "mongodb://localhost:27017/kafka_db",
    "database": "kafka_db",
    "collection": "events",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Spark MongoDB Ã–rneÄŸi:</p>
                                <pre class="code-block scala mt-2">import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import com.mongodb.spark.config._

val spark = SparkSession.builder()
  .appName("KafkaMongoDBIntegration")
  .master("local[*]")
  .config("spark.mongodb.input.uri", "mongodb://localhost:27017/kafka_db.events")
  .config("spark.mongodb.output.uri", "mongodb://localhost:27017/kafka_db.events")
  .getOrCreate()

// Kafka'dan veri okuma
val df = spark.readStream
  .format("kafka")
  .option("kafka.bootstrap.servers", "localhost:9092")
  .option("subscribe", "input-topic")
  .load()
  .selectExpr("CAST(value AS STRING) as json")
  .select(from_json("json", "name STRING, age INT").as("data"))
  .select("data.*")

// MongoDB'ye yazma
val query = df.writeStream
  .foreachBatch { (batchDF: org.apache.spark.sql.DataFrame, batchId: Long) =>
    batchDF.write
      .format("com.mongodb.spark.sql.DefaultSource")
      .mode("append")
      .save()
  }
  .start()

query.awaitTermination()</pre>
                            </div>
                        </div>

                        <!-- Soru 58 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 58: Kafka ve Redis nasÄ±l entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve Redis entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect Redis Connector:</strong> Kafka'dan Redis'e veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Redis Stream:</strong> Redis'in stream veri yapÄ±sÄ± ile Kafka arasÄ±nda veri aktarÄ±mÄ±.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect Redis Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "redis-sink",
  "config": {
    "connector.class": "com.github.jcustenborder.kafka.connect.redis.RedisSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "redis.host": "localhost",
    "redis.port": "6379",
    "redis.command": "SET",
    "redis.key": "kafka-message",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Java Redis Entegrasyonu:</p>
                                <pre class="code-block java mt-2">import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;
import redis.clients.jedis.Jedis;
import java.util.Collections;
import java.util.Properties;

public class KafkaRedisIntegration {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");
        props.put("group.id", "redis-consumer");
        props.put("key.deserializer", StringDeserializer.class.getName());
        props.put("value.deserializer", StringDeserializer.class.getName());
        
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        consumer.subscribe(Collections.singletonList("input-topic"));
        
        Jedis jedis = new Jedis("localhost", 6379);
        
        while (true) {
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
            for (ConsumerRecord<String, String> record : records) {
                // Redis'e yaz
                jedis.set("kafka:" + record.offset(), record.value());
                System.out.println("Written to Redis: " + record.value());
            }
        }
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 59 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 59: Kafka ve PostgreSQL nasÄ±l
                                entegre edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve PostgreSQL entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect JDBC Connector:</strong> Kafka'dan PostgreSQL'e veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Debezium:</strong> PostgreSQL'den deÄŸiÅŸiklikleri yakalayÄ±p Kafka'ya gÃ¶ndermek iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect JDBC Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "postgres-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "jdbc:postgresql://localhost:5432/kafka_db",
    "connection.user": "postgres",
    "connection.password": "password",
    "auto.create": "true",
    "auto.evolve": "true",
    "insert.mode": "insert",
    "pk.mode": "none",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Debezium PostgreSQL Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "postgres-source",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "database.hostname": "localhost",
    "database.port": "5432",
    "database.user": "postgres",
    "database.password": "password",
    "database.dbname": "postgres",
    "database.server.name": "postgres-server",
    "plugin.name": "pgoutput"
  }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 60 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 60: Kafka ve MySQL nasÄ±l entegre
                                edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Kafka ve MySQL entegrasyonu iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Kafka Connect JDBC Connector:</strong> Kafka'dan MySQL'e veri aktarmak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li><strong>Debezium:</strong> MySQL'den deÄŸiÅŸiklikleri yakalayÄ±p Kafka'ya gÃ¶ndermek iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kafka Connect JDBC Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "mysql-sink",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSinkConnector",
    "tasks.max": "1",
    "topics": "input-topic",
    "connection.url": "jdbc:mysql://localhost:3306/kafka_db",
    "connection.user": "root",
    "connection.password": "password",
    "auto.create": "true",
    "auto.evolve": "true",
    "insert.mode": "insert",
    "pk.mode": "none",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": false
  }
}</pre>
                                <p class="mt-2 font-medium">Debezium MySQL Connector YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block json mt-2">{
  "name": "mysql-source",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "root",
    "database.password": "password",
    "database.server.id": "184054",
    "database.server.name": "mysql-server",
    "database.include.list": "kafka_db",
    "database.history.kafka.bootstrap.servers": "localhost:9092",
    "database.history.kafka.topic": "schema-changes.kafka_db"
  }
}</pre>
                            </div>
                        </div>
                    </div>

                    <!-- Kafka Ä°leri DÃ¼zey Senaryolar -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Kafka Ä°leri DÃ¼zey Senaryolar</h3>

                        <!-- Soru 61 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 61: Kafka'da CQRS (Command Query
                                Responsibility Segregation) pattern nasÄ±l uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> CQRS pattern, yazma (command) ve okuma (query) iÅŸlemlerini ayÄ±ran bir mimari pattern'idir. Kafka ile CQRS uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Command Side:</strong> KullanÄ±cÄ± eylemleri (create, update, delete) iÃ§in bir topic.</li>
                                    <li><strong>Event Store:</strong> KomutlarÄ± olaylara dÃ¶nÃ¼ÅŸtÃ¼ren ve olaylarÄ± bir topic'e yazan bir servis.</li>
                                    <li><strong>Query Side:</strong> OlaylarÄ± dinleyen ve okuma modelini gÃ¼ncelleyen bir servis.</li>
                                </ul>
                                <p class="mt-2 font-medium">CQRS Mimarisi Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Command Service
public class CommandService {
    private final KafkaTemplate<String, Object> kafkaTemplate;
    
    public void createUser(CreateUserCommand command) {
        // Komutu doÄŸrula
        // ...
        
        // Olay oluÅŸtur
        UserCreatedEvent event = new UserCreatedEvent(
            command.getUserId(),
            command.getUsername(),
            command.getEmail()
        );
        
        // OlayÄ± Kafka'ya gÃ¶nder
        kafkaTemplate.send("user-commands", event);
    }
}

// Event Processor
public class EventProcessor {
    @KafkaListener(topics = "user-commands")
    public void processUserCreatedEvent(UserCreatedEvent event) {
        // OlayÄ± iÅŸle ve veritabanÄ±na yaz
        User user = new User(
            event.getUserId(),
            event.getUsername(),
            event.getEmail()
        );
        
        userRepository.save(user);
        
        // Okuma modelini gÃ¼ncelle
        UserView userView = new UserView(
            event.getUserId(),
            event.getUsername(),
            event.getEmail()
        );
        
        userViewRepository.save(userView);
    }
}

// Query Service
public class QueryService {
    public UserView getUser(String userId) {
        return userViewRepository.findById(userId);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 62 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 62: Kafka'da Event Sourcing pattern
                                nasÄ±l uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Event Sourcing, uygulama durumunu olaylarÄ±n bir dizisi olarak saklayan bir pattern'idir. Kafka ile Event Sourcing uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Event Store:</strong> OlaylarÄ± saklamak iÃ§in bir Kafka topic'i.</li>
                                    <li><strong>Aggregate:</strong> OlaylarÄ± uygulayarak mevcut durumu yeniden oluÅŸturan bir sÄ±nÄ±f.</li>
                                    <li><strong>Snapshot:</strong> PerformansÄ± artÄ±rmak iÃ§in belirli aralÄ±klarla durumun anlÄ±k gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ alma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Event Sourcing Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Event Interface
public interface Event {
    String getAggregateId();
    Instant getTimestamp();
}

// Aggregate Class
public class UserAggregate {
    private String userId;
    private String username;
    private String email;
    private List<Event> events = new ArrayList<>();
    
    public static UserAggregate create(String userId, String username, String email) {
        UserAggregate aggregate = new UserAggregate();
        aggregate.apply(new UserCreatedEvent(userId, username, email));
        return aggregate;
    }
    
    public void updateEmail(String email) {
        apply(new UserEmailUpdatedEvent(userId, email));
    }
    
    private void apply(Event event) {
        // OlayÄ± uygula
        if (event instanceof UserCreatedEvent) {
            UserCreatedEvent e = (UserCreatedEvent) event;
            this.userId = e.getUserId();
            this.username = e.getUsername();
            this.email = e.getEmail();
        } else if (event instanceof UserEmailUpdatedEvent) {
            UserEmailUpdatedEvent e = (UserEmailUpdatedEvent) event;
            this.email = e.getEmail();
        }
        
        // OlayÄ± listeye ekle
        events.add(event);
    }
    
    public List<Event> getUncommittedEvents() {
        return new ArrayList<>(events);
    }
    
    public void markEventsAsCommitted() {
        events.clear();
    }
}

// Event Store
public class EventStore {
    private final KafkaTemplate<String, Event> kafkaTemplate;
    
    public void saveEvents(String aggregateId, List<Event> events) {
        events.forEach(event -> {
            kafkaTemplate.send("user-events", aggregateId, event);
        });
    }
    
    public List<Event> getEvents(String aggregateId) {
        // Kafka'dan olaylarÄ± oku
        // ...
        return events;
    }
}

// Aggregate Repository
public class AggregateRepository {
    private final EventStore eventStore;
    
    public void save(UserAggregate aggregate) {
        eventStore.saveEvents(aggregate.getUserId(), aggregate.getUncommittedEvents());
        aggregate.markEventsAsCommitted();
    }
    
    public UserAggregate findById(String userId) {
        List<Event> events = eventStore.getEvents(userId);
        UserAggregate aggregate = new UserAggregate();
        
        // OlaylarÄ± sÄ±rayla uygula
        events.forEach(aggregate::apply);
        
        return aggregate;
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 63 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 63: Kafka'da Saga pattern nasÄ±l
                                uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Saga pattern, daÄŸÄ±tÄ±k sistemlerde transaction yÃ¶netimi iÃ§in kullanÄ±lan bir pattern'idir. Kafka ile Saga uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Orchestrator-Based Saga:</strong> Merkezi bir orchestrator tÃ¼m adÄ±mlarÄ± yÃ¶netir.</li>
                                    <li><strong>Choreography-Based Saga:</strong> Her servis kendi adÄ±mÄ±nÄ± tamamlar ve bir sonraki adÄ±mÄ± tetikler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Choreography-Based Saga Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Order Service
@Service
public class OrderService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Transactional
    public Order createOrder(OrderRequest orderRequest) {
        // SipariÅŸi oluÅŸtur
        Order order = new Order(orderRequest);
        orderRepository.save(order);
        
        // OrderCreatedEvent gÃ¶nder
        OrderCreatedEvent event = new OrderCreatedEvent(
            order.getId(),
            order.getCustomerId(),
            order.getAmount()
        );
        
        kafkaTemplate.send("orders", event);
        
        return order;
    }
    
    @KafkaListener(topics = "payment-completed")
    public void handlePaymentCompleted(PaymentCompletedEvent event) {
        // Ã–deme tamamlandÄ±, sipariÅŸi gÃ¼ncelle
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.PAID);
        orderRepository.save(order);
        
        // OrderCompletedEvent gÃ¶nder
        OrderCompletedEvent orderEvent = new OrderCompletedEvent(order.getId());
        kafkaTemplate.send("orders", orderEvent);
    }
    
    @KafkaListener(topics = "payment-failed")
    public void handlePaymentFailed(PaymentFailedEvent event) {
        // Ã–deme baÅŸarÄ±sÄ±z, sipariÅŸi iptal et
        Order order = orderRepository.findById(event.getOrderId());
        order.setStatus(OrderStatus.CANCELLED);
        orderRepository.save(order);
        
        // OrderCancelledEvent gÃ¶nder
        OrderCancelledEvent orderEvent = new OrderCancelledEvent(order.getId());
        kafkaTemplate.send("orders", orderEvent);
    }
}

// Payment Service
@Service
public class PaymentService {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @KafkaListener(topics = "orders")
    public void handleOrderCreated(OrderCreatedEvent event) {
        try {
            // Ã–deme iÅŸlemini yap
            Payment payment = paymentService.processPayment(
                event.getOrderId(),
                event.getAmount()
            );
            
            // PaymentCompletedEvent gÃ¶nder
            PaymentCompletedEvent paymentEvent = new PaymentCompletedEvent(
                payment.getOrderId(),
                payment.getId()
            );
            
            kafkaTemplate.send("payments", paymentEvent);
        } catch (PaymentException e) {
            // PaymentFailedEvent gÃ¶nder
            PaymentFailedEvent paymentEvent = new PaymentFailedEvent(
                event.getOrderId(),
                e.getMessage()
            );
            
            kafkaTemplate.send("payments", paymentEvent);
        }
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 64 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 64: Kafka'da Dead Letter Queue (DLQ)
                                nasÄ±l uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Dead Letter Queue, iÅŸlenemeyen mesajlarÄ± saklamak iÃ§in kullanÄ±lan bir pattern'idir. Kafka ile DLQ uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Hata Yakalama:</strong> Mesaj iÅŸlenirken oluÅŸan hatalarÄ± yakala.</li>
                                    <li><strong>DLQ Topic:</strong> Ä°ÅŸlenemeyen mesajlarÄ± gÃ¶ndermek iÃ§in Ã¶zel bir topic.</li>
                                    <li><strong>Retry MekanizmasÄ±:</strong> MesajlarÄ± yeniden denemek iÃ§in bir mekanizma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Dead Letter Queue Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">@Service
public class MessageProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Value("${kafka.topic.dlq}")
    private String dlqTopic;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        try {
            // MesajÄ± iÅŸle
            process(record.value());
            
            // BaÅŸarÄ±lÄ± ise offset'i commit et
            // ...
        } catch (Exception e) {
            // Hata durumunda log yaz
            logger.error("Error processing message: " + record.value(), e);
            
            // MesajÄ± DLQ'ya gÃ¶nder
            sendToDlq(record, e);
        }
    }
    
    private void sendToDlq(ConsumerRecord<String, String> record, Exception e) {
        // Orijinal mesaj bilgilerini ve hatayÄ± iÃ§eren bir DLQ mesajÄ± oluÅŸtur
        DlqMessage dlqMessage = new DlqMessage(
            record.value(),
            record.topic(),
            record.partition(),
            record.offset(),
            e.getMessage(),
            Instant.now()
        );
        
        // DLQ topic'ine gÃ¶nder
        kafkaTemplate.send(dlqTopic, dlqMessage);
    }
}

// Retry MekanizmasÄ±
@Service
public class RetryableMessageProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Value("${kafka.topic.retry}")
    private String retryTopic;
    
    @Value("${kafka.topic.dlq}")
    private String dlqTopic;
    
    @KafkaListener(topics = "input-topic")
    public void processWithRetry(ConsumerRecord<String, String> record) {
        int maxRetries = 3;
        int retryCount = 0;
        boolean success = false;
        
        while (retryCount < maxRetries && !success) {
            try {
                // MesajÄ± iÅŸle
                process(record.value());
                success = true;
            } catch (Exception e) {
                retryCount++;
                
                if (retryCount >= maxRetries) {
                    // Maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±, DLQ'ya gÃ¶nder
                    sendToDlq(record, e);
                } else {
                    // Retry topic'ine gÃ¶nder
                    sendToRetryTopic(record, retryCount, e);
                    
                    // Bir sonraki deneme iÃ§in bekle
                    try {
                        Thread.sleep(1000 * retryCount);
                    } catch (InterruptedException ie) {
                        Thread.currentThread().interrupt();
                    }
                }
            }
        }
    }
    
    private void sendToRetryTopic(ConsumerRecord<String, String> record, int retryCount, Exception e) {
        RetryMessage retryMessage = new RetryMessage(
            record.value(),
            record.topic(),
            record.partition(),
            record.offset(),
            retryCount,
            e.getMessage(),
            Instant.now()
        );
        
        kafkaTemplate.send(retryTopic, retryMessage);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 65 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 65: Kafka'da idempotent consumer nasÄ±l
                                uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Idempotent consumer, aynÄ± mesajÄ±n birden fazla kez iÅŸlenmesini Ã¶nleyen bir pattern'idir. Kafka ile idempotent consumer uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Mesaj ID'si:</strong> Her mesaj iÃ§in benzersiz bir ID.</li>
                                    <li><strong>Ä°ÅŸlenmiÅŸ ID'ler:</strong> Zaten iÅŸlenmiÅŸ mesaj ID'lerini saklayan bir mekanizma.</li>
                                </ul>
                                <p class="mt-2 font-medium">Idempotent Consumer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">@Service
public class IdempotentConsumer {
    @Autowired
    private ProcessedMessageRepository processedMessageRepository;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Mesaj ID'sini oluÅŸtur
        String messageId = record.key() + "-" + record.offset();
        
        // MesajÄ±n daha Ã¶nce iÅŸlenip iÅŸlenmediÄŸini kontrol et
        if (processedMessageRepository.existsById(messageId)) {
            logger.info("Message already processed: " + messageId);
            return;
        }
        
        try {
            // MesajÄ± iÅŸle
            process(record.value());
            
            // MesajÄ± iÅŸlenmiÅŸ olarak iÅŸaretle
            ProcessedMessage processedMessage = new ProcessedMessage(
                messageId,
                record.topic(),
                record.partition(),
                record.offset(),
                Instant.now()
            );
            
            processedMessageRepository.save(processedMessage);
        } catch (Exception e) {
            // Hata durumunda log yaz ve iÅŸlemi geri al
            logger.error("Error processing message: " + messageId, e);
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // MesajÄ± iÅŸle
        // ...
    }
}

// Redis ile Idempotent Consumer
@Service
public class RedisIdempotentConsumer {
    @Autowired
    private RedisTemplate<String, String> redisTemplate;
    
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Mesaj ID'sini oluÅŸtur
        String messageId = record.key() + "-" + record.offset();
        
        // Redis'te mesaj ID'sini kontrol et
        Boolean isProcessed = redisTemplate.hasKey(messageId);
        
        if (Boolean.TRUE.equals(isProcessed)) {
            logger.info("Message already processed: " + messageId);
            return;
        }
        
        try {
            // MesajÄ± iÅŸle
            process(record.value());
            
            // MesajÄ± Redis'te iÅŸlenmiÅŸ olarak iÅŸaretle
            redisTemplate.opsForValue().set(messageId, "PROCESSED");
            
            // MesajÄ±n ne kadar sÃ¼re kalacaÄŸÄ±nÄ± ayarla (Ã¶rneÄŸin 7 gÃ¼n)
            redisTemplate.expire(messageId, 7, TimeUnit.DAYS);
        } catch (Exception e) {
            // Hata durumunda log yaz ve iÅŸlemi geri al
            logger.error("Error processing message: " + messageId, e);
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // MesajÄ± iÅŸle
        // ...
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 66 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 66: Kafka'da backpressure nasÄ±l
                                yÃ¶netilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Backpressure, veri Ã¼reticisinin hÄ±zÄ±nÄ± tÃ¼keticinin iÅŸleyebileceÄŸi hÄ±zla sÄ±nÄ±rlayan bir mekanizmadÄ±r. Kafka'da backpressure yÃ¶netmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Consumer Lag Ä°zleme:</strong> Consumer'Ä±n geride kalmasÄ±nÄ± izleme.</li>
                                    <li><strong>Dynamic Throttling:</strong> Producer hÄ±zÄ±nÄ± dinamik olarak ayarlama.</li>
                                    <li><strong>Buffer Boyutunu Ayarlama:</strong> Producer ve consumer buffer boyutlarÄ±nÄ± ayarlama.</li>
                                </ul>
                                <p class="mt-2 font-medium">Backpressure YÃ¶netimi Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">@Service
public class BackpressureManager {
    @Autowired
    private KafkaAdmin kafkaAdmin;
    
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    private final double maxLagThreshold = 1000.0; // Maksimum lag eÅŸiÄŸi
    private final double minLagThreshold = 100.0;  // Minimum lag eÅŸiÄŸi
    
    @Scheduled(fixedRate = 5000) // Her 5 saniyede bir kontrol et
    public void manageBackpressure() {
        // TÃ¼m consumer gruplarÄ± iÃ§in lag deÄŸerlerini al
        Map<String, Map<TopicPartition, OffsetAndMetadata>> consumerGroups = getConsumerGroupOffsets();
        
        for (Map.Entry<String, Map<TopicPartition, OffsetAndMetadata>> entry : consumerGroups.entrySet()) {
            String groupId = entry.getKey();
            Map<TopicPartition, OffsetAndMetadata> offsets = entry.getValue();
            
            // Her topic iÃ§in lag hesapla
            Map<String, Long> topicLags = calculateTopicLags(offsets);
            
            for (Map.Entry<String, Long> topicEntry : topicLags.entrySet()) {
                String topic = topicEntry.getKey();
                Long lag = topicEntry.getValue();
                
                // Lag eÅŸiÄŸine gÃ¶re throttling uygula
                if (lag > maxLagThreshold) {
                    // Producer hÄ±zÄ±nÄ± dÃ¼ÅŸÃ¼r
                    throttleProducer(topic, 0.5); // %50 hÄ±zÄ±nda
                    logger.info("Throttling producer for topic: " + topic + " due to high lag: " + lag);
                } else if (lag < minLagThreshold) {
                    // Producer hÄ±zÄ±nÄ± artÄ±r
                    throttleProducer(topic, 1.0); // Tam hÄ±z
                    logger.info("Resuming producer for topic: " + topic + " as lag is normal: " + lag);
                }
            }
        }
    }
    
    private Map<String, Long> calculateTopicLags(Map<TopicPartition, OffsetAndMetadata> offsets) {
        Map<String, Long> topicLags = new HashMap<>();
        
        // Her topic iÃ§in lag hesapla
        for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {
            TopicPartition partition = entry.getKey();
            OffsetAndMetadata offsetMetadata = entry.getValue();
            
            // Topic son offset'ini al
            long endOffset = getEndOffset(partition);
            
            // Lag hesapla
            long lag = endOffset - offsetMetadata.offset();
            
            // Topic lag'ini gÃ¼ncelle
            topicLags.merge(partition.topic(), lag, Long::sum);
        }
        
        return topicLags;
    }
    
    private void throttleProducer(String topic, double throttleFactor) {
        // Producer'Ä± kÄ±sÄ±tla
        // Bu, producer'Ä±n linger.ms ve batch.size ayarlarÄ±nÄ± deÄŸiÅŸtirerek yapÄ±labilir
        // veya Ã¶zel bir throttling mekanizmasÄ± uygulanabilir
        
        // Ã–rnek: linger.ms deÄŸerini artÄ±r
        updateProducerConfig(topic, "linger.ms", (int) (10 / throttleFactor));
        
        // Ã–rnek: batch.size deÄŸerini artÄ±r
        updateProducerConfig(topic, "batch.size", (int) (16384 / throttleFactor));
    }
    
    private void updateProducerConfig(String topic, String configKey, int configValue) {
        // Producer config'ini gÃ¼ncelle
        // Bu, Kafka Admin API veya Ã¶zel bir config yÃ¶netimi ile yapÄ±labilir
        // ...
        
        logger.info("Updated producer config for topic: " + topic + ", " + configKey + "=" + configValue);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 67 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 67: Kafka'da exactly-once processing nasÄ±l
                                saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Exactly-once processing, her mesajÄ±n tam olarak bir kez iÅŸlendiÄŸini garanti eden bir Ã¶zelliktir. Kafka'da exactly-once processing saÄŸlamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Idempotent Producer:</strong> AynÄ± mesajÄ±n birden fazla kez gÃ¶nderilmesini Ã¶nler.</li>
                                    <li><strong>Transactions:</strong> Birden fazla partition'a atomik yazma iÅŸlemleri saÄŸlar.</li>
                                    <li><strong>Read Committed Isolation Level:</strong> Sadece commit edilmiÅŸ mesajlarÄ± okur.</li>
                                    <li><strong>Consumer Position Commit:</strong> Mesaj iÅŸlendikten sonra offset'leri commit eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Exactly-Once Processing Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">@Service
public class ExactlyOnceProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @KafkaListener(topics = "input-topic")
    @Transactional
    public void processMessage(ConsumerRecord<String, String> record) {
        try {
            // MesajÄ± iÅŸle
            String result = process(record.value());
            
            // Sonucu output topic'ine gÃ¶nder
            kafkaTemplate.send(new ProducerRecord<>("output-topic", record.key(), result));
            
            // Ä°ÅŸlem baÅŸarÄ±lÄ±, transaction commit edilecek
        } catch (Exception e) {
            // Hata durumunda transaction rollback edilecek
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private String process(String message) {
        // MesajÄ± iÅŸle ve sonuÃ§ dÃ¶ndÃ¼r
        return "PROCESSED: " + message;
    }
}

// Transactional Producer Ã–rneÄŸi
@Service
public class TransactionalProducerService {
    @Autowired
    private KafkaTemplate<String, String> kafkaTemplate;
    
    @PostConstruct
    public void init() {
        // Transactional producer'Ä± baÅŸlat
        kafkaTemplate.setTransactionIdPrefix("tx-");
    }
    
    public void sendInTransaction(String topic, String key, String value) {
        // Transaction iÃ§inde mesaj gÃ¶nder
        kafkaTemplate.executeInTransaction(template -> {
            template.send(new ProducerRecord<>(topic, key, value));
            return true;
        });
    }
}

// Exactly-Once Consumer Ã–rneÄŸi
@Service
public class ExactlyOnceConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record, Acknowledgment acknowledgment) {
        try {
            // MesajÄ± iÅŸle
            process(record.value());
            
            // Ä°ÅŸlem baÅŸarÄ±lÄ±, acknowledgment'Ä± onayla
            acknowledgment.acknowledge();
        } catch (Exception e) {
            // Hata durumunda acknowledgment'Ä± reddet
            acknowledgment.nack(1000); // 1 saniye sonra tekrar dene
            throw new RuntimeException("Failed to process message", e);
        }
    }
    
    private void process(String message) {
        // MesajÄ± iÅŸle
        // ...
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 68 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 68: Kafka'da schema evrimi (schema
                                evolution) nasÄ±l yÃ¶netilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Schema evrimi, veri ÅŸemalarÄ±nÄ±n zamanla deÄŸiÅŸmesini yÃ¶netme iÅŸlemidir. Kafka'da schema evrimi yÃ¶netmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Schema Registry:</strong> ÅemalarÄ± merkezi olarak yÃ¶netir.</li>
                                    <li><strong>Uyumluluk KurallarÄ±:</strong> Åema deÄŸiÅŸikliklerinin uyumluluÄŸunu kontrol eder.</li>
                                    <li><strong>Avro, Protobuf, JSON Schema:</strong> Schema evrimini destekleyen formatlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Schema Evrimi Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Ä°lk schema
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "email", "type": "string"}
  ]
}

// Yeni schema (yeni alan eklenmiÅŸ)
{
  "type": "record",
  "name": "User",
  "fields": [
    {"name": "id", "type": "string"},
    {"name": "name", "type": "string"},
    {"name": "email", "type": "string"},
    {"name": "age", "type": ["null", "int"], "default": null}
  ]
}

// Java ile Schema Registry kullanÄ±mÄ±
public class SchemaEvolutionExample {
    public static void main(String[] args) throws IOException, RestClientException {
        // Schema Registry istemcisi oluÅŸtur
        SchemaRegistryClient client = new CachedSchemaRegistryClient("http://localhost:8081", 100);
        
        // Schema'yÄ± kaydet
        String schemaJson = "{\n" +
            "  \"type\": \"record\",\n" +
            "  \"name\": \"User\",\n" +
            "  \"fields\": [\n" +
            "    {\"name\": \"id\", \"type\": \"string\"},\n" +
            "    {\"name\": \"name\", \"type\": \"string\"},\n" +
            "    {\"name\": \"email\", \"type\": \"string\"}\n" +
            "  ]\n" +
            "}";
        
        Schema schema = new Schema.Parser().parse(schemaJson);
        SchemaMetadata metadata = client.register("users-value", schema);
        
        System.out.println("Schema registered with id: " + metadata.getId());
        
        // Schema'yÄ± al
        Schema retrievedSchema = client.getById(metadata.getId());
        System.out.println("Retrieved schema: " + retrievedSchema.toString());
        
        // Yeni schema'yÄ± kaydet (evrim)
        String newSchemaJson = "{\n" +
            "  \"type\": \"record\",\n" +
            "  \"name\": \"User\",\n" +
            "  \"fields\": [\n" +
            "    {\"name\": \"id\", \"type\": \"string\"},\n" +
            "    {\"name\": \"name\", \"type\": \"string\"},\n" +
            "    {\"name\": \"email\", \"type\": \"string\"},\n" +
            "    {\"name\": \"age\", \"type\": [\"null\", \"int\"], \"default\": null}\n" +
            "  ]\n" +
            "}";
        
        Schema newSchema = new Schema.Parser().parse(newSchemaJson);
        SchemaMetadata newMetadata = client.register("users-value", newSchema);
        
        System.out.println("New schema registered with id: " + newMetadata.getId());
        
        // Uyumluluk kontrolÃ¼
        boolean isCompatible = client.testCompatibility("users-value", newSchema);
        System.out.println("Is new schema compatible? " + isCompatible);
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 69 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 69: Kafka'da multi-tenancy nasÄ±l
                                uygulanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Multi-tenancy, tek bir Kafka kÃ¼mesinde birden fazla kiracÄ± (tenant) iÃ§in veri ayÄ±rma saÄŸlayan bir yaklaÅŸÄ±mdÄ±r. Kafka'da multi-tenancy uygulamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Tenant BazlÄ± Topic'ler:</strong> Her tenant iÃ§in ayrÄ± topic'ler.</li>
                                    <li><strong>Tenant BazlÄ± Partition'lar:</strong> Her tenant iÃ§in ayrÄ± partition'lar.</li>
                                    <li><strong>Tenant BazlÄ± Consumer GruplarÄ±:</strong> Her tenant iÃ§in ayrÄ± consumer gruplarÄ±.</li>
                                    <li><strong>Tenant BazlÄ± Yetkilendirme:</strong> Her tenant iÃ§in ayrÄ± ACL'ler.</li>
                                </ul>
                                <p class="mt-2 font-medium">Multi-Tenancy Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Tenant bazlÄ± topic isimlendirme
public class TopicNamingStrategy {
    public static String getTenantTopic(String tenantId, String baseTopic) {
        return tenantId + "-" + baseTopic;
    }
}

// Tenant bazlÄ± producer
@Service
public class TenantAwareProducer {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public void sendToTenant(String tenantId, String topic, String key, Object value) {
        String tenantTopic = TopicNamingStrategy.getTenantTopic(tenantId, topic);
        
        // Tenant bilgisini header'a ekle
        ProducerRecord<String, Object> record = new ProducerRecord<>(
            tenantTopic, key, value
        );
        
        record.headers().add("tenant-id", tenantId.getBytes());
        
        kafkaTemplate.send(record);
    }
}

// Tenant bazlÄ± consumer
@Service
public class TenantAwareConsumer {
    @KafkaListener(topics = "#{tenantAwareTopicResolver.getTopics()}")
    public void processMessage(ConsumerRecord<String, String> record) {
        // Tenant ID'sini header'dan al
        String tenantId = getTenantId(record);
        
        // Tenant'a Ã¶zgÃ¼ iÅŸ mantÄ±ÄŸÄ±nÄ± uygula
        processForTenant(tenantId, record.value());
    }
    
    private String getTenantId(ConsumerRecord<String, String> record) {
        // Topic adÄ±ndan tenant ID'sini Ã§Ä±kar
        String topic = record.topic();
        return topic.substring(0, topic.indexOf('-'));
    }
    
    private void processForTenant(String tenantId, String message) {
        // Tenant'a Ã¶zgÃ¼ iÅŸ mantÄ±ÄŸÄ±
        // ...
    }
}

// Tenant bazlÄ± yetkilendirme
@Service
public class TenantAwareAuthorizer {
    public boolean authorize(String tenantId, String resource, String operation) {
        // Tenant'Ä±n kaynaÄŸa eriÅŸim yetkisi olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        // ...
        return true;
    }
}

// Tenant bazlÄ± konfigÃ¼rasyon
@Configuration
public class TenantAwareConfig {
    @Bean
    public KafkaAdmin kafkaAdmin() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        return new KafkaAdmin(configs);
    }
    
    @Bean
    public NewTopic createTenantTopics() {
        // Tenant'lar iÃ§in topic'leri oluÅŸtur
        return TopicBuilder.name("tenant1-orders")
                .partitions(3)
                .replicas(1)
                .build();
    }
}</pre>
                            </div>
                        </div>

                        <!-- Soru 70 -->
                        <div class="question-card border-l-4 border-blue-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 70: Kafka'da veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ (data
                                integrity) nasÄ±l saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼, Kafka'da verinin doÄŸru ve tutarlÄ± kalmasÄ±nÄ± saÄŸlayan Ã¶nlemlerdir. Kafka'da veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ saÄŸlamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Checksum:</strong> Veriye checksum ekleyerek bozulmayÄ± tespit etme.</li>
                                    <li><strong>Validation:</strong> Veriyi iÅŸlemeden Ã¶nce doÄŸrulama.</li>
                                    <li><strong>Idempotent Operations:</strong> AynÄ± iÅŸlemin birden fazla kez uygulanmasÄ±nÄ± Ã¶nleme.</li>
                                    <li><strong>Transactions:</strong> Birden fazla iÅŸlemi atomik olarak gerÃ§ekleÅŸtirme.</li>
                                </ul>
                                <p class="mt-2 font-medium">Veri BÃ¼tÃ¼nlÃ¼ÄŸÃ¼ Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">// Checksum ile veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼
public class DataIntegrityUtils {
    public static String calculateChecksum(String data) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(data.getBytes(StandardCharsets.UTF_8));
            return Hex.encodeHexString(hash);
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("Failed to calculate checksum", e);
        }
    }
    
    public static boolean verifyChecksum(String data, String checksum) {
        String calculatedChecksum = calculateChecksum(data);
        return calculatedChecksum.equals(checksum);
    }
}

// Producer ile checksum gÃ¶nderme
@Service
public class ChecksumProducer {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    public void sendWithChecksum(String topic, String key, String value) {
        // Veri ve checksum'Ä± iÃ§eren bir nesne oluÅŸtur
        DataWithChecksum dataWithChecksum = new DataWithChecksum(
            value,
            DataIntegrityUtils.calculateChecksum(value)
        );
        
        // MesajÄ± gÃ¶nder
        kafkaTemplate.send(new ProducerRecord<>(topic, key, dataWithChecksum));
    }
}

// Consumer ile checksum doÄŸrulama
@Service
public class ChecksumConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, DataWithChecksum> record) {
        DataWithChecksum dataWithChecksum = record.value();
        
        // Checksum'Ä± doÄŸrula
        if (!DataIntegrityUtils.verifyChecksum(
            dataWithChecksum.getData(),
            dataWithChecksum.getChecksum()
        )) {
            throw new DataIntegrityException("Checksum verification failed");
        }
        
        // Veriyi iÅŸle
        process(dataWithChecksum.getData());
    }
    
    private void process(String data) {
        // Veriyi iÅŸle
        // ...
    }
}

// Validation ile veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼
@Service
public class ValidationConsumer {
    @KafkaListener(topics = "input-topic")
    public void processMessage(ConsumerRecord<String, String> record) {
        String data = record.value();
        
        // Veriyi doÄŸrula
        ValidationResult validationResult = validate(data);
        
        if (!validationResult.isValid()) {
            // GeÃ§ersiz veriyi DLQ'ya gÃ¶nder
            sendToDlq(record, validationResult.getErrorMessage());
            return;
        }
        
        // GeÃ§erli veriyi iÅŸle
        process(data);
    }
    
    private ValidationResult validate(String data) {
        // Veriyi doÄŸrula
        if (data == null || data.isEmpty()) {
            return ValidationResult.invalid("Data is null or empty");
        }
        
        if (data.length() > 1000) {
            return ValidationResult.invalid("Data is too long");
        }
        
        return ValidationResult.valid();
    }
}

// Transaction ile veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼
@Service
public class TransactionalProcessor {
    @Autowired
    private KafkaTemplate<String, Object> kafkaTemplate;
    
    @Autowired
    private DatabaseService databaseService;
    
    @Transactional
    public void processInTransaction(String input) {
        // Veriyi iÅŸle
        String result = process(input);
        
        // VeritabanÄ±na yaz
        databaseService.save(result);
        
        // Output topic'ine gÃ¶nder
        kafkaTemplate.send(new ProducerRecord<>("output-topic", result));
        
        // Ä°ÅŸlem baÅŸarÄ±lÄ±, transaction commit edilecek
    }
    
    private String process(String input) {
        // Veriyi iÅŸle ve sonuÃ§ dÃ¶ndÃ¼r
        return "PROCESSED: " + input;
    }
}</pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- RabbitMQ SorularÄ± -->
        <section id="rabbitmq" class="mb-16">
            <div class="bg-white rounded-lg shadow-md p-6 mb-8">
                <div class="flex items-center mb-6">
                    <div class="rabbit-color p-3 rounded-full mr-4">
                        <i class="fas fa-envelope text-white text-xl"></i>
                    </div>
                    <h2 class="text-2xl font-bold text-gray-800">RabbitMQ MÃ¼lakat SorularÄ±</h2>
                </div>
                <p class="text-gray-600 mb-6">Bu dokÃ¼manda RabbitMQ mÃ¼lakatlarÄ±nda en Ã§ok sorulan konular soru-cevap mantÄ±ÄŸÄ±yla aÃ§Ä±klanmÄ±ÅŸ ve Ã¶rnek kodlar eklenmiÅŸtir.</p>

                <div class="space-y-6">
                    <!-- Temel RabbitMQ KavramlarÄ± -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ Temel RabbitMQ KavramlarÄ±</h3>

                        <!-- Soru 1 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 1: RabbitMQ nedir? Ne iÅŸe
                                yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ, aÃ§Ä±k kaynaklÄ± bir mesajlaÅŸma kuyruÄŸu sistemidir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>AMQP (Advanced Message Queuing Protocol) standardÄ±nÄ± uygular.</li>
                                    <li>FarklÄ± uygulamalar arasÄ±nda asenkron iletiÅŸim saÄŸlar.</li>
                                    <li>YÃ¼ksek performanslÄ±, gÃ¼venilir ve Ã¶lÃ§eklenebilir bir mesajlaÅŸma Ã§Ã¶zÃ¼mÃ¼dÃ¼r.</li>
                                </ul>
                                <p class="mt-2 font-medium">RabbitMQ Sunucusunu BaÅŸlatma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmq-server</pre>
                            </div>
                        </div>

                        <!-- Soru 2 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 2: RabbitMQ'da Exchange nedir?
                                TÃ¼rleri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Exchange, gelen mesajlarÄ± belirli kurallara gÃ¶re kuyruklara yÃ¶nlendiren bir bileÅŸendir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Direct Exchange:</strong> MesajÄ± routing key'e tam olarak eÅŸleÅŸen kuyruklara yÃ¶nlendirir.</li>
                                    <li><strong>Topic Exchange:</strong> MesajÄ± routing key'inin bir desenine (pattern) gÃ¶re kuyruklara yÃ¶nlendirir.</li>
                                    <li><strong>Fanout Exchange:</strong> MesajÄ± baÄŸlÄ± tÃ¼m kuyruklara yayÄ±nlar.</li>
                                    <li><strong>Headers Exchange:</strong> MesajÄ± header'lara gÃ¶re kuyruklara yÃ¶nlendirir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Direct Exchange OluÅŸturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare exchange name=direct-exchange type=direct</pre>
                            </div>
                        </div>

                        <!-- Soru 3 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 3: RabbitMQ'da Queue nedir?
                                TÃ¼rleri nelerdir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Queue, mesajlarÄ±n depolandÄ±ÄŸÄ± ve tÃ¼keticiye ulaÅŸtÄ±rÄ±ldÄ±ÄŸÄ± bir yapÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Classic Queue:</strong> Standart kuyruk tÃ¼rÃ¼.</li>
                                    <li><strong>Quorum Queue:</strong> YÃ¼ksek eriÅŸilebilirlik ve veri gÃ¼venliÄŸi iÃ§in kullanÄ±lan kuyruk tÃ¼rÃ¼.</li>
                                    <li><strong>Stream Queue:</strong> Log tabanlÄ±, yÃ¼ksek performanslÄ± kuyruk tÃ¼rÃ¼.</li>
                                </ul>
                                <p class="mt-2 font-medium">Queue OluÅŸturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare queue name=my-queue</pre>
                            </div>
                        </div>

                        <!-- Soru 4 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 4: RabbitMQ'da Binding nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Binding, bir exchange ile bir kuyruk arasÄ±ndaki iliÅŸkiyi tanÄ±mlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Exchange'ten kuyruÄŸa mesajlarÄ±n nasÄ±l yÃ¶nlendirileceÄŸini belirler.</li>
                                    <li>Direct ve Topic exchange'lerde routing key veya binding key kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Binding OluÅŸturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqadmin declare binding source=direct-exchange destination=my-queue routing_key=my-key</pre>
                            </div>
                        </div>

                        <!-- Soru 5 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 5: RabbitMQ'da Producer ve Consumer
                                arasÄ±ndaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Producer (Publisher):</strong> RabbitMQ'ya mesaj gÃ¶nderen uygulamadÄ±r.</li>
                                    <li><strong>Consumer:</strong> RabbitMQ'dan mesaj alan uygulamadÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Java Producer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
try (Connection connection = factory.newConnection();
     Channel channel = connection.createChannel()) {
    
    channel.exchangeDeclare("direct-exchange", "direct");
    
    String message = "Hello, RabbitMQ!";
    channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());
    System.out.println(" [x] Sent '" + message + "'");
}</pre>
                                <p class="mt-2 font-medium">Java Consumer Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
try (Connection connection = factory.newConnection();
     Channel channel = connection.createChannel()) {
    
    channel.queueDeclare("my-queue", false, false, false, null);
    channel.queueBind("my-queue", "direct-exchange", "my-key");
    
    DeliverCallback deliverCallback = (consumerTag, delivery) -> {
        String message = new String(delivery.getBody(), "UTF-8");
        System.out.println(" [x] Received '" + message + "'");
    };
    channel.basicConsume("my-queue", true, deliverCallback, consumerTag -> {});
}</pre>
                            </div>
                        </div>

                        <!-- Soru 6 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 6: RabbitMQ'da Routing Key nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Routing Key, bir mesajÄ±n hangi kuyruÄŸa yÃ¶nlendirileceÄŸini belirten bir etikettir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Direct ve Topic exchange'lerde kullanÄ±lÄ±r.</li>
                                    <li>Direct exchange'te tam eÅŸleÅŸme, Topic exchange'te desen eÅŸleÅŸmesi saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Routing Key ile Mesaj GÃ¶nderme:</p>
                                <pre class="code-block java mt-2">String routingKey = "user.created";
channel.basicPublish("topic-exchange", routingKey, null, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 7 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 7: RabbitMQ'da Virtual Host nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Virtual Host, RabbitMQ sunucusu iÃ§indeki mantÄ±ksal bir bÃ¶lÃ¼mdÃ¼r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>FarklÄ± uygulamalar iÃ§in izolasyon saÄŸlar.</li>
                                    <li>Her virtual host kendi exchange'lerine, kuyruklarÄ±na ve kullanÄ±cÄ±larÄ±na sahiptir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Virtual Host OluÅŸturma Komutu:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl add_vhost my-vhost</pre>
                                <p class="mt-2 font-medium">Virtual Host'a KullanÄ±cÄ± Ekleme:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_permissions -p my-vhost my-user ".*" ".*" ".*"</pre>
                            </div>
                        </div>

                        <!-- Soru 8 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 8: RabbitMQ'da Connection ve Channel
                                arasÄ±ndaki fark nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong></p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Connection:</strong> Uygulama ile RabbitMQ sunucusu arasÄ±ndaki TCP baÄŸlantÄ±sÄ±dÄ±r.</li>
                                    <li><strong>Channel:</strong> Bir connection Ã¼zerinden aÃ§Ä±lan sanal bir baÄŸlantÄ±dÄ±r.</li>
                                </ul>
                                <p>Her connection birden fazla channel iÃ§erebilir. Channel'lar, aynÄ± TCP baÄŸlantÄ±sÄ± Ã¼zerinden birden fazla iÅŸlemi paralel olarak gerÃ§ekleÅŸtirmek iÃ§in kullanÄ±lÄ±r.</p>
                            </div>
                        </div>

                        <!-- Soru 9 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 9: RabbitMQ'da Message Durability
                                (KalÄ±cÄ±lÄ±k) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Message Durability, mesajlarÄ±n RabbitMQ sunucusu yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda bile kaybolmamasÄ±nÄ± saÄŸlayan bir Ã¶zelliktir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Persistent Messages:</strong> Disk Ã¼zerinde saklanan mesajlardÄ±r.</li>
                                    <li><strong>Transient Messages:</strong> Bellekte saklanan ve sunucu yeniden baÅŸlatÄ±ldÄ±ÄŸÄ±nda kaybolan mesajlardÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">KalÄ±cÄ± Mesaj GÃ¶nderme:</p>
                                <pre class="code-block java mt-2">channel.basicPublish("direct-exchange", "my-key", 
                     MessageProperties.PERSISTENT_TEXT_PLAIN, 
                     message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 10 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 10: RabbitMQ'da Acknowledgment
                                (Onay) nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Acknowledgment, bir mesajÄ±n baÅŸarÄ±yla iÅŸlendiÄŸini RabbitMQ'ya bildiren mekanizmadÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Automatic Acknowledgment:</strong> Mesaj tÃ¼keticiye ulaÅŸtÄ±ÄŸÄ±nda otomatik olarak onaylanÄ±r.</li>
                                    <li><strong>Manual Acknowledgment:</strong> TÃ¼ketici mesajÄ± iÅŸledikten sonra manuel olarak onaylar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Manual Acknowledgment Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">DeliverCallback deliverCallback = (consumerTag, delivery) -> {
    String message = new String(delivery.getBody(), "UTF-8");
    System.out.println(" [x] Received '" + message + "'");
    
    // MesajÄ± iÅŸle
    processMessage(message);
    
    // Onayla
    channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
};
channel.basicConsume("my-queue", false, deliverCallback, consumerTag -> {});</pre>
                            </div>
                        </div>
                    </div>

                    <!-- RabbitMQ Ä°leri DÃ¼zey Konular -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ RabbitMQ Ä°leri DÃ¼zey Konular</h3>

                        <!-- Soru 11 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 11: RabbitMQ'da Prefetch Count
                                nedir? Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Prefetch Count, bir tÃ¼keticiye aynÄ± anda gÃ¶nderilebilecek maksimum mesaj sayÄ±sÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>TÃ¼ketici performansÄ±nÄ± optimize etmek iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>DÃ¼ÅŸÃ¼k deÄŸerler, mesajlarÄ±n daha eÅŸit daÄŸÄ±tÄ±lmasÄ±nÄ± saÄŸlar.</li>
                                    <li>YÃ¼ksek deÄŸerler, daha yÃ¼ksek verimlilik saÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prefetch Count Ayarlama:</p>
                                <pre class="code-block java mt-2">channel.basicQos(10); // Her seferinde en fazla 10 mesaj gÃ¶nder</pre>
                            </div>
                        </div>

                        <!-- Soru 12 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 12: RabbitMQ'da Dead Letter Exchange (DLX)
                                nedir? Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Dead Letter Exchange, iÅŸlenemeyen veya reddedilen mesajlarÄ±n yÃ¶nlendirildiÄŸi bir exchange'tir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Mesajlar sÃ¼resi dolduÄŸunda, kuyruk dolu olduÄŸunda veya reddedildiÄŸinde DLX'e gÃ¶nderilir.</li>
                                    <li>Ä°ÅŸlenemeyen mesajlarÄ± analiz etmek ve yeniden iÅŸlemek iÃ§in kullanÄ±lÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">DLX Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-dead-letter-exchange", "dlx-exchange");
args.put("x-dead-letter-routing-key", "dlx-key");

channel.queueDeclare("my-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 13 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 13: RabbitMQ'da Message TTL (Time-To-Live)
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Message TTL, bir mesajÄ±n kuyrukta ne kadar sÃ¼re kalacaÄŸÄ±nÄ± belirten bir sÃ¼re sÄ±nÄ±rlamasÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>SÃ¼re dolduÄŸunda mesaj kuyruktan kaldÄ±rÄ±lÄ±r veya DLX'e gÃ¶nderilir.</li>
                                    <li>Kuyruk seviyesinde veya mesaj seviyesinde ayarlanabilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Kuyruk TTL Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-message-ttl", 60000); // 60 saniye

channel.queueDeclare("my-queue", false, false, false, args);</pre>
                                <p class="mt-2 font-medium">Mesaj TTL Ayarlama:</p>
                                <pre class="code-block java mt-2">AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
    .expiration("60000") // 60 saniye
    .build();

channel.basicPublish("direct-exchange", "my-key", properties, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 14 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 14: RabbitMQ'da Publisher Confirms
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Publisher Confirms, bir mesajÄ±n RabbitMQ sunucusu tarafÄ±ndan alÄ±ndÄ±ÄŸÄ±nÄ± onaylayan bir mekanizmadÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>MesajlarÄ±n kaybolmamasÄ±nÄ± saÄŸlar.</li>
                                    <li>Asenkron veya senkron olarak kullanÄ±labilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Publisher Confirms Ã–rneÄŸi:</p>
                                <pre class="code-block java mt-2">channel.confirmSelect();

// Senkron onay
channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());
channel.waitForConfirmsOrDie(5000); // 5 saniye bekle

// Asenkron onay
channel.addConfirmListener((deliveryTag, multiple) -> {
    System.out.println("Message confirmed with tag: " + deliveryTag);
}, (deliveryTag, multiple) -> {
    System.out.println("Message not confirmed with tag: " + deliveryTag);
});

channel.basicPublish("direct-exchange", "my-key", null, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 15 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 15: RabbitMQ'da Alternate Exchange nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Alternate Exchange, bir exchange'e gÃ¶nderilen mesajlarÄ±n herhangi bir kuyruÄŸa yÃ¶nlendirilememesi durumunda yÃ¶nlendirildiÄŸi bir exchange'tir.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>YanlÄ±ÅŸ routing key ile gÃ¶nderilen mesajlarÄ± yakalamak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Exchange oluÅŸturulurken ayarlanÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Alternate Exchange Ayarlama:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("alternate-exchange", "alternate-exchange");

channel.exchangeDeclare("main-exchange", "direct", true, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 16 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 16: RabbitMQ'da Priority Queue nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Priority Queue, mesajlarÄ±n Ã¶nceliklerine gÃ¶re iÅŸlendiÄŸi bir kuyruk tÃ¼rÃ¼dÃ¼r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>YÃ¼ksek Ã¶ncelikli mesajlar dÃ¼ÅŸÃ¼k Ã¶ncelikli mesajlardan Ã¶nce iÅŸlenir.</li>
                                    <li>Kuyruk oluÅŸturulurken maksimum Ã¶ncelik seviyesi belirlenir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Priority Queue OluÅŸturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-max-priority", 10); // Maksimum Ã¶ncelik seviyesi

channel.queueDeclare("priority-queue", false, false, false, args);</pre>
                                <p class="mt-2 font-medium">Ã–ncelikli Mesaj GÃ¶nderme:</p>
                                <pre class="code-block java mt-2">AMQP.BasicProperties properties = new AMQP.BasicProperties.Builder()
    .priority(5) // 1-10 arasÄ± Ã¶ncelik
    .build();

channel.basicPublish("direct-exchange", "my-key", properties, message.getBytes());</pre>
                            </div>
                        </div>

                        <!-- Soru 17 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 17: RabbitMQ'da Lazy Queues nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Lazy Queues, mesajlarÄ± disk Ã¼zerinde saklayarak bellek kullanÄ±mÄ±nÄ± optimize eden kuyruk tÃ¼rÃ¼dÃ¼r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>BÃ¼yÃ¼k miktarda mesajÄ± saklamak iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Mesajlar tÃ¼keticiye gÃ¶nderilene kadar diskte kalÄ±r.</li>
                                </ul>
                                <p class="mt-2 font-medium">Lazy Queue OluÅŸturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");

channel.queueDeclare("lazy-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 18 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 18: RabbitMQ'da Quorum Queues nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Quorum Queues, yÃ¼ksek eriÅŸilebilirlik ve veri gÃ¼venliÄŸi iÃ§in tasarlanmÄ±ÅŸ bir kuyruk tÃ¼rÃ¼dÃ¼r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Raft konsensus algoritmasÄ±nÄ± kullanÄ±r.</li>
                                    <li>Ã‡oÄŸunluk (quorum) ile karar verir.</li>
                                    <li>Veri kaybÄ±nÄ± Ã¶nlemek iÃ§in en az 3 node gerektirir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Quorum Queue OluÅŸturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-type", "quorum");

channel.queueDeclare("quorum-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 19 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 19: RabbitMQ'da Shovel eklentisi nedir?
                                Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Shovel eklentisi, bir RabbitMQ sunucusundan diÄŸerine veya baÅŸka bir mesajlaÅŸma sistemine mesaj kopyalamak iÃ§in kullanÄ±lÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>FarklÄ± sunucular arasÄ±nda mesaj senkronizasyonu saÄŸlar.</li>
                                    <li>Yedekleme veya veri migrasyonu iÃ§in kullanÄ±labilir.</li>
                                </ul>
                                <p class="mt-2 font-medium">Shovel YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_parameter shovel my-shovel \
'{"src-uri": "amqp://source-server", "src-queue": "source-queue", \
"dest-uri": "amqp://destination-server", "dest-queue": "destination-queue"}'</pre>
                            </div>
                        </div>

                        <!-- Soru 20 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 20: RabbitMQ'da Federation eklentisi nedir?
                                Ne iÅŸe yarar?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Federation eklentisi, farklÄ± RabbitMQ sunucularÄ± arasÄ±nda mesajlarÄ±n gÃ¼venilir bir ÅŸekilde daÄŸÄ±tÄ±lmasÄ±nÄ± saÄŸlar.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>CoÄŸrafi olarak daÄŸÄ±lmÄ±ÅŸ sunucular iÃ§in kullanÄ±lÄ±r.</li>
                                    <li>Shovel'dan farklÄ± olarak, federation upstream sunucudaki exchange'leri downstream sunucudaki exchange'lere baÄŸlar.</li>
                                </ul>
                                <p class="mt-2 font-medium">Federation Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_parameter federation-upstream my-upstream \
'{"uri":"amqp://upstream-server"}'

rabbitmqctl set_parameter federation-upstream-set my-upstream-set \
'{"upstream-set":"my-upstream"}'

rabbitmqctl set_parameter policy federation \
'{"pattern":"", "federation-upstream-set":"my-upstream-set"}'</pre>
                            </div>
                        </div>
                    </div>

                    <!-- RabbitMQ Ä°zleme ve YÃ¶netim -->
                    <div class="bg-gray-50 rounded-lg p-4 mb-6">
                        <h3 class="text-xl font-bold text-gray-800 mb-4">ğŸ”¹ RabbitMQ Ä°zleme ve YÃ¶netim</h3>

                        <!-- Soru 21 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 21: RabbitMQ'da monitoring iÃ§in
                                hangi araÃ§lar kullanÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ monitoring iÃ§in kullanÄ±lan araÃ§lar:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>RabbitMQ Management Plugin:</strong> Web tabanlÄ± yÃ¶netim arayÃ¼zÃ¼.</li>
                                    <li><strong>Prometheus + Grafana:</strong> Metrikleri toplamak ve gÃ¶rselleÅŸtirmek iÃ§in.</li>
                                    <li><strong>rabbitmq_exporter:</strong> Prometheus iÃ§in metrikleri dÄ±ÅŸa aktaran bir araÃ§.</li>
                                    <li><strong>ELK Stack:</strong> LoglarÄ± toplamak ve analiz etmek iÃ§in.</li>
                                </ul>
                                <p class="mt-2 font-medium">Management Plugin EtkinleÅŸtirme:</p>
                                <pre class="code-block bash mt-2">rabbitmq-plugins enable rabbitmq_management</pre>
                                <p class="mt-2 font-medium">Prometheus ile Entegrasyon:</p>
                                <pre class="code-block bash mt-2">rabbitmq-plugins enable rabbitmq_prometheus</pre>
                            </div>
                        </div>

                        <!-- Soru 22 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 22: RabbitMQ'da log yÃ¶netimi nasÄ±l
                                yapÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da log yÃ¶netimi iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Log DosyalarÄ±:</strong> RabbitMQ log dosyalarÄ± /var/log/rabbitmq/ dizininde bulunur.</li>
                                    <li><strong>Log Seviyeleri:</strong> debug, info, warning, error, critical.</li>
                                    <li><strong>Log DÃ¶ndÃ¼rme:</strong> Log dosyalarÄ±nÄ±n belirli boyuta ulaÅŸtÄ±ÄŸÄ±nda dÃ¶ndÃ¼rÃ¼lmesi.</li>
                                </ul>
                                <p class="mt-2 font-medium">Log YapÄ±landÄ±rmasÄ±:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
log.file.level = info
log.file = /var/log/rabbitmq/rabbit.log
log.exchange = true
log.queue = true</pre>
                            </div>
                        </div>

                        <!-- Soru 23 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 23: RabbitMQ'da memory alarm
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Memory alarm, RabbitMQ sunucusunun bellek kullanÄ±mÄ± belirli bir eÅŸiÄŸi aÅŸtÄ±ÄŸÄ±nda tetiklenen bir uyarÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Bellek kritik seviyeye ulaÅŸtÄ±ÄŸÄ±nda, yeni mesajlarÄ± kabul etmeyi durdurur.</li>
                                    <li>Publisher'lar bloke olur ve mesaj gÃ¶nderemez.</li>
                                    <li>Memory alarmÄ± temizlendikten sonra normal Ã§alÄ±ÅŸmaya devam eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Memory Alarm EÅŸiÄŸi Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
vm_memory_high_watermark.relative = 0.6 # %60 bellek kullanÄ±mÄ±</pre>
                            </div>
                        </div>

                        <!-- Soru 24 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 24: RabbitMQ'da disk alarm
                                nedir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> Disk alarm, RabbitMQ sunucusunun disk alanÄ± belirli bir eÅŸiÄŸi aÅŸtÄ±ÄŸÄ±nda tetiklenen bir uyarÄ±dÄ±r.</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li>Disk alanÄ± kritik seviyeye ulaÅŸtÄ±ÄŸÄ±nda, yeni mesajlarÄ± kabul etmeyi durdurur.</li>
                                    <li>Publisher'lar bloke olur ve mesaj gÃ¶nderemez.</li>
                                    <li>Disk alarmÄ± temizlendikten sonra normal Ã§alÄ±ÅŸmaya devam eder.</li>
                                </ul>
                                <p class="mt-2 font-medium">Disk Alarm EÅŸiÄŸi Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
disk_free_limit.relative = 1.0 # %1 boÅŸ disk alanÄ±</pre>
                            </div>
                        </div>

                        <!-- Soru 25 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 25: RabbitMQ'da kullanÄ±cÄ± ve yetki
                                yÃ¶netimi nasÄ±l yapÄ±lÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da kullanÄ±cÄ± ve yetki yÃ¶netimi iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>KullanÄ±cÄ± OluÅŸturma:</strong> rabbitmqctl add_user komutu ile.</li>
                                    <li><strong>Yetki Atama:</strong> rabbitmqctl set_permissions komutu ile.</li>
                                    <li><strong>Rol Atama:</strong> rabbitmqctl set_user_tags komutu ile.</li>
                                </ul>
                                <p class="mt-2 font-medium">KullanÄ±cÄ± OluÅŸturma:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl add_user my-user my-password</pre>
                                <p class="mt-2 font-medium">Yetki Atama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_permissions -p my-vhost my-user ".*" ".*" ".*"</pre>
                                <p class="mt-2 font-medium">Rol Atama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_user_tags my-user administrator</pre>
                            </div>
                        </div>

                        <!-- Soru 26 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 26: RabbitMQ'da cluster nasÄ±l
                                kurulur?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ cluster kurmak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>ERLANG Cookie:</strong> TÃ¼m node'larÄ±n aynÄ± ERLANG cookie'ye sahip olmasÄ± gerekir.</li>
                                    <li><strong>Node'larÄ± BirleÅŸtirme:</strong> rabbitmqctl join_cluster komutu ile.</li>
                                    <li><strong>Mirror Queues:</strong> KuyruklarÄ±n cluster iÃ§indeki tÃ¼m node'larda kopyalanmasÄ±.</li>
                                </ul>
                                <p class="mt-2 font-medium">ERLANG Cookie Ayarlama:</p>
                                <pre class="code-block bash mt-2"># /var/lib/rabbitmq/.erlang.cookie dosyasÄ±nÄ± tÃ¼m node'larda aynÄ± yapÄ±n</pre>
                                <p class="mt-2 font-medium">Cluster OluÅŸturma:</p>
                                <pre class="code-block bash mt-2"># Node 1
rabbitmq-server -detached

# Node 2
rabbitmq-server -detached
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@node1
rabbitmqctl start_app

# Node 3
rabbitmq-server -detached
rabbitmqctl stop_app
rabbitmqctl join_cluster rabbit@node1
rabbitmqctl start_app</pre>
                            </div>
                        </div>

                        <!-- Soru 27 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 27: RabbitMQ'da yÃ¼ksek eriÅŸilebilirlik
                                (High Availability) nasÄ±l saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da yÃ¼ksek eriÅŸilebilirlik saÄŸlamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Cluster:</strong> Birden fazla node iÃ§eren bir cluster oluÅŸturmak.</li>
                                    <li><strong>Mirror Queues:</strong> KuyruklarÄ±n cluster iÃ§indeki tÃ¼m node'larda kopyalanmasÄ±.</li>
                                    <li><strong>Load Balancer:</strong> Client'larÄ±n cluster node'larÄ±na daÄŸÄ±tÄ±lmasÄ± iÃ§in.</li>
                                </ul>
                                <p class="mt-2 font-medium">Mirror Queue Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all"}'</pre>
                                <p class="mt-2 font-medium">Hem Mirror Queue Hem Synchronized Queue Ayarlama:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl set_policy ha-all ".*" '{"ha-mode":"all","ha-sync-mode":"automatic"}'</pre>
                            </div>
                        </div>

                        <!-- Soru 28 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 28: RabbitMQ'da backup nasÄ±l
                                alÄ±nÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da backup almak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Definitions:</strong> Exchange, kuyruk, binding ve kullanÄ±cÄ± tanÄ±mlarÄ±nÄ± dÄ±ÅŸa aktarmak.</li>
                                    <li><strong>Mnesia Database:</strong> VeritabanÄ±nÄ± kopyalamak.</li>
                                    <li><strong>MesajlarÄ±n Backup'Ä±:</strong> Kuyruklardaki mesajlarÄ± kurtarmak.</li>
                                </ul>
                                <p class="mt-2 font-medium">Definitions DÄ±ÅŸa Aktarma:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl export_definitions > definitions.json</pre>
                                <p class="mt-2 font-medium">Mnesia Database Backup:</p>
                                <pre class="code-block bash mt-2">rabbitmqctl stop
cd /var/lib/rabbitmq/mnesia/rabbit@$(hostname)
cp -r * /backup/location/
rabbitmq-server -detached</pre>
                            </div>
                        </div>

                        <!-- Soru 29 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 29: RabbitMQ'da performans nasÄ±l
                                optimize edilir?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ performansÄ±nÄ± optimize etmek iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>Prefetch Count:</strong> TÃ¼keticiye gÃ¶nderilecek mesaj sayÄ±sÄ±nÄ± ayarlamak.</li>
                                    <li><strong>Batch Processing:</strong> MesajlarÄ± toplu olarak iÅŸlemek.</li>
                                    <li><strong>Persistent vs. Non-Persistent:</strong> GerekmedikÃ§e kalÄ±cÄ± mesajlar kullanmamak.</li>
                                    <li><strong>Lazy Queues:</strong> BÃ¼yÃ¼k miktarda mesaj iÃ§in lazy kuyruklar kullanmak.</li>
                                    <li><strong>Connection Pooling:</strong> BaÄŸlantÄ± havuzu kullanmak.</li>
                                </ul>
                                <p class="mt-2 font-medium">Prefetch Count Ayarlama:</p>
                                <pre class="code-block java mt-2">channel.basicQos(100); // Her seferinde en fazla 100 mesaj gÃ¶nder</pre>
                                <p class="mt-2 font-medium">Lazy Queue OluÅŸturma:</p>
                                <pre class="code-block java mt-2">Map<String, Object> args = new HashMap<>();
args.put("x-queue-mode", "lazy");

channel.queueDeclare("lazy-queue", false, false, false, args);</pre>
                            </div>
                        </div>

                        <!-- Soru 30 -->
                        <div class="question-card border-l-4 border-orange-500 pl-4 py-2 mb-4">
                            <h4 class="text-lg font-semibold text-gray-800 mb-2">â“ Soru 30: RabbitMQ'da gÃ¼venlik nasÄ±l
                                saÄŸlanÄ±r?</h4>
                            <div class="text-gray-700">
                                <p><strong>Cevap:</strong> RabbitMQ'da gÃ¼venlik saÄŸlamak iÃ§in:</p>
                                <ul class="list-disc pl-5 mt-2">
                                    <li><strong>SSL/TLS:</strong> Client ile sunucu arasÄ±ndaki iletiÅŸimi ÅŸifrelemek.</li>
                                    <li><strong>KullanÄ±cÄ± DoÄŸrulama:</strong> KullanÄ±cÄ± adÄ± ve ÅŸifre ile doÄŸrulama.</li>
                                    <li><strong>Yetkilendirme:</strong> KullanÄ±cÄ±larÄ±n kaynaklara eriÅŸimini kontrol etmek.</li>
                                    <li><strong>Virtual Hosts:</strong> FarklÄ± uygulamalarÄ± izole etmek.</li>
                                </ul>
                                <p class="mt-2 font-medium">SSL/TLS Ayarlama:</p>
                                <pre class="code-block properties mt-2"># rabbitmq.conf
listeners.ssl.default = 5671
ssl_options.cacertfile = /path/to/cacert.pem
ssl_options.certfile = /path/to/cert.pem
ssl_options.keyfile = /path/to/key.pem</pre>
                                <p class="mt-2 font-medium">Java Client SSL Ayarlama:</p>
                                <pre class="code-block java mt-2">ConnectionFactory factory = new ConnectionFactory();
factory.setHost("localhost");
factory.setPort(5671);
factory.useSslProtocol();
factory.setUsername("my-user");
factory.setPassword("my-password");</pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <footer class="text-center py-8 text-gray-600">
            <p>Â© 2025 HacÄ± Celal Aygar. All rights reserved. Kafka ve RabbitMQ MÃ¼lakat SorularÄ±</p>
        </footer>
    </div>

    <script>
        function scrollToCategory(categoryId) {
            const element = document.getElementById(categoryId);
            element.scrollIntoView({ behavior: 'smooth' });
        }
    </script>
</body>

</html>
